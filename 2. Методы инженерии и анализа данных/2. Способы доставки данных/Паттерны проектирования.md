<h2>Паттерны проектирования</h2>

В области инженерии данных широко применяются различные паттерны проектирования, которые помогают решать стандартные задачи интеграции данных. Паттерны, такие как Change Data Capture (CDC), Event Sourcing и Command Query Responsibility Segregation (CQRS), обеспечивают надежные и масштабируемые подходы к обработке и анализу данных.

<h3>1. Сhange Data Capture (CDC)</h3>

Change Data Capture (CDC) — это методология и набор шаблонов проектирования программного обеспечения, которые позволяют выявлять и отслеживать изменения в данных в системе-источнике (например, в базе данных) и доставлять эти изменения в другие системы или процессы в режиме, близком к реальному времени. CDC играет ключевую роль в построении реактивных, событийно-ориентированных и слабосвязанных систем. Он является "кровеносной системой" для данных, обеспечивая их непрерывный поток из систем-источников в системы-потребители.

Вместо того чтобы периодически опрашивать всю базу данных на предмет изменений (например, с помощью `SELECT ... WHERE last_modified > ...`), CDC захватывает каждое изменение (`INSERT`, `UPDATE`, `DELETE`) непосредственно в момент его совершения.

Преимущества:
- Асинхронность и производительность: Источник данных (OLTP-база) не блокируется и не нагружается дополнительными запросами от многочисленных потребителей. Изменения доставляются асинхронно, что сохраняет высокую производительность транзакционных систем.
- Доставка в реальном времени (Near Real-Time): Потребители получают данные практически мгновенно после их изменения в источнике. Это критически важно для систем мониторинга, аналитики в реальном времени и мгновенных уведомлений.
- Надежность и полнота данных: Захватываются все изменения, включая удаления. Подход на основе лога гарантирует, что ни одно изменение не будет пропущено, так как он является единственным источником истины для транзакций.
- Упрощение интеграции: CDC предоставляет стандартизированный способ потоковой передачи изменений данных. Вместо того чтобы создавать уникальные интеграции для каждой системы, можно настроить единый CDC-конвейер, и все подписчики будут получать одинаково форматированные события.
- Поддержка современных архитектурных паттернов.

Инструменты для реализации:
- Debezium: Распространенная платформа с открытым исходным кодом, построенная поверх Apache Kafka. Использует коннекторы для разных БД, которые считывают журналы транзакций и публикуют события в топики Kafka в формате JSON/Avro.
- Oracle GoldenGate / Oracle LogMiner: Промышленное решение для Oracle, GoldenGate — мощный инструмент для репликации данных в реальном времени.
- SQL Server Change Data Capture / Change Tracking: Встроенные функции MS SQL Server для отслеживания изменений.
- PostgreSQL Logical Decoding: Низкоуровневый API для доступа к содержимому WAL. Именно его используют такие инструменты, как Debezium, для работы с PostgreSQL.
- AWS Database Migration Service (DMS): Позволяет настраивать непрерывную репликацию данных из популярных баз данных в различные цели в AWS (S3, Redshift, Kinesis).
- AWS Glue Streaming ETL: Может использовать собственные коннекторы для CDC.
- Google Cloud Dataflow: Позволяет создавать конвейеры потоковой обработки, которые могут включать в себя шаг CDC через коннекторы или пользовательский код.
- Azure Data Factory: Имеет возможности для потокового копирования данных, которые можно использовать для сценариев CDC.

Сложности реализации в распределенных системах:
- Гарантия доставки "точно один раз" (Exactly-Once Semantics): Необходимо координировать работу между чтением лога БД-источника и подтверждением записи в систему-назначение (например, Kafka). Если процессор CDC упал после обработки изменения, но до его отправки, при перезапуске оно может быть обработано повторно.
- Управление схемой данных (Schema Evolution): Все потребители событий CDC должны быть способны обработать новую версию сообщения. Без четкой стратегии это приводит к поломке конвейеров.
- Масштабирование и производительность: Высоконагруженная БД может генерировать огромный поток изменений. Один узел обработки CDC может не справиться. Параллельная обработка событий из лога, который по своей природе является последовательным (упорядоченным), сложна. Неправильное распределение может привести к нарушению порядка событий для одной и той же строки.
- Мониторинг и обработка сбоев: Если потребитель "отстает" от источника или ломается, это может привести к лавине необработанных сообщений или потере данных. Необходимо отслеживать лаг репликации (разницу между последним изменением в источнике и последним обработанным событием). Также нужно иметь механизмы для повторной обработки данных с определенного момента (replay).
- Влияние на источник (нагрузка): Даже чтение лога создает нагрузку на источник. При высоком RPS (числе операций в секунду) это может стать проблемой. В распределенной системе с множеством БД и коннекторов CDC необходимо централизованно управлять нагрузкой, чтобы не "положить" источники данных.

Проблемы безопасности:
- Несанкционированный доступ к конфиденциальным данным: CDC по своей сути захватывает все изменения, включая вставки и обновления конфиденциальных данных. Злоумышленник, получивший доступ к потоку событий CDC (например, к топику Kafka), получает полную копию всех данных базы в реальном времени, минуя механизмы аутентификации и авторизации самого приложения.
- Отсутствие контроля доступа на уровне строк (Row-Level Security): В приложении может быть реализована сложная логика разрешений (например, пользователь видит только свои заказы). CDC-поток обходит эту логику, передавая данные всех пользователей сразу. Потребитель CDC-потока, который не реализует такую же логику авторизации, получит несанкционированный доступ к данным.
- Неизменяемость и аудит логов: Поток событий CDC — это, по сути, лог всех транзакций. Его подмена или удаление может скрыть следы взлома или мошеннических операций из-за чего возникает потеря целостности данных и возможности для аудита.

<h3>2. Event Sourcing</h3>

Event Sourcing - это паттерн, при котором изменения состояния приложения хранятся как последовательность событий. Это не только позволяет восстановить текущее состояние системы, но и воспроизвести историю изменений.

Основные концепции:
- Событие (Event): Факт, что что-то произошло в системе. События неизменяемы (immutable). Их нельзя удалить или изменить после сохранения.
- Поток событий (Event Stream): Упорядоченный список всех событий, относящихся к одному агрегату (например, к конкретному заказу или пользователю). Это источник истины.
- Агрегат (Aggregate): Кластер связанных объектов, которые рассматриваются как единое целое. Именно агрегат обрабатывает команды и порождает новые события.
- Команда (Command): Запрос на выполнение действия (например, WithdrawMoney). Если команда валидна, агрегат генерирует соответствующее событие (например, MoneyWithdrawn).
- Проекция (Projection): Механизм, который обрабатывает поток событий и создает из него "читаемые модели" (Read Models), оптимизированные для конкретных запросов (например, "последние 10 транзакций", "общий баланс по всем счетам").
- Event Store: Специализированное хранилище для событий. Оно append-only (данные только добавляются в конец), оптимизировано для записи и чтения последовательностей событий.

Рабочий цикл:
1. Клиент отправляет Команду (например, "Измeнить статус заказа на 'Выполнен'").
2. Система загружает все прошлые События для этого агрегата (заказа) из Event Store.
3. Воссоздается текущее состояние агрегата путем применения всех событий.
4. Агрегат проверяет, может ли команда быть выполнена. Если да, он генерирует новое Событие (OrderCompleted).
5. Новое событие сохраняется в Event Store.
6. Событие публикуется, и все заинтересованные Проекции обновляют свои Read Models.

Преимущества:
- Полный аудит и трассируемость: Есть полная, достоверная история всех изменений в системе.
- Временные запросы: Можно откатить время назад и посмотреть, как выглядела система в любой момент в прошлом.
- Гибкость чтения: Проекции позволяют создавать любое представление данных под конкретные нужды UI или отчетов, не затрагивая способ записи.
- Согласованность в распределенных системах: События — это идеальный механизм для интеграции между различными микросервисами.
- Отказоустойчивость: Поскольку события неизменяемы, их можно повторно обработать в случае сбоя, чтобы восстановить состояние.
- Моделирование сложной бизнес-логики: Паттерн отлично сочетается с DDD (Domain-Driven Design), так как заставляет думать в терминах событий и инвариантов предметной области.

Недостатки:
- Производительность запросов: Получение текущего состояния агрегата требует воспроизведения всех его событий (это можно оптимизировать с помощью снапшотов — периодического сохранения текущего состояния).
- Миграция данных: Изменение структуры событий в будущем — нетривиальная задача. Требуются стратегии апгрейда (upcasting) или дублирования потоков.
- Eventual Consistency Read Models: Проекции обновляются асинхронно, поэтому между записью события и его отображением в отчете или UI может быть небольшая задержка. Это усложняет логику на клиенте.
- Потенциально большой объем данных: Event Store может расти очень быстро, но на практике это решается архивацией и компрессией старых данных.
- Выбор гранулярности событий: Слишком мелкие события ведут к большому количеству, слишком крупные — к потере семантики и сложности обработки.

<h4>Типы событий</h4>

По уровню абстракции:
- Системные события: Отражают технические изменения (например, `UserSessionStarted`, `CacheInvalidated`). Реже используются в чистом ES, где фокус на бизнесе.
- События предметной области (Domain Events): Самый важный тип. Они выражают факт из бизнес-логики. Названия обычно в прошедшем времени и на языке бизнеса: `OrderSubmitted`, `PaymentReceived`, `InventoryItemDeactivated`.

По характеру данных:
- Фактоидные события: Содержат все данные, необходимые для описания факта (`PaymentReceived { orderId: 123, amount: 99.99, method: "card", date: "..." }`).
- Дельта-события: Отражают изменение величины. Например, `ProductPriceChanged { delta: -5.00 }` (цена уменьшилась на 5). Такие события сложнее, так как для восстановления состояния нужно знать предыдущее значение.

По цели в жизненном цикле агрегата:
- События-создатели: События, которые инициируют жизненный цикл агрегата (`AccountOpened`, `OrderCreated`).
- События-изменители: Меняют состояние существующего агрегата (`AddressUpdated`, `ItemAddedToOrder`).
- События-завершители: Делают агрегат неактивным или завершают его жизнь (`AccountClosed`, `OrderCancelled`).

<h4>Восстановление состояния системы</h4>

Базовый процесс:
1. Извлечение потока событий: Система обращается к Event Store и запрашивает все события для конкретного агрегата (например, все события с AggregateId = Order-123), упорядоченные по версии или времени.
2. Создание экземпляра агрегата: Создается новый, "пустой" объект агрегата.
3. Применение событий: Для каждого события в потоке, начиная с самого старого, вызывается метод Apply агрегата, который обновляет его внутреннее состояние.

Псевдокод:
```python
events = [
    AccountOpened(account_id=1, initial_deposit=100),
    DepositPerformed(account_id=1, amount=50),
    WithdrawalPerformed(account_id=1, amount=30)
]

account = BankAccount(account_id=1)
for event in events:
    account.apply(event) # Внутри этого метода состояние обновляется
print(account.balance)   # Выведет: 120 (100 + 50 - 30)
```

С использованием снапшота:
1. Система периодически (например, каждые 100 событий или при достижении определенного возраста агрегата) создает снапшот.
2. Снапшот сохраняется в отдельном хранилище (часто в том же Event Store) вместе с версией агрегата, на которую он был сделан.
3. При следующем запросе на восстановление агрегата:
  - Система сначала загружает последний снапшот.
  - Затем загружает и применяет только те события, которые произошли после версии снапшота.

Псевдокод:
```python
snapshot = event_store.load_snapshot("Order-123")
order = snapshot.data

# Загружаем события с версии 5001 по 10000.
events = event_store.load_events("Order-123", from_version=5001)

for event in events:
    order.apply(event)
```

<h4>Управление версиями событий</h4>

Поскольку события неизменяемы, а бизнес-логика эволюционирует, структура наших событий со временем будет меняться. Например, есть событие CustomerAddressChangedV1 с полем street_name. Через год нужно хранить отдельно street_name и building_number. Нужно создать новую версию события CustomerAddressChangedV2. Но в Event Store уже сохранены тысячи событий старого формата. Система должна уметь читать и обрабатывать их все.

Стратегии:
- Несовместимые изменения (Самый простой, но негибкий способ): Структура события изменяется полностью и обновляется весь код, который его обрабатывает. Приемлимо только на ранних этапах разработки, так как старые события становятся нечитаемыми для новой версии системы.
- Добавление новых полей (Обратно-совместимые изменения): новые поля добавляются как необязательные (optional/nullable). Старый код, не знающий об этих полях, сможет проигнорировать их. Новый код должен корректно обрабатывать их отсутствие. Пример: В `CustomerAddressChangedV1` было `street: String`. В V2 мы добавляем `house_number: String?`. Старые события будут иметь `house_number = null`.
- Апкастинг (Upcasting): Это процесс преобразования события старой версии в событие новой версии при чтении из Event Store. Пишутся специальные скрипты-конвертеры, извлекающие данные из старой версии и преобразующие в новую версию. Преимущество заключается в том, что Бизнес-логика агрегата работает только с актуальной версией события, а недостаток в сложности чтения данных.
- Дублирование потока событий (Наиболее надежный, но сложный способ): Когда требуется кардинальное изменение, создается новый поток событий для агрегата. Старый поток замораживается, а все новые изменения пишутся в новый поток. Это похоже на создание новой ветки в системе контроля версий. Используется в очень редких случаях, когда предыдущие стратегии не работают, например, при фундаментальном изменении бизнес-процесса.