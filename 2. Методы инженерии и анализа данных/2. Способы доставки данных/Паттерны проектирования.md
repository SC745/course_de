<h2>Паттерны проектирования</h2>

В области инженерии данных широко применяются различные паттерны проектирования, которые помогают решать стандартные задачи интеграции данных. Паттерны, такие как Change Data Capture (CDC), Event Sourcing и Command Query Responsibility Segregation (CQRS), обеспечивают надежные и масштабируемые подходы к обработке и анализу данных.

<h3>1. Сhange Data Capture</h3>

Change Data Capture (CDC) — это методология и набор шаблонов проектирования программного обеспечения, которые позволяют выявлять и отслеживать изменения в данных в системе-источнике (например, в базе данных) и доставлять эти изменения в другие системы или процессы в режиме, близком к реальному времени. CDC играет ключевую роль в построении реактивных, событийно-ориентированных и слабосвязанных систем. Он является "кровеносной системой" для данных, обеспечивая их непрерывный поток из систем-источников в системы-потребители.

Вместо того чтобы периодически опрашивать всю базу данных на предмет изменений (например, с помощью `SELECT ... WHERE last_modified > ...`), CDC захватывает каждое изменение (`INSERT`, `UPDATE`, `DELETE`) непосредственно в момент его совершения.

Преимущества:
- Асинхронность и производительность: Источник данных (OLTP-база) не блокируется и не нагружается дополнительными запросами от многочисленных потребителей. Изменения доставляются асинхронно, что сохраняет высокую производительность транзакционных систем.
- Доставка в реальном времени (Near Real-Time): Потребители получают данные практически мгновенно после их изменения в источнике. Это критически важно для систем мониторинга, аналитики в реальном времени и мгновенных уведомлений.
- Надежность и полнота данных: Захватываются все изменения, включая удаления. Подход на основе лога гарантирует, что ни одно изменение не будет пропущено, так как он является единственным источником истины для транзакций.
- Упрощение интеграции: CDC предоставляет стандартизированный способ потоковой передачи изменений данных. Вместо того чтобы создавать уникальные интеграции для каждой системы, можно настроить единый CDC-конвейер, и все подписчики будут получать одинаково форматированные события.
- Поддержка современных архитектурных паттернов.

Инструменты для реализации:
- Debezium: Распространенная платформа с открытым исходным кодом, построенная поверх Apache Kafka. Использует коннекторы для разных БД, которые считывают журналы транзакций и публикуют события в топики Kafka в формате JSON/Avro.
- Oracle GoldenGate / Oracle LogMiner: Промышленное решение для Oracle, GoldenGate — мощный инструмент для репликации данных в реальном времени.
- SQL Server Change Data Capture / Change Tracking: Встроенные функции MS SQL Server для отслеживания изменений.
- PostgreSQL Logical Decoding: Низкоуровневый API для доступа к содержимому WAL. Именно его используют такие инструменты, как Debezium, для работы с PostgreSQL.
- AWS Database Migration Service (DMS): Позволяет настраивать непрерывную репликацию данных из популярных баз данных в различные цели в AWS (S3, Redshift, Kinesis).
- AWS Glue Streaming ETL: Может использовать собственные коннекторы для CDC.
- Google Cloud Dataflow: Позволяет создавать конвейеры потоковой обработки, которые могут включать в себя шаг CDC через коннекторы или пользовательский код.
- Azure Data Factory: Имеет возможности для потокового копирования данных, которые можно использовать для сценариев CDC.

Сложности реализации в распределенных системах:
- Гарантия доставки "точно один раз" (Exactly-Once Semantics): Необходимо координировать работу между чтением лога БД-источника и подтверждением записи в систему-назначение (например, Kafka). Если процессор CDC упал после обработки изменения, но до его отправки, при перезапуске оно может быть обработано повторно.
- Управление схемой данных (Schema Evolution): Все потребители событий CDC должны быть способны обработать новую версию сообщения. Без четкой стратегии это приводит к поломке конвейеров.
- Масштабирование и производительность: Высоконагруженная БД может генерировать огромный поток изменений. Один узел обработки CDC может не справиться. Параллельная обработка событий из лога, который по своей природе является последовательным (упорядоченным), сложна. Неправильное распределение может привести к нарушению порядка событий для одной и той же строки.
- Мониторинг и обработка сбоев: Если потребитель "отстает" от источника или ломается, это может привести к лавине необработанных сообщений или потере данных. Необходимо отслеживать лаг репликации (разницу между последним изменением в источнике и последним обработанным событием). Также нужно иметь механизмы для повторной обработки данных с определенного момента (replay).
- Влияние на источник (нагрузка): Даже чтение лога создает нагрузку на источник. При высоком RPS (числе операций в секунду) это может стать проблемой. В распределенной системе с множеством БД и коннекторов CDC необходимо централизованно управлять нагрузкой, чтобы не "положить" источники данных.

Проблемы безопасности:
- Несанкционированный доступ к конфиденциальным данным: CDC по своей сути захватывает все изменения, включая вставки и обновления конфиденциальных данных. Злоумышленник, получивший доступ к потоку событий CDC (например, к топику Kafka), получает полную копию всех данных базы в реальном времени, минуя механизмы аутентификации и авторизации самого приложения.
- Отсутствие контроля доступа на уровне строк (Row-Level Security): В приложении может быть реализована сложная логика разрешений (например, пользователь видит только свои заказы). CDC-поток обходит эту логику, передавая данные всех пользователей сразу. Потребитель CDC-потока, который не реализует такую же логику авторизации, получит несанкционированный доступ к данным.
- Неизменяемость и аудит логов: Поток событий CDC — это, по сути, лог всех транзакций. Его подмена или удаление может скрыть следы взлома или мошеннических операций из-за чего возникает потеря целостности данных и возможности для аудита.

<h3>2. Event Sourcing</h3>

Event Sourcing - это паттерн, при котором изменения состояния приложения хранятся как последовательность событий. Это не только позволяет восстановить текущее состояние системы, но и воспроизвести историю изменений.

Основные концепции:
- Событие (Event): Факт, что что-то произошло в системе. События неизменяемы (immutable). Их нельзя удалить или изменить после сохранения.
- Поток событий (Event Stream): Упорядоченный список всех событий, относящихся к одному агрегату (например, к конкретному заказу или пользователю). Это источник истины.
- Агрегат (Aggregate): Кластер связанных объектов, которые рассматриваются как единое целое. Именно агрегат обрабатывает команды и порождает новые события.
- Команда (Command): Запрос на выполнение действия (например, WithdrawMoney). Если команда валидна, агрегат генерирует соответствующее событие (например, MoneyWithdrawn).
- Проекция (Projection): Механизм, который обрабатывает поток событий и создает из него "читаемые модели" (Read Models), оптимизированные для конкретных запросов (например, "последние 10 транзакций", "общий баланс по всем счетам").
- Event Store: Специализированное хранилище для событий. Оно append-only (данные только добавляются в конец), оптимизировано для записи и чтения последовательностей событий.

Рабочий цикл:
1. Клиент отправляет Команду (например, "Измeнить статус заказа на 'Выполнен'").
2. Система загружает все прошлые События для этого агрегата (заказа) из Event Store.
3. Воссоздается текущее состояние агрегата путем применения всех событий.
4. Агрегат проверяет, может ли команда быть выполнена. Если да, он генерирует новое Событие (OrderCompleted).
5. Новое событие сохраняется в Event Store.
6. Событие публикуется, и все заинтересованные Проекции обновляют свои Read Models.

Преимущества:
- Полный аудит и трассируемость: Есть полная, достоверная история всех изменений в системе.
- Временные запросы: Можно откатить время назад и посмотреть, как выглядела система в любой момент в прошлом.
- Гибкость чтения: Проекции позволяют создавать любое представление данных под конкретные нужды UI или отчетов, не затрагивая способ записи.
- Согласованность в распределенных системах: События — это идеальный механизм для интеграции между различными микросервисами.
- Отказоустойчивость: Поскольку события неизменяемы, их можно повторно обработать в случае сбоя, чтобы восстановить состояние.
- Моделирование сложной бизнес-логики: Паттерн отлично сочетается с DDD (Domain-Driven Design), так как заставляет думать в терминах событий и инвариантов предметной области.

Недостатки:
- Производительность запросов: Получение текущего состояния агрегата требует воспроизведения всех его событий (это можно оптимизировать с помощью снапшотов — периодического сохранения текущего состояния).
- Миграция данных: Изменение структуры событий в будущем — нетривиальная задача. Требуются стратегии апгрейда (upcasting) или дублирования потоков.
- Eventual Consistency Read Models: Проекции обновляются асинхронно, поэтому между записью события и его отображением в отчете или UI может быть небольшая задержка. Это усложняет логику на клиенте.
- Потенциально большой объем данных: Event Store может расти очень быстро, но на практике это решается архивацией и компрессией старых данных.
- Выбор гранулярности событий: Слишком мелкие события ведут к большому количеству, слишком крупные — к потере семантики и сложности обработки.

<h4>Типы событий</h4>

По уровню абстракции:
- Системные события: Отражают технические изменения (например, `UserSessionStarted`, `CacheInvalidated`). Реже используются в чистом ES, где фокус на бизнесе.
- События предметной области (Domain Events): Самый важный тип. Они выражают факт из бизнес-логики. Названия обычно в прошедшем времени и на языке бизнеса: `OrderSubmitted`, `PaymentReceived`, `InventoryItemDeactivated`.

По характеру данных:
- Фактоидные события: Содержат все данные, необходимые для описания факта (`PaymentReceived { orderId: 123, amount: 99.99, method: "card", date: "..." }`).
- Дельта-события: Отражают изменение величины. Например, `ProductPriceChanged { delta: -5.00 }` (цена уменьшилась на 5). Такие события сложнее, так как для восстановления состояния нужно знать предыдущее значение.

По цели в жизненном цикле агрегата:
- События-создатели: События, которые инициируют жизненный цикл агрегата (`AccountOpened`, `OrderCreated`).
- События-изменители: Меняют состояние существующего агрегата (`AddressUpdated`, `ItemAddedToOrder`).
- События-завершители: Делают агрегат неактивным или завершают его жизнь (`AccountClosed`, `OrderCancelled`).

<h4>Восстановление состояния системы</h4>

Базовый процесс:
1. Извлечение потока событий: Система обращается к Event Store и запрашивает все события для конкретного агрегата (например, все события с AggregateId = Order-123), упорядоченные по версии или времени.
2. Создание экземпляра агрегата: Создается новый, "пустой" объект агрегата.
3. Применение событий: Для каждого события в потоке, начиная с самого старого, вызывается метод Apply агрегата, который обновляет его внутреннее состояние.

Псевдокод:
```python
events = [
    AccountOpened(account_id=1, initial_deposit=100),
    DepositPerformed(account_id=1, amount=50),
    WithdrawalPerformed(account_id=1, amount=30)
]

account = BankAccount(account_id=1)
for event in events:
    account.apply(event) # Внутри этого метода состояние обновляется
print(account.balance)   # Выведет: 120 (100 + 50 - 30)
```

С использованием снапшота:
1. Система периодически (например, каждые 100 событий или при достижении определенного возраста агрегата) создает снапшот.
2. Снапшот сохраняется в отдельном хранилище (часто в том же Event Store) вместе с версией агрегата, на которую он был сделан.
3. При следующем запросе на восстановление агрегата:
  - Система сначала загружает последний снапшот.
  - Затем загружает и применяет только те события, которые произошли после версии снапшота.

Псевдокод:
```python
snapshot = event_store.load_snapshot("Order-123")
order = snapshot.data

# Загружаем события с версии 5001 по 10000.
events = event_store.load_events("Order-123", from_version=5001)

for event in events:
    order.apply(event)
```

<h4>Управление версиями событий</h4>

Поскольку события неизменяемы, а бизнес-логика эволюционирует, структура наших событий со временем будет меняться. Например, есть событие CustomerAddressChangedV1 с полем street_name. Через год нужно хранить отдельно street_name и building_number. Нужно создать новую версию события CustomerAddressChangedV2. Но в Event Store уже сохранены тысячи событий старого формата. Система должна уметь читать и обрабатывать их все.

Стратегии:
- Несовместимые изменения (Самый простой, но негибкий способ): Структура события изменяется полностью и обновляется весь код, который его обрабатывает. Приемлимо только на ранних этапах разработки, так как старые события становятся нечитаемыми для новой версии системы.
- Добавление новых полей (Обратно-совместимые изменения): новые поля добавляются как необязательные (optional/nullable). Старый код, не знающий об этих полях, сможет проигнорировать их. Новый код должен корректно обрабатывать их отсутствие. Пример: В `CustomerAddressChangedV1` было `street: String`. В V2 мы добавляем `house_number: String?`. Старые события будут иметь `house_number = null`.
- Апкастинг (Upcasting): Это процесс преобразования события старой версии в событие новой версии при чтении из Event Store. Пишутся специальные скрипты-конвертеры, извлекающие данные из старой версии и преобразующие в новую версию. Преимущество заключается в том, что Бизнес-логика агрегата работает только с актуальной версией события, а недостаток в сложности чтения данных.
- Дублирование потока событий (Наиболее надежный, но сложный способ): Когда требуется кардинальное изменение, создается новый поток событий для агрегата. Старый поток замораживается, а все новые изменения пишутся в новый поток. Это похоже на создание новой ветки в системе контроля версий. Используется в очень редких случаях, когда предыдущие стратегии не работают, например, при фундаментальном изменении бизнес-процесса.

<h3>3. Command Query Responsibility Segregation</h3>

Основная идея CQRS - разделить операции чтения данных (Queries) и операции изменения данных (Commands) на разные модели. В традиционном CRUD-подходе (Create, Read, Update, Delete) мы используется одна и та же модель данных для всех операций. Это создает компромиссы:
- Модель оптимизирована для записи, но неэффективна для сложных запросов (много JOIN-ов).
- Модель оптимизирована для чтения, но избыточна и неудобна для валидации и бизнес-логики при записи.

Возникают конфликты блокировок при одновременных чтениях и записях. CQRS решает эти проблемы, предлагая использовать разные модели для разных целей:
- Команда (Command) — это операция, которая изменяет состояние системы. Например: `RegisterUserCommand`, `UpdateOrderAddressCommand`, `ShipOrderCommand`. Команды не возвращают данных (кроме, возможно, статуса выполнения или ID). Они только меняют состояние.
- Запрос (Query) — это операция, которая читает и возвращает данные, не изменяя состояние системы. Например: `GetUserByIdQuery`, `GetRecentOrdersQuery`.

Основные компоненты:
- Команда (Command): Объект, описывающий намерение изменить что-либо в системе. Это не просто данные, а DTO (Data Transfer Object), который несет в себе смысл действия. Именуется в повелительном наклонении (`CreateUser`, `CancelOrder`). Обрабатывается ровно одним обработчиком.Не возвращает данных (void), но может возвращать статус (успех/ошибка) или ID созданной сущности, но не сами данные.
- Обработчик команды (Command Handler): Компонент, который получает команду, выполняет всю необходимую бизнес-логику и вносит изменения в write-модель (модель записи). Ответственности: валидация команды, извлечение агрегата (Aggregate Root) из базы, вызов методов агрегата для изменения его состояния, сохранение обновленного агрегата обратно в базу.
- Запрос (Query): Объект, описывающий намерение запросить данные. Он определяет критерии выборки. Именуется как вопрос (`GetUserDetails`, `FindProductsByCategory`). Обрабатывается ровно одним обработчиком, Не изменяет данные.
- Обработчик запроса (Query Handler): Компонент, который получает запрос и возвращает данные из read-модели (модели чтения). Выполняет быстрые запросы к оптимизированному источнику данных (например, к денормализованной SQL-таблице или к NoSQL-базе), маппинг результата в DTO, идеально подходящий для клиента (например, для веб-страницы).
- Write-модель (Модель записи): Модель данных, оптимизированная для записи и обеспечения целостности данных. Часто строится вокруг Доменно-Ориентированного Проектирования (DDD) и Агрегатов. Содержит всю бизнес-логику и инварианты. Обычно хранится в нормализованном виде в реляционной или документной БД.
- Read-модель (Модель чтения): Модель данных, оптимизированная для быстрого и удобного чтения. Представляет собой денормализованные проекции данных из write-модели. Структура read-модели полностью зависит от потребностей UI/клиента. Например, одна таблица может содержать все данные для отображения целой страницы, чтобы избежать JOIN-ов. Может храниться в том же источнике, что и write-модель (но в других таблицах), или в совершенно другой системе (кеш, Elasticsearch, отдельная NoSQL БД).

<h4>Синхронизация данных</h4>

Синхронизация данных между write-моделью (где происходят изменения) и read-моделью (откуда читаются данные) — это сердцевина CQRS. Существует два основных подхода, которые определяют степень согласованности данных.

Синхронизация в рамках транзакции - подходит для простых систем с низкой нагрузкой на запись, где строгая согласованность является критическим требованием:
1. Открывается транзакция.
2. Обработчик команды вносит изменения в агрегат в write-хранилище.
3. Тот же обработчик немедленно обновляет соответствующие проекции в read-хранилище (например, обновляет денормализованную таблицу).
4. Транзакция коммитится.

Преимущества:
- Строгая согласованность (Strong Consistency): Read-модель всегда актуальна и немедленно отражает изменения из write-модели. Нет задержек.
- Простота понимания: логика прямолинейна, так как обновление происходит в одном месте.

Недостатки:
- Производительность: Запись становится медленнее, так как нужно обновлять две разные модели в одной транзакции. Это может создать узкое горло.
- Связность: Write-модель и read-модель жестко связаны. Любое изменение в структуре read-модели может потребовать изменений в коде команд.
- Масштабируемость: Трудно масштабировать write- и read-стороны независимо, так как они используют одну транзакцию.

Асинхронная синхронизация через события - используется практически во всех сложных и высоконагруженных системах, где можно смириться с небольшой задержкой в согласованности:
1. Обработчик команды обновляет агрегат в write-хранилище.
2. Агрегат генерирует одно или несколько событий предметной области (Domain Events).
3. Эти события сохраняются (часто вместе с агрегатом, если используется Event Sourcing) и публикуются в шину событий.
4. Обработчики событий (Event Handlers), подписанные на эти события, асинхронно получают их.
5. Каждый обработчик события обновляет свою часть read-модели, выполняя запросы к read-хранилищу.

Преимущества:
- Развязка: Write- и read-стороны полностью разделены и общаются только через события, что позволяет развивать их независимо.
- Производительность: Команды выполняются очень быстро, так как им не нужно ждать обновления read-модели.
- Гибкость и масштабируемость: Легко добавить новую read-модель или изменить существующую, просто создав новый обработчик событий. Write- и read-стороны можно масштабировать независимо.
- Устойчивость: Если read-модель временно недоступна, события могут накапливаться в очереди и будут обработаны после ее восстановления.

Недостатки:
- Согласованность: Read-модель может отставать от write-модели на миллисекунды или даже секунды. Это означает, что пользователь, только что отправивший команду, может не сразу увидеть изменения при последующем запросе.
- Сложность: Архитектура становится сложнее. Нужно управлять шиной событий, обработчиками, повторными попытками и решать проблемы идемпотентности.

<h4>Оптимизация производительности</h4>

CQRS сам по себе является мощным инструментом оптимизации, но он также открывает дорогу для дополнительных стратегий повышения производительности, особенно на стороне чтения.

Оптимизация Read-модели:
- Денормализация: Вместо множества JOIN-ов между нормализованными таблицами данные предварительно объединяются и сохраняются в одной структуре. Запрос на чтение выполняется к этой структуре, что резко ускоряет его.
- Специализированные хранилища данных (Polyglot Persistence): Можно выбрать базу данных, идеально подходящую для конкретных задач чтения. Например, Elasticsearch для полнотекстового поиска и сложных фильтров, Redis для кеширования часто запрашиваемых данных или в качестве основной read-модели, если данные помещаются в память, колоночные БД для аналитических запросов и отчетности, требующих агрегации больших объемов данных.
- Материализованные представления (Materialized Views): Сохраненные результаты запроса, которые можно периодически обновлят как аналог денормализованной таблицы, управляемый на уровне БД.
- Несколько read-моделей: Для разных сценариев использования можно создать разные read-модели, каждая из которых оптимизирована под свою задачу.

Оптимизация Write-модели:
- Фокусировка на целостности: Write-модель освобождается от бремени обслуживания запросов. Ее можно оптимизировать исключительно для быстрой и безопасной записи, используя нормализованную схему и блокировки только там, где это действительно необходимо.
- Event Sourcing: Этот паттерн часто используется вместе с CQRS. Вместо сохранения текущего состояния агрегата сохраняется вся последовательность событий, которые к этому состоянию привели.