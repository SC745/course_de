<h2>Основы и интеграция</h2>
<h3>1. Основы ClickHouse</h3>
<h4>Предназначение и основные концепции</h4>

ClickHouse — это колоночная система управления базами данных (СУБД) с открытым исходным кодом, разработанная компанией Yandex для сверхбыстрой аналитической обработки запросов (OLAP — Online Analytical Processing). Её главная задача — выполнять сложные агрегирующие запросы за доли секунды или секунды на объемах данных в петабайты.

Ключевые концепции:
- Колоночное хранение: Данные хранятся не по строкам (как в MySQL, PostgreSQL), а по столбцам. Это фундаментальная особенность, определяющая все преимущества.
- Векторизованная обработка запросов: Запросы выполняются не над отдельными значениями, а над целыми массивами данных (векторами), что максимально эффективно использует возможности современных CPU и кешей.
- Работа с "холодными" и "горячими" данными: Система оптимизирована для хранения огромных объемов данных на медленных дисках (HDD) или в облаке (S3), при этом активно используя кеширование и RAM для скорости.
- Данные вставляются, а не изменяются (в основном): ClickHouse предполагает, что данные в основном пишутся и почти никогда не обновляются или удаляются. Это позволяет применять оптимизации, недоступные для OLTP-систем. Однако с недавних версий поддерживаются легкие обновления и удаления (через мутации).
- Shared-nothing архитектура: Система легко масштабируется горизонтально добавлением новых серверов (шардирование). Каждый сервер независим.

Архитектура:
- SLB (Server Load Balancer): SLB или балансировщик нагрузки обычно используется для распределения входящего трафика между несколькими узлами или серверами в кластере ClickHouse. Это обеспечивает равномерное распределение запросов и повышает доступность и отказоустойчивость системы.
- Shard (Шард): В контексте ClickHouse шард представляет собой подмножество данных, хранящееся на отдельном узле или группе узлов. Шардинг позволяет горизонтально масштабировать данные, поскольку запросы могут выполняться параллельно на разных шардах. Это особенно важно для больших объемов данных и высокопроизводительных вычислений.
- Процессоры запросов: Это компоненты, которые обрабатывают SQL-запросы, исполняя операции над данными, хранящимися в базе. Особое внимание в ClickHouse уделяется эффективности обработки больших объемов данных, что достигается через использование векторных запросов.
- ECS (Elastic Compute Service): ECS обычно относится к виртуальным машинам или экземплярам, предоставляемым в облачных сервисах, таких как Alibaba Cloud, AWS или Google Cloud. В контексте ClickHouse, ECS может быть использован для развертывания и управления инстансами ClickHouse.
- Cloud Disk: Это облачное дисковое хранилище, используемое для хранения данных. В архитектуре ClickHouse облачные диски могут использоваться для хранения данных таблиц, журналов и резервных копий.
- Табличные движки: MergeTree - для вставки и выборки, Log - для быстрой записи, Integration Engines - для интеграции с внешними системами, Special Engines = для специализированных задач

Преимущества:
- Чтение только нужных столбцов: Если запросу нужно 5 полей из 100, с диска будет прочитано только 5 столбцов. В строчной базе пришлось бы читать всю строку со всеми 100 полями.
- Эффективное сжатие: Данные в одном столбце обычно однородны (числа, даты, строки), что позволяет сжимать их в десятки-сотни раз лучше, чем разнородные данные в строке.
- Векторизация: Операции над целыми массивами (векторами) данных минимизируют накладные расходы и лучше используют CPU.
- Экономия ресурсов ввода-вывода (I/O) и хранилища: Меньший объем данных, считываемый с диска + лучшее сжатие = меньше нагрузка на диск и сеть (в распределенном кластере).
- Оптимизация под агрегацию и сканирование: Агрегатные функции выполняются последовательно в памяти для целых столбцов, что очень быстро. Легко добавляются новые индексы (пропускающие индексы) для конкретных столбцов без перестройки всей таблицы.
- Поддержка сложных аналитических функций: Оконные функции, приблизительные вычисления (например, `uniq`), вероятностные структуры данных (HyperLogLog), работа с временными рядами "из коробки".

Недостатки (обратная сторона преимуществ):
- Низкая производительность на точечных запросах (`SELECT` по одному ключу) и частых обновлениях (OLTP).
- Сложности с транзакционностью и согласованностью в реальном времени.
- Запросы `JOIN` работают иначе, чем в OLTP-базах, и требуют правильного проектирования данных (часто предпочитается денормализация).

<h4>Системные требования и установка</h4>

Поддерживаемые ОС:
- Linux: Наиболее предпочтительная и поддерживаемая платформа. Официально поддерживаются Ubuntu (начиная с 18.04), Debian (начиная с 9), CentOS (7 и 8) и RHEL (7 и 8) Также работает на других дистрибутивах (Fedora, OpenSUSE, ALT Linux и др.)
- macOS: Поддерживается для разработки, но не для production.
- FreeBSD: Экспериментальная поддержка.
- Windows: Не поддерживается нативно, но может быть запущен в Docker или WSL2 (Windows Subsystem for Linux).

Системные требования:
- Память (RAM): Минимум 4 ГБ, но для production-нагрузок рекомендуется от 64 ГБ и более. ClickHouse использует память для обработки запросов, особенно для JOIN и агрегаций.
- Процессор: Современный многоядерный процессор (ClickHouse эффективно использует многопоточность).
- Диск: Предпочтительно SSD или NVMe для высоких нагрузок. HDD подойдут для хранения больших объемов холодных данных. Объем зависит от объема данных и степени сжатия (сжатие может достигать 20-30 раз).
- Файловая система: Рекомендуется ext4 (для Linux) или xfs. Важно отключить atime для ускорения чтения.
- Сеть: Высокая пропускная способность для распределенных кластеров.

Перед установкой ClickHouse необходимо добавить репозиторий ClickHouse в список источников пакетов системы:
```bash
sudo apt-get install apt-transport-https ca-certificates dirmngr
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4    # добавление GPG ключа
echo "deb https://repo.clickhouse.com/deb/stable/ main/" | sudo tee /etc/apt/sources.list.d/clickhouse.list
```

После добавления репозитория нужно обновить информацию о пакетах и установить ClickHouse:
```bash
sudo apt-get update
sudo apt-get install clickhouse-server clickhouse-client
```

После установки ClickHouse сервер можно запустить следующей командой:
```bash
sudo service clickhouse-server start
```

Для проверки успешной установки и работоспособности ClickHouse можно подключиться к серверу с помощью клиента ClickHouse:
```bash
clickhouse-client
```

<h4>Основные команды</h4>

Управление сервером:
```bash
sudo systemctl start clickhouse-server                           # Запуск сервера
sudo systemctl stop clickhouse-server                            # Остановка сервера
sudo systemctl restart clickhouse-server                         # Перезагрузка сервера
sudo systemctl status clickhouse-server                          # Проверка статуса
sudo tail -f /var/log/clickhouse-server/clickhouse-server.log    # Просмотр логов

```

Конфигурация сервера:
- Основной конфигурационный файл: `/etc/clickhouse-server/config.xml`
- Пользовательские настройки: `/etc/clickhouse-server/config.d/`

Конфигурация пользователей и прав доступа: Файлы в `/etc/clickhouse-server/users.xml` и `/etc/clickhouse-server/users.d/`

Команды `clickhouse-client`:
```bash
clickhouse-client               # Запуск клиента:
clickhouse-client --password    # Если установлен пароль
clickhouse-client --host=example.com --port=9000 --user=username --password    # Подключение к удаленному серверу
clickhouse-client --query="SELECT 1"                            # Выполнение запроса из командной строки
clickhouse-client < queries.sql                                 # Выполнение запроса из файла
clickhouse-client --format=Pretty                               # Форматирование вывода
clickhouse-client --multiquery --query="SELECT 1; SELECT 2;"    # Многозапросный режим
clickhouse-client --max_memory_usage=1000000000                 # Настройки в клиенте

```

<h4>Параллелизация запросов</h4>

ClickHouse использует несколько уровней параллелизма для ускорения обработки запросов. Уровни параллелизма:
- Многопоточность на одном узле (на уровне одного запроса): ClickHouse может параллельно читать данные из нескольких кусков (parts) таблицы. Каждый поток может обрабатывать свой кусок. При агрегации данных ClickHouse использует параллельную обработку. Частичные результаты агрегации из разных потоков затем объединяются (merge). Настройки: `max_threads` (максимальное количество потоков для обработки запроса, по умолчанию равно количеству ядер CPU) и `max_block_size` (размер блока для обработки).
- Распределенная обработка (на уровне кластера): При работе с распределенной таблицей (Distributed engine) запрос параллельно выполняется на всех шардах (или на части, в зависимости от условий). Координатор (нода, на которую пришел запрос) отправляет подзапросы на все шарды, дожидается ответов и выполняет финальную агрегацию (если требуется). Если в запросе есть `GROUP BY`, то агрегация сначала выполняется на каждом шарде, а затем на координаторе происходит финальное объединение. Иногда, если данные уже сгруппированы по ключу шардирования, можно использовать настройку `distributed_group_by_no_merge` для отключения финальной агрегации.
- Векторизованное выполнение (на уровне CPU): ClickHouse обрабатывает данные не по одному значению, а по блокам (столбцам) данных, используя SIMD-инструкции процессора. Это позволяет эффективно использовать кэш CPU и выполнять операции над множеством значений за одну инструкцию. При чтении с диска ClickHouse использует асинхронный ввод-вывод и может параллельно читать данные с нескольких дисков.

Пример настройки параллелизма:
sql
```sql
-- Установить максимальное количество потоков для выполнения запроса
SET max_threads = 16;

-- Для распределенных запросов можно управлять параллельностью на уровне шардов
SET distributed_aggregation_memory_efficient = 1;
SET group_by_two_level_threshold = 1000000;

```
Советы по оптимизации параллелизма:
- Не устанавливать `max_threads` слишком высоким, так как это может привести к конкуренции за ресурсы и снижению производительности. Обычно достаточно количества ядер CPU.
- Для распределенных запросов важно, чтобы данные были равномерно распределены по шардам, чтобы избежать ситуации, когда один шард обрабатывает значительно больше данных, чем другие (skew).
- Использовать настройки для управления памятью и параллелизмом при агрегации, такие как `max_bytes_before_external_group_by` (для внешней сортировки на диске при нехватке памяти) и `distributed_aggregation_memory_efficient`.

<h4>Способы вставки данных</h4>

Классический `INSERT`: Подходит для небольших вставок (тысячи строк):
```sql
INSERT INTO table_name (col1, col2) VALUES (v1, v2), (v3, v4), ...
```

Пакетная вставка (`INSERT SELECT`):
```sql
INSERT INTO table_name SELECT ...
```

Вставка данных из файлов (наиболее распространённый способ):
```sql
clickhouse-client --query="INSERT INTO table_name FORMAT CSVWithNames" < data.csv    # Из локального файла
INSERT INTO table_name FROM INFILE '/path/to/data.csv' FORMAT CSV                    # Из файла на сервер
```

Использование специальных форматов для больших объёмов:
```sql
clickhouse-client --query="SELECT * FROM source_table" --format Native | clickhouse-client --query="INSERT INTO dest_table FORMAT Native" # Native формат
INSERT INTO table_name FROM INFILE 'data.parquet' FORMAT Parquet    # Parquet, ORC, Avro
```

Потоковая вставка (для интеграций):
- Нативные протоколы: Библиотеки для Python (clickhouse-driver), Java, Go и др. используют быстрый бинарный протокол.
- Kafka: С помощью движка Kafka или Materialized View данные автоматически консьюмируются из топика и вставляются в таблицу.
- PostgreSQL, MySQL: Используя движки PostgreSQL или MySQL, можно делать INSERT в ClickHouse, который будет читать данные из внешней БД.

<h4>Резервное копирование и восстановление</h4>

ClickHouse не имеет встроенного полноценного механизма бэкапов как коммерческие СУБД, но есть проверенные подходы:
- Логическое резервное копирование (экспорт данных):
```sql
SELECT * FROM my_table
INTO OUTFILE '/backup/my_table.csv'
FORMAT CSVWithNames
```
Плюсы: Переносимость, сжатие, выбор формата (Parquet, Native).
Минусы: Медленно для огромных объемов, блокирующая операция (для больших таблиц).
- Физическое резервное копирование (файлы данных):
  - Ручное копирование: Остановить запись, скопировать директорию /var/lib/clickhouse/data/database/table/ и /metadata/. Подходит только для небольших остановок.
  - Снапшоты ФС: Использование LVM, ZFS или btrfs для создания моментальных снимков папки с данными. Требует осторожности.
  - Replication как бэкап: Наличие 2-3 реплик в кластере (движок ReplicatedMergeTree) — лучшая защита от сбоя железа. Но не защищает от человеческой ошибки (случайного DROP TABLE).
- `clickhouse-backup` — де-факто стандарт. Создает полные/инкрементальные бэкапы (данные + схема), умеет работать с S3, GCS, Azure Blob Storage (идеально для хранения), поддерживает шифрование и сжатие, позволяет делать бэкапы без остановки сервера (`--skip-check-parts`). Основные команды:
```bash
clickhouse-backup create my_backup
clickhouse-backup upload my_backup
clickhouse-backup restore my_backup
```

Восстановление данных:
- Из логического бэкапа: `INSERT ... FROM INFILE`.
- Из физического бэкапа: Остановить ClickHouse, восстановить данные и метаданные в соответствующие директории, запустить `sudo clickhouse start --force-recover`. 
- С помощью clickhouse-backup: Команда restore сделает всё автоматически.
- Восстановление таблицы: Если таблица случайно удалена, но данные на диске остались, можно создать таблицу заново с той же структурой и выполнить `ATTACH PARTITION` или переместить данные из папки `detached`.


<h3>2. Интеграция с внешними источниками</h3>
<h4>Основы интеграции</h4>

ClickHouse может работать с внешними данными через несколько механизмов. Основные из них:
- Табличные движки (Table Engines): Позволяют создать таблицу в ClickHouse, которая является "окном" во внешнюю систему. Запросы к такой таблице преобразуются в запросы к внешнему источнику.
  - ODBC / JDBC: Универсальные драйверы для связи с любыми СУБД: PostgreSQL, MySQL, Microsoft SQL Server, Oracle, Greenplum и многими другими. Требуется установить в системе ClickHouse JDBC-драйвер для целевой СУБД. Обычно драйвер помещается в папку `/usr/share/clickhouse/jdbc-drivers/` (или аналогичную, в зависимости от установки) и настроить конфигурацию JDBC-драйверов в ClickHouse (при необходимости).
  - MySQL: Нативный движок для прямого подключения к MySQL/MariaDB.
  - PostgreSQL: Нативный движок для подключения к PostgreSQL.
  - MongoDB: Прямое чтение данных из коллекций MongoDB.
- Файловые движки и виртуальные столбцы: Позволяют запрашивать данные напрямую из файлов в различных форматах, хранящихся как локально, так и в облаке. File, URL, S3 движки поддерживают множество форматов: Parquet, ORC, Arrow, JSONEachRow, CSV, TSV, Avro и др:
  - S3 / URL: Чтение и запись файлов из/в Amazon S3, Google Cloud Storage, Azure Blob Storage и подобных, а также по HTTP/HTTPS URL.
  - HDFS: Прямая работа с файлами в Hadoop Distributed File System.
- Интеграция с системами обмена сообщениями (Message Queues): Позволяет нативно потреблять данные из потоковых систем:
  - Kafka: Движок Kafka для подписки на топики Apache Kafka. Это основной способ потокового приема данных.
  - RabbitMQ: Поддержка RabbitMQ для аналогичных целей.
- Внешние словари (External Dictionaries): Позволяют загружать справочные данные из внешних источников для JOIN-подобных операций. Поддерживаются источники: локальные файлы, HTTP(s), различные СУБД (через ODBC/JDBC), встроенные в CH источники (ClickHouse, MySQL, MongoDB).

Примеры:
```sql
CREATE TABLE my_external_url ENGINE = URL('http://example.com/data.csv', CSV, 'name String, age UInt32')    -- URL
CREATE TABLE kafka_table (name String, age UInt32) ENGINE = Kafka(...) SETTINGS ...                         -- Kafka
CREATE TABLE hdfs_table (...) ENGINE = HDFS('hdfs://namenode:port/path/to/file', 'Parquet')                 -- HDFS
CREATE TABLE jdbc_table (...) ENGINE = JDBC('jdbc:mysql://host:port/db', 'user', 'password', 'table')       -- JDBC
```

Поддерживаемые типы данных:
- PostgreSQL, MySQL: Поддерживают почти все стандартные SQL-типы с автоматическим преобразованием в типы ClickHouse:
  - Числовые: `Int8-Int256`, `UInt8-UInt256`, `Float32`, `Float64`, `Decimal`
  - Строковые: `String`, `FixedString`, `Enum`
  - Дата/время: `Date`, `Date32`, `DateTime`, `DateTime64`
  - Специальные: `UUID`, `IPv4`, `IPv6`
  - Агрегатные: поддерживаются через движок `AggregateFunction`
- MongoDB:
  - `ObjectId` → `String`
  - `Date` → `DateTime`
  - `Number` → `Float64` или `Int64`
  - `Array` → `Array(String)` или вложенные структуры
  - `Document` → `Nested` или `JSON`
- S3, HDFS, URL:
  - Данные в форматах: CSV, TSV, JSONEachRow, Parquet, ORC, Arrow
  - Типы определяются схемой, указанной в запросе `CREATE TABLE`
- Kafka: Зависит от формата сообщений. Чаще используется String для сырых данных или структурированные форматы

Ограничения при работе с внешними источниками:
- Производительность (Самое главное): Данные не хранятся в ClickHouse и не используют его колоночную структуру и индексы (первичный ключ, засечки и т.д.). Каждый запрос выполняется "на лету" с обращением к внешней системе. Это медленно, особенно для агрегаций и `JOIN`. Не подходит для аналитики на больших объемах в реальном времени.
- Ограниченная поддержка DML: Большинство внешних движков поддерживают только чтение. Запись поддерживается лишь для некоторых движков (например, MySQL, PostgreSQL, S3) и часто с ограничениями. Например, вставка в PostgreSQL таблицу работает, но это неэффективно для больших пачек.
- Отсутствие транзакционности и согласованности: Операции не являются атомарными. При сбое во время длительного INSERT через ODBC часть данных может уже быть записана в целевой системе. Чтение данных из внешних источников (особенно СУБД) может приводить к нагрузке на них и влиять на их работу.
- Ограниченная поддержка сложных запросов: Пушдауны (Pushdown) — способность ClickHouse делегировать часть работы (фильтрацию, агрегацию) внешней системе — реализована не для всех движков и не для всех операций. Например, для MySQL движка условие `WHERE` на столбец-ключ может быть отправлено (pushed down) в MySQL, что ускорит запрос. Но для файла в S3 — нет.
- Сложность управления схемой: Изменение схемы данных во внешнем источнике может привести к ошибкам в запросах ClickHouse. Необходимо вручную обновлять DDL внешней таблицы.

Внешние источники данных в ClickHouse можно использовать в запросах, включая операции объединения (`JOIN`) и агрегации (`GROUP BY`). Однако важно помнить об ограничениях производительности, так как данные находятся вне ClickHouse и могут быть обработаны менее эффективно.

Пример `JOIN` внутренней таблицы ClickHouse с внешней таблицей (например, через JDBC):
```sql
SELECT
    local_table.id,
    local_table.value,
    jdbc_table.name
FROM local_table
LEFT JOIN jdbc_table ON local_table.id = jdbc_table.id
```

Пример агрегации данных из внешней таблицы:
```sql
SELECT
    category,
    COUNT(*) as count
FROM mysql_table
GROUP BY category
```

При выполнении таких запросов ClickHouse может пытаться "протолкнуть" некоторые операции (например, фильтрацию) во внешнюю систему, если это поддерживается движком. Однако это зависит от конкретного движка и версии ClickHouse.

Для улучшения производительности рекомендуется:
- По возможности загружать данные из внешних источников во внутренние таблицы ClickHouse (например, с помощью ETL-процессов).
- Использовать внешние источники для относительно небольших объемов данных, особенно для операций `JOIN`.
- Для справочников, которые используются в JOIN, рассмотреть использование внешних словарей (External Dictionaries), которые загружаются в память и могут быть более эффективны.

<h4>Основные команды для работы со внешними источниками</h4>

ClickHouse предоставляет несколько механизмов для работы с внешними данными:
- Файлы (локальные и по HTTP/S3):
```sql
# file(path, format, structure) — чтение из локального файла сервера.
SELECT * FROM file('data.csv', CSV, 'id UInt32, name String')
# url(url, format, structure) — чтение по HTTP/HTTPS.
SELECT * FROM url('https://example.com/data.tsv', TSV, 'column1 String')
# s3(url, access_key_id, secret_access_key, format, structure) — прямое чтение из S3-совместимых хранилищ.
SELECT * FROM s3('https://storage.example.com/my-bucket/data.parquet', 'AKIA...', 'secret...', Parquet)
```
- Внешние БД (через интеграции):
```sql
# mysql('host:port', 'database', 'table', 'user', 'password') - внешняя БД MySQL
SELECT * FROM mysql('localhost:3306', 'test', 'users', 'user', 'password')
# postgresql('host:port', 'database', 'table', 'user', 'password') - внешняя БД PostgreSQL
SELECT * FROM postgresql('localhost:5432', 'prod', 'orders', 'user', 'password')
```
MongoDB, SQLite, JDBC: Аналогичные табличные функции (`mongodb`, `sqlite`, `jdbc`).
- Виртуальные столбцы и движки таблиц: Создание таблицы на внешний источник (например, MySQL):
```sql
CREATE TABLE mysql_orders (
    id UInt64,
    amount Float64
) ENGINE = MySQL('localhost:3306', 'db', 'orders', 'user', 'password');
SELECT * FROM mysql_orders;
```
- Команды `INSERT` для загрузки данных из ClickHouse во внешние источники
```sql
# Вставка в файл
INSERT INTO FUNCTION file('output.csv', CSV) SELECT * FROM local_table;
# Вставка в S3
INSERT INTO FUNCTION s3('https://.../out.parquet', ...) SELECT * FROM local_table;
# Вставка во внешнюю БД
INSERT INTO TABLE FUNCTION mysql(...) SELECT * FROM local_table;
```

<h4> Параллельная загрузка данных из внешних источников</h4>

Параллельное чтение из одного источника: Настройки `max_threads` и `max_block_size` влияют на параллельную обработку уже загруженных данных. При использовании `file()` или `s3()` параллелизм на чтении одного файла ограничен. Решение: Разбивать большие файлы на части (например, `data_*.csv`) и читать их параллельно с помощью `s3(..., format)` или через `INSERT INTO ... SELECT` из нескольких потоков/задач.

Параллельное чтение из нескольких разделов или таблиц:
```sql
INSERT INTO local_table
SELECT * FROM mysql_table WHERE month='2023-01'
UNION ALL
SELECT * FROM mysql_table WHERE month='2023-02'
```

Параллельная вставка (parallel_distributed_insert_select): При использовании распределённых запросов (к кластеру ClickHouse) можно заставить шарды выполнять `INSERT ... SELECT` параллельно. Для этого нужно создать распределённую таблицу на все шарды, включить настройку `parallel_distributed_insert_select` и  запустить запрос с `INSERT INTO distributed_table SELECT ... FROM external_source`. Каждый шард выполнит свою часть работы.

Практические советы для максимального параллелизма: Использовать `async_insert=1` при вставке больших объёмов из приложений (не для `INSERT ... SELECT`). Выгружать данные партициями (по датам, id) в отдельные файлы и загружать их одновременно разными job.
```bash
cat data_*.csv | parallel -j 8 'clickhouse-client --query "INSERT INTO table FORMAT CSV" < {}'
```
Настроить пул потоков: Увеличьте `background_pool_size`, `background_schedule_pool_size` если много фоновых задач (MV, словари).
Для словарей использовать `layout_cache`, `complex_key_cache` — они загружают данные параллельно в несколько потоков.

<h4>Транзакционная целостность</h4>

ClickHouse не является полноценной транзакционной СУБД (в смысле ACID для произвольных операций). Его сила — в скорости вставки и чтения больших объемов данных. Атомарность на уровне вставки: Вставка данных (`INSERT`) является атомарной на уровне одного запроса. Все строки одного запроса `INSERT` либо будут записаны, либо ни одна. При вставке из нескольких параллельных `INSERT` целостность на уровне таблицы гарантируется.

Изоляция между запросами:
- Чтение: Запрос `SELECT` видит консистентный снимок данных на момент начала своего выполнения. Данные, вставленные во время выполнения `SELECT`, не будут им видны.
- Одновременное чтение и запись: `SELECT` и `INSERT` не блокируют друг друга. Это одно из ключевых преимуществ для аналитики.

Механизмы для "транзакционности":
- Блочная структура данных: Данные вставляются пачками (блоками), и многие операции работают с целыми блоками как с атомарными единицами.
- Мутации (`ALTER ... UPDATE/DELETE`): Тяжелые операции, которые перезаписывают целые партиции (куски данных). Они неатомарны на уровне всей таблицы, но атомарны на уровне партиции. Мутации выполняются асинхронно. Для отслеживания прогресса есть системная таблица `system.mutations`.
- Легковесные транзакции (Lightweight transactions): Используются с фразой `SETTINGS mutations_sync = 1/2`. Это позволяет ждать завершения мутации, но не дает полноценной изоляции как в OLTP.
- Движок `ReplicatedMergeTree`: Обеспечивает консистентность реплик. Данные на разных репликах будут идентичны (в конечном счете, eventual consistency). Запись в несколько реплик синхронизирована.

ClickHouse предлагает "транзакционность для аналитики" — гарантии целостности при вставке больших пачек данных и консистентное чтение. Для частых точечных UPDATE/DELETE (OLTP-сценарии) он не подходит. Стратегия — вставка новых данных и периодическая очистка устаревших.

<h4>Интеграция с облачными хранилищами данных</h4>

ClickHouse имеет превосходную и глубокую интеграцию с S3-совместимыми объектными хранилищами (Amazon S3, Яндекс Object Storage, Google Cloud Storage, MinIO и др.).

Основные возможности интеграции:

- S3 как прямое хранилище для табличных движков: Можно читать и писать данные напрямую в/из S3 с помощью виртуальных файловых систем.
```sql
INSERT INTO TABLE my_table
SELECT * FROM s3('https://bucket.s3.amazonaws.com/data*.csv', 'CSV');
SELECT * FROM s3('https://...', 'Parquet') LIMIT 10;
```
- Движок таблиц S3: Позволяет работать с S3 как с постоянной таблицей (часто для выгрузки данных или промежуточного хранения).
```sql
CREATE TABLE my_s3_table (id UInt32, name String)
ENGINE = S3('https://.../output.csv', 'CSV');
```
- Хранение данных MergeTree в S3 (важнейшая функция):
  - S3 как диск (storage_policy): Можно настроить политику хранения, где "горячие" данные лежат на локальных SSD, а "холодные" автоматически перемещаются в S3. Прозрачно для пользователя: запросы работают со всей историей данных.
  - S3 как основной диск: Можно создать таблицу, данные которой полностью хранятся в S3. Это дешевле, но запросы будут медленнее из-за задержек сети.
- Бэкенд для репликации в S3: Начиная с версии 22.8, ClickHouse может хранить данные для репликации движка `ReplicatedMergeTree` не на локальном диске, а в S3. Это позволяет легко создавать и масштабировать кластеры в облаке, отделяя хранилище от вычислительных узлов.
- Резервное копирование в S3: Утилита clickhouse-backup и встроенные механизмы эффективно работают с S3 для создания и хранения бэкапов.

Практическое применение:
- Холодное хранение (Cold Storage): Архивация старых данных в дешевое S3 с сохранением возможности запроса.
- Data Lake Queries: Прямой запрос к данным, уже лежащим в Data Lake (Parquet, CSV в S3).
- Разделение хранения и вычислений (Storage-Compute Separation): Кластер ClickHouse может динамически подключаться к общему хранилищу в S3, что упрощает масштабирование и повышает отказоустойчивость.
- Экспорт/Импорт: Быстрая выгрузка результатов больших запросов в S3 для передачи в другие системы.

<h4>Интеграция с Apache Kafka</h4>

ClickHouse интегрируется с Kafka через специальный движок таблиц `Kafka`. Этот движок не хранит данные сам, а работает как потребитель (consumer) Kafka, который:
1. Читает сообщения из указанных топиков Kafka.
2. Парсит их в заданном формате (JSONEachRow, CSV, Avro через AvroConfluent и т.д.).
3. Перенаправляет данные в обычную (целевую) таблицу ClickHouse с помощью материализованного представления (Materialized View).

Ключевые преимущества:
- Потоковая (stream) загрузка данных в реальном времени. Данные появляются в ClickHouse с минимальной задержкой (секунды).
- Высокая пропускная способность. ClickHouse может потреблять сотни тысяч сообщений в секунду.
- Отказоустойчивость: ClickHouse хранит смещения (offsets) в системной таблице `kafka` в Zookeeper или самому Kafka (начиная с версии 22.3). При перезапуске потребление продолжится с того места, где остановились.
- Гибкость преобразований. Materialized View позволяет фильтровать, преобразовывать данные и дедуплицировать их перед вставкой в финальную таблицу.
- Поддержка схем. Использование формата AvroConfluent позволяет интегрироваться с Schema Registry Confluent для контроля схемы данных.
- Простота эксплуатации. Не нужны дополнительные ETL-процессы (как, например, Airflow) для пакетной загрузки. Система работает непрерывно.

ClickHouse подключается к Kafka как стандартный потребитель (consumer) из группы (consumer group). Ключевые настройки, которые нужно учесть на стороне Kafka и при конфигурации в ClickHouse:
- Настройки в конфигурационном файле ClickHouse (`config.xml`): `<kafka>` - необязательная секция для общих настроек SSL/аутентификации для всех таблиц Kafka. Чаще настройки задаются прямо при создании таблицы Kafka.
- Ключевые параметры при создании таблицы Kafka в ClickHouse:
```sql
CREATE TABLE queue (
    timestamp DateTime,
    message String
) ENGINE = Kafka
SETTINGS
    kafka_broker_list = 'kafka-host-1:9092,kafka-host-2:9092',
    kafka_topic_list = 'clickhouse_topic',
    kafka_group_name = 'clickhouse_consumer_group',
    kafka_format = 'JSONEachRow',
    kafka_max_block_size = 1048576,
    kafka_skip_broken_messages = 1,
    kafka_num_consumers = 1,
    kafka_handle_error_mode = 'stream';
```

Настройки:
- `kafka_group_name`: Имя группы потребителей, крайне важно для управления оффсетами. Уникальное для каждого потока потребления, позволяет перезапускать потребителя с того же места.
- `kafka_num_consumers`: Количество потребителей в одной таблице. Увеличивать только если одна партиция топика не успевает обрабатываться. Не должно превышать число партиций в топике Kafka.
- `kafka_skip_broken_messages`: Сколько битых сообщений можно пропустить подряд. Защищает от падения потока из-за одиночного некорректного сообщения.
- `kafka_commit_every_batch`: Фиксировать оффсет после каждой пачки (batch). По умолчанию 0 (после блока). 1 увеличивает надежность, но снижает производительность.
- `kafka_poll_timeout_ms`: Таймаут опроса брокера. По умолчанию 5000 (5 сек). Уменьшать для более быстрого ответа на остановку, увеличивать для снижения нагрузки на CPU.
- `kafka_flush_interval_ms`: Интервал сброса данных из внутреннего буфера в MV. По умолчанию 750, Увеличение может немного повысить производительность за счет задержки.

Настройка ClickHouse для приема сообщений:
1. Создание целевой таблицы (куда будут складываться итоговые данные).
```sql
CREATE TABLE target_table (
    id UInt64,
    timestamp DateTime,
    data String,
    metric Float32
) ENGINE = MergeTree
ORDER BY (id, timestamp);
```
2. Создание таблицы-движка Kafka (для чтения потока).
```sql
CREATE TABLE kafka_queue (
    id UInt64,
    timestamp DateTime,
    data String,
    metric Float32
) ENGINE = Kafka
SETTINGS
    kafka_broker_list = 'localhost:9092',
    kafka_topic_list = 'incoming_data',
    kafka_group_name = 'ch_consumers',
    kafka_format = 'JSONEachRow',
    kafka_skip_broken_messages = 10,
    kafka_num_consumers = 4; -- Если в топике 4 партиции
```
3. Создание Materialized View — мост между kafka_queue и target_table.
```sql
CREATE MATERIALIZED VIEW consumer_mv TO target_table AS
SELECT id,
       timestamp,
       data,
       metric
  FROM kafka_queue
 WHERE metric > 0; -- Опциональная фильтрация или трансформация
```

Данные, появляющиеся в топике Kafka `incoming_data`, автоматически читаются таблицей `kafka_queue`, преобразуются MV и вставляются в `target_table`.

Остановка и запуск потока:
```sql
DETACH TABLE kafka_queue; -- Остановить потребление
ATTACH TABLE kafka_queue; -- Возобновить потребление
```

Надежность и отказоустойчивость в интеграции ClickHouse с Kafka достигаются за счет нескольких механизмов:
- Хранение оффсетов: ClickHouse хранит оффсеты (позиции чтения) для каждой партиции Kafka. Это позволяет при перезапуске продолжить чтение с того места, где остановились. До версии 22.3 оффсеты хранились в ZooKeeper, а начиная с 22.3 можно хранить в самом Kafka (как это делают стандартные консьюмеры). Это важно для отказоустойчивости, так как при сбое ClickHouse-сервера другой сервер может подхватить чтение с того же оффсета.
- Репликация в ClickHouse: Для обеспечения отказоустойчивости данных в ClickHouse можно использовать реплицированные таблицы (движок `ReplicatedMergeTree`). При этом каждая реплика может потреблять данные из Kafka, но это требует осторожности, чтобы не дублировать данные. Обычная практика: потреблять данные из Kafka только одним узлом (лидером) и затем реплицировать их на другие узлы через механизм репликации ClickHouse. Но можно настроить потребление на каждой реплике, тогда нужно следить за тем, чтобы оффсеты хранились отдельно для каждой реплики (разные `kafka_group_name`).
- Обработка сбоев в Kafka: Если Kafka-кластер становится недоступным, ClickHouse будет пытаться переподключиться (согласно настройкам таймаутов и повторов). Важно настроить `kafka_skip_broken_messages` и `kafka_handle_error_mode` (в новых версиях), чтобы обработка не прерывалась из-за единичных некорректных сообщений.
- Мониторинг и алертинг: Мониторить отставание по партициям можно через системную таблицу `system.kafka_tables` (столбец `messages_lag`), настроить алерты при большом lag или ошибках потребления. Также важно мониторить нагрузку на ClickHouse и Kafka, чтобы вовремя масштабироваться.
- Гарантии доставки: ClickHouse с движком Kafka обеспечивает гарантию "at least once" (минимум один раз). Это означает, что в случае сбоя могут быть дубликаты. Для исключения дубликатов можно использовать идемпотентные вставки (например, с помощью `ReplacingMergeTree` и версии) или дедупликацию на уровне блока (настройка `merge_tree`), а также транзакции в Kafka (требует тщательной настройки и поддерживается не во всех сценариях).
- Резервное копирование и восстановление: Регулярно делайте бэкапы данных в ClickHouse (например, с помощью `ALTER TABLE ... FREEZE` или инструментов типа clickhouse-backup). Имейте план восстановления данных из бэкапа в случае потери.