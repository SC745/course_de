<h2>Оптимизация и мониторинг</h2>
<h3>1. Производительность и оптимизация</h3>
<h4>Основы производительности</h4>

Производительность ClickHouse базируется на нескольких архитектурных принципах:
- Колоночное хранение: Данные хранятся не по строкам, а по столбцам. Это позволяет при запросе читать только необходимые столбцы, а не всю строку (снижение I/O), эффективно сжимать данные (однотипные данные в колонке сжимаются лучше).
- Векторизованная обработка запросов: Операции выполняются не над отдельными значениями, а над целыми блоками данных (векторами, обычно 65536 строк). Это максимально эффективно использует возможности CPU (кеш, конвейер инструкций SIMD).
- Индексные структуры (первичный ключ): Это не B-tree индекс как в OLAP. ClickHouse использует разреженный индекс. Для каждой N-ой строки (где N — `index_granularity`, обычно 8192) запоминается значение первичного ключа и адрес начала этого куска (гранулы) данных на диске. При запросе с `WHERE` по первичному ключу система быстро находит нужные гранулы и считывает только их.
- Data Skipping Индексы: Дополнительные легковесные индексы позволяют "пропускать" гранулы данных, которые гарантированно не содержат искомых значений.
- Материализованные представления и агрегатные функции: Возможность предварительно вычислять и хранить агрегированные данные, что ускоряет выполнение типовых отчетов в тысячи раз.
- Работа с данными партиями (batch): ClickHouse оптимизирован под вставку больших пачек данных (тысячи-миллионы строк за раз), а не одиночных `INSERT`. Мелкие частые вставки крайне неэффективны.
- Локальность данных: Высокая производительность достигается при работе с данными на локальных SSD/NVMe дисках. Распределенность (кластеры) — это надстройка для масштабирования и отказоустойчивости.

<h4>Настройки производительности</h4>

Настройки можно разделить на несколько групп. Основной конфигурационный файл — `config.xml` и пользовательские настройки в `users.xml`.

Настройки, влияющие на слияния (MergeTree):
- `max_bytes_to_merge_at_max_space_in_pool` (по умолчанию ~150 ГБ) — максимальный суммарный размер данных в одном слиянии. Слишком большие значения могут привести к долгим слияниям и нехватке места на диске.
- `number_of_free_entries_in_pool_to_lower_max_size_of_merge` — управляет приоритизацией слияний. Увеличение значения заставляет ClickHouse делать более мелкие слияния, что полезно при нехватке места.

Настройки для вставки данных:
- `max_insert_block_size` (по умолчанию 1,048,576) — размер блока для вставки. Должен быть согласован с настройками клиента.
- `min_insert_block_size_rows` — минимальный размер блока для вставки. Если блок меньше, он будет аккумулироваться в памяти до достижения этого порога. Важно для мелких вставок.
- `async_insert` (рекомендуется 1) — включает асинхронную вставку, когда данные сначала буферизуются, а потом записываются пачкой. Ключевая настройка для работы с мелкими вставками.
- `wait_for_async_insert` (по умолчанию 1) — ждать ли подтверждения записи при асинхронной вставке.

Настройки для чтения (`SELECT`):
- `max_threads` — максимальное количество потоков для обработки одного запроса (см. ниже).
- `max_block_size` — размер блока, который используется при обработке и возврате данных.
- `preferred_block_size_bytes` — система будет стараться формировать блоки указанного размера в байтах для оптимизации работы кэша CPU.
- `use_uncompressed_cache` (по умолчанию 0) — использовать ли кэш разжатых данных. Включение (1) может сильно ускорить повторяющиеся запросы к одним и тем же данным, если они влезают в память.

Глобальные настройки ресурсов:
- `background_pool_size` / `background_schedule_pool_size` — количество потоков для фоновых операций (слияния, перемещения). По умолчанию равно количеству ядер CPU.
- `background_buffer_flush_schedule_pool_size` — пул для сброса буферных таблиц.

<h4>Настройки памяти и процессора</h4>

ClickHouse использует память для обработки запросов, фоновых операций и кэшей. Важно разделить общий объем памяти между этими потребителями.

Ограничение памяти на запрос:
- `max_memory_usage` (по умолчанию 10 ГБ) — абсолютный максимум RAM на один запрос. Самая важная настройка для предотвращения OOM (Out Of Memory). Устанавливается в байтах (например, 20GiB).
- `max_memory_usage_for_user` — лимит на все запросы одного пользователя.
- `max_server_memory_usage` — глобальный лимит на всю RAM сервера (не рекомендуется, лучше настраивать через cgroups).

Память для JOIN:
- `join_algorithm` — предпочитаемый алгоритм (hash, parallel_hash, partial_merge, auto). hash требует хранения правой таблицы в памяти, но быстрее.
- `max_bytes_in_join` — ограничение памяти для хеш-таблицы JOIN.
- `join_use_nulls` — влияет на использование памяти.

Память для агрегации:
- `max_bytes_before_external_group_by` / `max_bytes_before_external_sort` — если агрегация или сортировка превышает этот порог, данные сбрасываются на диск (внешняя агрегация/сортировка). Критически важная настройка для тяжелых запросов, предотвращающая OOM. Типичное значение — 50-80% от max_memory_usage.

Кэши:
- `uncompressed_cache_size` (по умолчанию 8 GiB) — объем кэша разжатых данных. Увеличивайте, если горячие данные не помещаются в RAM.
- `mark_cache_size` (по умолчанию 5 GiB) — кэш для файлов индексов (.mrk). Должен быть достаточно большим, чтобы хранить индексы всех активно используемых таблиц.

Процессор
- `max_threads` (по умолчанию равно количеству ядер CPU) — определяет параллелизм на уровне данных. Для запросов с GROUP BY, ORDER BY данные разбиваются на потоки. Установка значения больше числа физических ядер редко дает выигрыш и может навредить из-за переключения контекста. Для легких запросов его можно уменьшить.
- `parallelize_output_from_storages` — распараллеливать ли чтение с диска. Для быстрых SSD часто имеет смысл включить.
- `max_streams_to_max_threads_ratio` (по умолчанию 1) — множитель для создания потоков при чтении с удаленных источников (например, при чтении из S3 или HDFS).

Настройки для операций с диском:
- `local_filesystem_read_method` / `..._write_method` — методы ввода-вывода (`pread`, `read`, `mmap`). Для NVMe SSD часто pread или read показывают лучшую производительность, чем mmap.
- `min_bytes_to_use_direct_io` (по умолчанию 0) — порог для использования прямого ввода-вывода (O_DIRECT), минуя кэш ОС. При использовании быстрых NVMe налету и наличии большого объема RAM в самом ClickHouse, установка значения (например, 1GiB) может освободить кэш ОС для полезной работы.

<h4>План выполнения запроса</h4>

Пример запроса:
```sql
EXPLAIN
SELECT
    user_id,
    COUNT() as page_views,
    SUM(revenue) as total_revenue
FROM user_events
WHERE
    event_date >= '2024-01-01'
    AND event_type = 'page_view'
    AND country IN ('US', 'UK', 'DE')
GROUP BY user_id
HAVING total_revenue > 100
ORDER BY total_revenue DESC
LIMIT 100
```

План выполнения:
```bash
Expression (Projection)
  Limit
    Expression (Before ORDER BY)
      Sorting (Merge)
        Aggregating
          Expression (Before GROUP BY)
            Filter (HAVING)
              Expression (Before GROUP BY)
                Filter (WHERE)
                  ReadFromMergeTree (user_events)
```

Для получения детального плана:
```sql
EXPLAIN
    header = 1,
    description = 1,
    actions = 1,
    json = 0
SELECT ... -- тот же запрос
```

Разбор плана запроса (выполнение снизу вверх):
1. ReadFromMergeTree (user_events) - чтение данных:
```bash
ReadFromMergeTree
Read Type: Default
Parts: 12 parts (по числу партиций)
Granules: 2450 granules (гранулы для чтения)
Indexes:
  PrimaryKey: (event_date, event_type)
  MinMax: event_date: ['2024-01-01', +Inf)
  Partition: event_date
```
2. Filter (WHERE) - применение условий WHERE:
```bash
Filter
Predicate:
  (event_date >= '2024-01-01')
  AND (event_type = 'page_view')
  AND (country IN ('US', 'UK', 'DE'))
Rows Before: 10,000,000 (оценка)
Rows After: 500,000 (оценка после фильтрации)
```
3. Expression (Before GROUP BY) - вычисление выражений:
```bash
Expression
Actions: PROJECT user_id, revenue
```
4. Aggregating - агрегация:
```bash
Aggregating
Keys: user_id
Aggregates: count(), sum(revenue)
Memory Usage: ~256 MB (оценка)
```
5. Filter (HAVING) - применение HAVING:
```bash
Filter
Predicate: total_revenue > 100
Rows Before: 50,000
Rows After: 10,000
```
6. Sorting (Merge) - сортировка:
```bash
Sorting
Keys: total_revenue DESC
Limit: 100
Memory Usage: ~16 MB
```
7. Limit - применение LIMIT
8. Expression (Projection) - финальная проекция столбцов

В последних версиях ClickHouse появилась возможность использовать подсказки для влияния на план выполнения. Они задаются в виде комментариев в SQL-запросе:
```sql
-- Указание предпочтительного алгоритма JOIN
SELECT /*+ JOIN_DEFAULT_STRATEGY('hash') */ 
    a.*, b.name
FROM table_a AS a
JOIN table_b AS b ON a.id = b.id;

-- Указание направления JOIN (чтобы не переставлять таблицы местами)
SELECT /*+ NO_REORDER_JOINS() */ 
    a.*, b.name
FROM table_a AS a
JOIN table_b AS b ON a.id = b.id;

-- Принудительное использование определенного индекса (если есть несколько)
SELECT /*+ INDEX(my_table my_index) */ 
    *
FROM my_table
WHERE column = 'value';
```

<h4>Оптимизация запросов в MergeTree таблицах</h4>

Общие методы оптимизации:
- Партиционирование (`PARTITION BY`): Управление жизненным циклом данных (TTL, удаление партиций DROP PARTITION).  Партиция должна содержать от 1 до ~100 гигабайт данных. Слишком мелкие партиции -> много мелких кусков -> проблемы с мерджем и запросами. Слишком крупные партиции -> неэффективное удаление данных. Типичный ключ партицирования — по дате (`toYYYYMM(event_date)`, `toMonday(event_date)`).
- Ключ сортировки/Первичный ключ (ORDER BY / PRIMARY KEY): Определяет, как данные физически упорядочены на диске. Первый столбец в ключе должен быть самым часто используемым в фильтрах (`WHERE`, `GROUP BY`). Использовать кардинальность от высокой к низкой (например, user_id, date). Ключ работает по принципу пропуска индекса. Он указывает на "гранулы" данных (по умолчанию 8192 строки). Чем длиннее ключ, тем больше индексный файл, но точнее поиск. Не рекмендуется делать ключ слишком "широким", 2-4 столбца — часто оптимально.
- Индексация (Пропускающие индексы - Skipping Indexes): Дополнение к первичному индексу для столбцов, не входящих в `ORDER BY`. Пример (`bloom_filter` для поиска по подстроке):
```sql
ALTER TABLE logs ADD INDEX idx_message message TYPE bloom_filter GRANULARITY 1;
```
Индексы работают на уровне гранул. Они не гарантируют пропуск гранулы, а только позволяют это сделать. Эффективность зависит от данных.

Оптимизация чтения:
- Гранулярность: Настройка `index_granularity` (по умолч. 8192). Меньшее значение -> точнее индекс -> больше чтений. Увеличивать для очень больших таблиц.
- Кодеки сжатия столбцов: CODEC(Delta, ZSTD). Delta эффективен для монотонно возрастающих данных (timestamp, id). ZSTD дает хороший баланс скорости/сжатия.

Оптимизация вставки:
- Вставлять пачками (batch). Одна вставка 100к-1м строк гораздо эффективнее 1000 вставок по 100 строк.
- Использовать асинхронные вставки: через Buffer таблицу или `async_insert=1`.
```sql
CREATE TABLE logs_buffer AS logs ENGINE = Buffer(default, logs, 16, 10, 100, 10000, 1000000, 10000000, 100000000);
```
- Контролировать размер кусков: Настройки `min_bytes_for_wide_part`, `min_rows_for_wide_part` решают, хранить ли часть в "широком" (каждый столбец отдельно) или "компактном" (все в одном файле) формате. Для больших вставок важен "широкий" формат.
Параллельные вставки в разные партиции не блокируют друг друга.

<h4>Использование Materialized View для оптимизации</h4>

`MATERIALIZED VIEW` (MV) в ClickHouse — это не просто кэш запроса, а триггер на вставку в исходную таблицу. При вставке данных в исходную таблицу, кусок данных проходит через движок MV и записывается в целевую таблицу, где хранятся материализованные данные.

```sql
-- 1. Исходная детальная таблица
CREATE TABLE sales_detail (
    dt DateTime,
    product_id UInt32,
    revenue Decimal(10,2)
) ENGINE = MergeTree PARTITION BY toYYYYMM(dt) ORDER BY (dt, product_id);

-- 2. Целевая таблица для агрегированных данных
CREATE TABLE sales_daily (
    date Date,
    product_id UInt32,
    sum_revenue AggregateFunction(sum, Decimal(10,2)),
    count_revenue AggregateFunction(count, Decimal(10,2))
) ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(date) ORDER BY (date, product_id);

-- 3. MV, которая пересчитывает агрегаты при каждой вставке
CREATE MATERIALIZED VIEW sales_daily_mv TO sales_daily
AS
SELECT toDate(dt) AS date,
       product_id,
       sumState(revenue) AS sum_revenue,
       countState(revenue) AS count_revenue
  FROM sales_detail
 GROUP BY date, product_id;
```

Теперь запрос к агрегированным данным быстрый:
```sql
SELECT date,
       product_id,
       sumMerge(sum_revenue),
       countMerge(count_revenue)
  FROM sales_daily
 GROUP BY date, product_id;
```

Важные нюансы:
- Данные в MV появляются только после вставки. Исторические данные в неё не попадут автоматически. Их нужно подтянуть: 
```sql
INSERT INTO sales_daily SELECT ... FROM sales_detail WHERE dt < ...
```
- MV увеличивает нагрузку на вставку, так как данные обрабатываются дважды.
- Для агрегаций используется движок `AggregatingMergeTree` и функции `*State`/`*Merge`. Это "правильный" способ в ClickHouse.
- Можно создавать несколько MV на одну таблицу для разных агрегаций (по минутам, по часам, по разным измерениям).

<h4>Стратегии оптимизации запросов</h4>

Оптимизация в ClickHouse начинается на уровне проектирования таблиц, но эти стратегии касаются написания самих запросов:
- Использовать движок MergeTree и его производные.
- Минимизировать обрабатываемый объем данных(prewhere vs where): `PREWHERE` — это фильтрация, которая происходит до чтения столбцов, на уровне чтения кусков (chunks). Используется для условий, которые отфильтровывают много строк, особенно если задействованы столбцы, не входящие в первичный ключ. ClickHouse часто применяет `PREWHERE` автоматически, но можно указать вручную.
```sql
SELECT * FROM logs WHERE data LIKE '%error%'       -- Плохо (для большого столбца data)
SELECT * FROM logs PREWHERE data LIKE '%error%'    -- Лучше
```
- Избегать `SELECT *`. Читать только необходимые столбцы. В колоночной СУБД чтение лишнего столбца = чтение отдельного файла на диске.
- Сортировать данные по ключевым фильтрам. Если `ORDER BY` в запросе совпадает с ключом сортировки таблицы, ClickHouse сможет эффективно использовать первичный индекс для прыжков по данным.
- Избегать или аккуратно используйте `JOIN`. ClickHouse не реляционная СУБД, `JOIN` — не её сильная сторона. Для этого использовать денормализацию, движки Join или словари (DICTIONARY). Если `JOIN` необходим, правая таблица должна быть в памяти. Используйте движок Join для маленьких справочников.
```sql
CREATE TABLE small_dict (...) ENGINE = Join(ANY, LEFT, id);    -- Создание таблицы для JOIN в оперативке
```
- Агрегировать данные насколько возможно. Для этого использовать приближённые алгоритмы (`uniqCombined`, `quantileTDigest`), если точность не критична — они в разы быстрее.
- Использовать подзапросы вместо `JOIN` там, где это уместно. Часто фильтрация подзапросом эффективнее.
Контролировать память и параллелизм: настройки `max_memory_usage`, `max_threads`.

<h4>Оптимизация запросов к внешним источникам</h4>

ClickHouse может запрашивать данные из внешних источников через табличные функции (такие как `mysql`, `postgresql`, `s3`, `url`, `hdfs`) или через движки таблиц (например, MySQL, PostgreSQL, ODBC). Оптимизация таких запросов критична, поскольку внешние источники могут быть медленными. Стратегии оптимизации:
- Фильтрация и агрегация на стороне ClickHouse: ClickHouse старается передать часть запроса (предикаты, агрегации) во внешкую БД, но это зависит от возможностей внешней системы. Всегда старайтесь явно указать фильтры, чтобы уменьшить объем получаемых данных.
- Использование кэширования: Для повторяющихся запросов к внешним источникам можно использовать кэш. Например, для S3 есть настройки кэширования.
- Параллельное чтение: Если внешний источник поддерживает, можно читать данные параллельно. Например, для S3 можно использовать `s3_parallel_read=1`.
- Прямое соединение с внешними БД: При использовании движков таблиц (например, MySQL) запросы преобразуются в SQL запросы к внешней БД. Убедитесь, что на внешней БД есть индексы для ускорения.
- Буферизация и материализация: Если внешние данные используются часто, рассмотрите возможность загрузки их в ClickHouse (например, в таблицу с движком Memory или MergeTree). Можно использовать `CREATE TABLE AS SELECT ...` или `MATERIALIZED VIEW` для синхронизации.
- Настройки времени ожидания и повторов: Увеличьте `connect_timeout` и `receive_timeout` при работе с медленными сетями.

Пример запроса к MySQL с фильтрацией:
```sql
SELECT *
  FROM mysql('host:port', 'database', 'table', 'user', 'password')
 WHERE id = 1;
```
ClickHouse попытается отправить условие `id=1` в MySQL, чтобы тот вернул только одну строку.

<h4>Оптимизация запросов с использованием шардирования</h4>

Шардирование в ClickHouse — это горизонтальное разделение данных между несколькими серверами. Оно используется для масштабирования. Стратегии оптимизации:
- Распределенные запросы: Использовать Distributed движок для запросов ко всем шардам. ClickHouse может выполнять запросы параллельно на каждом шарде и агрегировать результаты.
- Локальность данных: При использовании Distributed движок может хранить локальную таблицу на каждом шарде. Убедиться, что запросы используют локальные таблицы, а не удаленные.
- Распределенные агрегации: Для агрегаций можно использовать двухуровневую агрегацию. Сначала каждый шард выполняет агрегацию, затем результаты отправляются на инициализирующий сервер для финальной агрегации. Это уменьшает объем передаваемых данных. Включить можно настройками:
```sql
SET distributed_aggregation_memory_efficient = 1;
SET group_by_two_level_threshold = 1000;
SET group_by_two_level_threshold_bytes = 100000000;
```
- Распределенные подзапросы: Избегать распределенных подзапросов, которые могут привести к передаче больших объемов данных. Вместо этого использовать `GLOBAL IN` или `GLOBAL JOIN`.
- Балансировка и топология: Правильно настраивать топологию кластера. Использовать веса реплик, если шарды неоднородны. Убедиться, что сетевые задержки минимальны. Пример создания распределенной таблицы:
```sql
CREATE TABLE distributed_table ON CLUSTER 'my_cluster' AS local_table
ENGINE = Distributed('my_cluster', 'default', 'local_table', rand());
```
Запросы к `distributed_table` будут распределяться по шардам.
- Распределенные DDL: Использовать `ON CLUSTER` для управления схемой на всех шардах.

<h4>Оптимизация запросов с использованием шардирования</h4>

Работа с большими данными требует особого подхода к проектированию таблиц, запросов и кластера. Стратегии оптимизации:
- Горизонтальное масштабирование (шардирование): Распределить данные по нескольким серверам. Это позволяет обрабатывать больше данных, чем помещается на один сервер.
- Вертикальное масштабирование: Увеличить ресурсы сервера (память, CPU, быстрые диски). ClickHouse эффективно использует многоядерные процессоры и оперативную память.
- Сжатие данных: ClickHouse сжимает данные по умолчанию. Выбор кодека (например, ZSTD) может значительно уменьшить объем хранилища и ускорить чтение.
- Архивация и TTL: Использовать TTL для автоматического удаления или перемещения старых данных на более медленные диски (или в S3). Это помогает управлять объемом активных данных. Пример:
```sql
CREATE TABLE logs (
  event_date DateTime,
  message String
) ENGINE = MergeTree
PARTITION BY toYYYYMM(event_date)
ORDER BY event_date
TTL event_date + INTERVAL 1 MONTH TO DISK 'slow_disk',
     event_date + INTERVAL 1 YEAR DELETE;
```
- Использование движка `ReplicatedMergeTree` для отказоустойчивости: Репликация не увеличивает производительность запросов, но обеспечивает доступность и целостность данных.
- Оптимизация памяти: Настроить параметры памяти для обработки больших запросов (`max_memory_usage`, `max_bytes_before_external_group_by`, `max_bytes_before_external_sort`). При нехватке памяти ClickHouse может сбрасывать промежуточные данные на диск.
- Проектирование таблиц: Правильный первичный ключ (для пропуска данных), партицирование для управления жизненным циклом, использование разных движков для разных задач (например, `MergeTree` для детальных данных, `AggregatingMergeTree` для агрегатов).
- Batch processing: Вставлять данные крупными пачками (от 10 000 до 1 000 000 строк за раз) и尽量避免 частые мелкие вставки.
- Мониторинг и профилирование: Использовать системные таблицы (`system.query_log`, `system.part_log`, `system.metrics`) для анализа производительности. Включить профилировку запросов (`SET send_profiler_end = 1`).
- Использование приближённых вычислений: Для больших данных точность может быть не так важна. Можно использовать приближённые функции (`uniqCombined`, `approxQuantile`).
- Векторизованное выполнение запросов: ClickHouse использует векторную обработку данных. Убедиться, что данные хранятся в колоночном формате и кодек сжатия не мешает векторной обработке.
- Работа с дисками: Использовать быстрые SSD. Разделить данные и журналы на разные диски. Настройка `storage_policy` позволяет использовать несколько дисков с разными скоростями. Пример настройки политики хранения:
```xml
<storage_configuration>
    <disks>
        <fast_disk>
            <path>/var/lib/clickhouse/fast/</path>
        </fast_disk>
        <slow_disk>
            <path>/var/lib/clickhouse/slow/</path>
        </slow_disk>
    </disks>
    <policies>
        <moving_from_fast_to_slow>
            <volumes>
                <fast>
                    <disk>fast_disk</disk>
                </fast>
                <slow>
                    <disk>slow_disk</disk>
                </slow>
            </volumes>
        </moving_from_fast_to_slow>
    </policies>
</storage_configuration>
```
Затем в таблице:
```sql
CREATE TABLE logs (...) ENGINE = MergeTree
PARTITION BY ...
ORDER BY ...
TTL ... TO VOLUME 'slow'
SETTINGS storage_policy = 'moving_from_fast_to_slow';
```

<h4>Оптимизация дисковых операций</h4>

Дисковые операции часто являются узким местом в производительности. Вот ключевые техники их оптимизации:
- Использование быстрых накопителей: NVMe SSD предпочтительнее SATA SSD и HDD. ClickHouse активно использует дисковый ввод-вывод, поэтому скорость диска напрямую влияет на производительность.
- Разделение данных на разные диски (Storage Policies): Можно настроить политики хранения, чтобы, например, горячие данные находились на быстрых NVMe, а холодные — на более медленных SATA или даже в объектном хранилище (S3). Также можно распределять данные по нескольким дискам (JBOD) для увеличения пропускной способности.
- Оптимизация слияний (Merge): Слияния (merge) — это фоновая операция объединения данных, которая может создавать высокую нагрузку на диск. Нужно настраивать параметры слияний (см. ниже) в соответствии с вашим оборудованием и нагрузкой.
- Использование TTL для управления жизненным циклом данных: Автоматическое удаление или перемещение старых данных на более медленные диски (или в S3) с помощью TTL (Time To Live) помогает поддерживать объем горячих данных на оптимальном уровне.
- Настройка методов ввода-вывода:
  - `local_filesystem_read_method` и `local_filesystem_write_method` (например, pread, read, mmap). Для NVMe SSD pread или read могут быть лучше, чем mmap.
  - `min_bytes_to_use_direct_io` — использование прямого ввода-вывода (O_DIRECT) позволяет обойти кэш ОС, что может быть полезно при наличии собственного кэша в ClickHouse (uncompressed cache) и быстрых дисках.
- Кэширование: Настройка кэша разжатых данных (`uncompressed_cache_size`) и кэша засечек (`mark_cache_size`) уменьшает количество обращений к диску.
- Оптимизация структуры таблиц: Правильный выбор порядка столбцов в первичном ключе и партиционирования может значительно уменьшить объем читаемых с диска данных.
- Использование эффективных кодеков сжатия (например, Delta, DoubleDelta, Gorilla для временных рядов, ZSTD для общего случая) уменьшает объем данных на диске, что снижает IO.

<h4>Оптимизация дисковых операций</h4>

TTL (Time To Live) — мощный инструмент управления жизненным циклом данных. Виды TTL:
- TTL для строк: Удаление строк по истечении времени:
```sql
CREATE TABLE example_table
(
    date Date,
    value Int32
)
ENGINE = MergeTree
ORDER BY date
TTL date + INTERVAL 1 MONTH;
```
- TTL для столбцов: Установка значений по умолчанию для столбцов через определенное время (например, обнуление конфиденциальных данных):
```sql
CREATE TABLE example_table
(
    date Date,
    secret String TTL date + INTERVAL 1 DAY
)
ENGINE = MergeTree
ORDER BY date;
```
- TTL для перемещения данных между дисками/томами: Например, перемещение старых данных на более медленный диск или в S3:
```sql
CREATE TABLE example_table
(
    date Date,
    value Int32
)
ENGINE = MergeTree
ORDER BY date
TTL date + INTERVAL 1 WEEK TO DISK 'slow_disk',
    date + INTERVAL 1 MONTH TO VOLUME 'cold_volume';
```

Стратегии оптимизации хранения данных:
- Партиционирование: Разбиение таблицы на части по ключу (например, по месяцу). Упрощает управление данными (удаление, перемещение) и может ускорить запросы, если они затрагивают только определенные партиции. Не стоит делать слишком мелкие партиции (например, по дням), если данных не много. Это может привести к большому количеству файлов и снижению производительности.
- Использование различных движков таблиц:
  - `ReplicatedMergeTree` для отказоустойчивости и распределения нагрузки на чтение.
  - `Distributed` для шардирования данных по кластеру.
  - `MergeTree` для локальных таблиц.
- Архивация старых данных: С помощью TTL перемещать старые данные в объектное хранилище (S3) или на холодные диски. ClickHouse поддерживает хранение данных в S3 и может запрашивать их оттуда при необходимости (хотя и с большей задержкой).
- Использование материализованных представлений: Для предварительного агрегирования данных и ускорения часто используемых запросов.
- Управление индексными гранулами: Параметр `index_granularity` (по умолчанию 8192) определяет, сколько строк в одной грануле индекса. Уменьшение этого значения может улучшить точность индекса (меньше лишних данных читается), но увеличит размер индекса и может замедлить запросы из-за большего количества гранул.

<h4>Настройка аутентификации и авторизации</h4>

ClickHouse поддерживает два основных способа управления доступом: устаревший XML-конфиги и современный SQL-управляемый RBAC (ролевая модель). Рекомендуется использовать RBAC.

Аутентификация: Определяется в `users.xml` или (лучше) в отдельных файлах в `users.d/.`

Основные методы:
- Пароль: Может быть храниться в plaintext, sha256, sha256 в hex, double_sha1 (для совместимости с MySQL).
- LDAP: Интеграция с внешним LDAP-сервером.
- Kerberos.

Пример создания пользователя через SQL (RBAC):
```sql
CREATE USER alice IDENTIFIED WITH sha256_password BY 'strong_password';
CREATE USER bob IDENTIFIED WITH ldap SERVER 'my_ldap_server';
```

Авторизация — RBAC модель
Роли: Группируют привилегии.
```sql
CREATE ROLE analyst;
GRANT SELECT ON database1.* TO analyst;
GRANT SELECT ON database2.table2 TO analyst;
```

Привязка ролей к пользователям:
```sql
GRANT analyst TO alice;
```

Привилегии: Можно выдавать напрямую.
```sql
GRANT INSERT ON db.table TO bob;
```

Профили настроек: Ограничивают ресурсы (макс. память, таймауты).
```sql
CREATE PROFILE readonly_profile SETTINGS max_memory_usage = 10000000000, read_only = 1;
CREATE USER viewer IDENTIFIED BY 'view' PROFILE readonly_profile;
```

<h3>2. Масштабирование и мониторинг</h3>
<h3>Масштабирование</h3>

Вертикальное масштабирование:
- Колоночное хранение: Данные хранятся не по строкам, а по столбцам. Это позволяет читать только те столбцы, которые нужны для запроса (меньший объем I/O), эффективно сжимать данные (поскольку значения в одном столбце часто похожи), что уменьшает объем хранилища в десятки раз.
- Векторизованная обработка запросов: Данные обрабатываются не по одной строке, а большими блоками (векторами, часто по 8192 строки). Это позволяет максимально эффективно использовать возможности CPU (кэш, инструкции SIMD).
- Распределение нагрузки на железо:
  - Множественные ядра CPU: ClickHouse активно использует все доступные ядра для параллельного выполнения частей одного запроса (параллелизм на уровне данных).
  - Большая пропускная способность дисков (IOPS, throughput): Оптимизирован под быстрые последовательные чтения (HDD/SSD, а лучше NVMe). Рекомендуется использовать RAID или несколько отдельных дисков для данных и журналов.
  - Большой объем RAM: Используется для хранения индексов, промежуточных данных, состояния агрегатных функций, кэширования.
- Отсутствие транзакционности (в классическом OLAP-смысле): Отказ от ACID для отдельных вставок/обновлений позволяет достичь предельной скорости записи и чтения.
- Эффективные алгоритмы и структуры данных:
  - MergeTree-движки: Фундамент ClickHouse. Данные записываются в мелкие куски (parts), которые затем фоново сливаются в более крупные, упорядоченные. Это обеспечивает быструю вставку (просто добавление нового куска на диск), предварительную сортировку по первичному ключу, что ускоряет диапазонные выборки (WHERE, GROUP BY).
  - Пропускающие индексы (Data Skipping Indexes): Статистические индексы (minmax, set, bloom_filter и др.), которые позволяют "пропускать" целые блоки данных при чтении, если известно, что нужных данных там нет.
  - Параллелизм и конкуренция: Поддерживает большое количество одновременных SELECT-запросов, эффективно распределяя ресурсы между ними.

Горизонтальное масштабирование:
- Шардирование (Sharding) — для масштабирования объема/производительности: Разделение данных между разными серверами (шардами) по какому-либо ключу (например, `user_id`). При вставке данных распределительный движок (например, Distributed) решает, на какой шард отправить каждую порцию данных, основываясь на ключе шардирования. Запрос, отправленный на любую ноду через Distributed-таблицу, выполняется параллельно на всех шардах, результаты агрегируются на ноде-инициаторе. Цель - Увеличить общую пропускную способность записи и чтения, а также общий объем данных сверх возможностей одного сервера.
- Репликация (Replication) — для отказоустойчивости и балансировки чтения: Создание полных копий данных (реплик) на нескольких серверах. Используются семейства движков `ReplicatedMergeTree`. При вставке в одну реплику данные через ZooKeeper синхронизируются со всеми другими репликами этого шарда. Репликация асинхронная на уровне кусков данных. Цель - отказоустойчивость и Балансировка чтения

<h4>Мониторинг метрик производительности</h4>

ClickHouse предоставляет несколько способов мониторинга:
- Системные таблицы (`system.metrics`, `system.events`, `system.asynchronous_metrics`, `system.query_log`, `system.part_log` и др.)
- HTTP-интерфейс для Prometheus (метрики экспортируются в формате Prometheus)
- Собственный профилировщик (`query profiler`) и трассировка (`trace_log`)

Основные метрики, которые важно отслеживать:
- Запросы: Количество запросов в секунду, медленные запросы (длительность запросов, можно настраивать пороги), ошибки запросов (количество исключений)
- Использование ресурсов: Загрузка CPU (системная и пользовательская)
- Использование памяти:
  - RAM: общее, свободное, используемое ClickHouse (включая разбивку по типам памяти: например, для кэшей, для запросов и т.д.)
  - Память процессов: RSS, виртуальная память
- Дисковое использование:
  - Свободное место на дисках (особенно важно, если данные растут быстро)
  - Скорость чтения/записи (IOPS, пропускная способность)
  - Использование inode
- Метрики ClickHouse (из `system.metrics` и `system.events`):
  - `Query` - количество запросов (разные типы)
  - `Merge` - активные слияния (мержи) в MergeTree
  - ReplicatedFetch - для репликации
  - TCPConnection - количество соединений
  - HTTPConnection - количество HTTP соединений
  - DelayedInserts - количество отложенных вставок (если есть проблемы с производительностью при вставке)
- Логи запросов (`system.query_log`): Позволяет анализировать историю запросов: кто, когда, какой запрос, как долго выполнялся, сколько строк прочитал, сколько памяти использовал.
- Логи партиций (`system.part_log`): Информация о создании, удалении, слиянии кусков данных в MergeTree.

Мониторинг внешних источников: ClickHouse может работать с внешними источниками данных (внешние словари, табличные функции, интеграции с Kafka, MySQL, PostgreSQL и др.). Мониторинг этих компонентов включает:
- Внешние словари (`system.dictionaries`):
  - Статус загрузки словарей (загружены ли, время последней загрузки, количество строк, объем памяти)
  - Ошибки загрузки словарей
- Интеграция с Kafka (движок Kafka):
  - Отставание потребителей (lag) по партициям
  - Количество сообщений, обработанных за период
  - Ошибки потребления
- Интеграция с MySQL/PostgreSQL (табличные функции, движок MySQL, движок PostgreSQL):
  - Задержка подключения
  - Количество переподключений
  - Задержка репликации (если используется)
- HDFS/S3 (табличные функции, движок S3):
  - Скорость чтения/записи
  - Количество ошибок при работе с объектами
- Также важно мониторить сетевые соединения между ClickHouse и этими внешними системами (задержки, разрывы).

<h4>Настройка мониторинга с помощью Graphana и Prometheus</h4>

Этапы настройки:
1. Настройка экспорта метрик из ClickHouse в Prometheus: ClickHouse имеет встроенную поддержку Prometheus. В конфигурационном файле `config.xml` (или в `prometheus.xml` внутри папки `config.d`) нужно добавить:
 ```xml
 <prometheus>
     <endpoint>/metrics</endpoint>
     <port>9363</port>
     <metrics>true</metrics>
     <events>true</events>
     <asynchronous_metrics>true</asynchronous_metrics>
     <status_info>true</status_info>
 </prometheus>
 ```
 После перезагрузки конфигурации или перезапуска ClickHouse метрики будут доступны по адресу `http://<clickhouse-server>:9363/metrics`.

2. Настройка Prometheus для сбора метрик: В конфигурации Prometheus (`prometheus.yml`) нужно добавить job:
```yaml
scrape_configs:
job_name: 'clickhouse'
static_configs:
targets: ['<clickhouse-server>:9363']
scrape_interval: 5s
```
3. Установка и настройка Grafana: Установить Grafana и добавьте источник данных (data source) типа Prometheus, указав URL до Prometheus.

4. Импорт дашбордов:В Grafana есть несколько готовых дашбордов для ClickHouse:
  - Официальный дашборд от ClickHouse: https://github.com/ClickHouse/clickhouse-presentations/tree/master/grafana
  - Дашборд от Percona: https://grafana.com/grafana/dashboards/882

Или можно создать свой дашборд, используя следующие ключевые метрики:
- Общее состояние кластера (количество нод, их версии, uptime)
- Запросы в секунду (разбивка по типу)
- Задержка запросов (средняя, 95-й и 99-й перцентили)
- Использование памяти (разбивка по типам: резидентная, для запросов, для кэшей)
- Активность слияний (мержей) и мутаций
- Количество реплик и их отставание (для реплицируемых таблиц)
- Использование дискового пространства
- Сетевой трафик (ввод/вывод)
- Количество открытых файлов

Пример запроса в Grafana для количества SELECT-запросов в секунду:
```
rate(ClickHouseProfileEvents_Query[5m])
```
или, если используется метрика из `system.events`:
```
rate(ClickHouseMetrics_Query[5m])
```
Для мониторинга репликации можно использовать метрики из system.replicas, например, отставание реплики:
```
ClickHouseMetrics_ReplicasMaxAbsoluteDelay
```

5. Настройка алертинга
В Prometheus или Grafana можно настроить алерты на критические состояния:
- Отсутствие метрик от ClickHouse (нода недоступна)
- Слишком много ошибок запросов
- Высокая загрузка CPU или памяти
- Заканчивается место на диске
- Отставание репликации выше порога
- Медленные запросы (перцентиль 95 выше порога)