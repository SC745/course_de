<h2>Apache Kafka</h2>
<h3>1. Архитектура и компоненты</h3>
<h4>Основные понятия</h4>

Apache Kafka — это распределённая система для потоковой обработки данных, широко используемая в качестве компонента платформ работы с большими данными, в особенности в режиме реального времени. Kafka представляет собой распределённую систему, ориентированную на потоки данных. Основной элемент архитектуры — это кластер, который состоит из нескольких брокеров. Данные в топиках разбиваются на партиции, которые распределяются и реплицируются между брокерами кластера. Это обеспечивает высокую доступность и параллельную обработку данных. Kafka использует простую модель хранения — все данные представляют собой последовательности байтов, что делает Kafka очень гибкой и высокопроизводительной системой.

Компоненты Apache Kafka:
- Продюсеры (Producers): Клиенты или приложения, которые публикуют (отправляют) данные в топики Kafka, аналогично папкам в файловой системе.
- Консьюмеры (Consumers): Подписываются на один или несколько топиков и читают данные в режиме реального времени. Kafka поддерживает модель чтения "откуда угодно", что позволяет консьюмерам управлять своим смещением в сообщении, и начинать чтение с любой точки. Консьюмеры в Kafka могут объединяться в группы. Kafka гарантирует, что сообщение из определенной партиции будет обработано только одним участником группы, что позволяет масштабировать обработку данных и обеспечивает балансировку нагрузки между консьюмерами в группе.
- Топики (Topics): Особая область, в котором хранятся данные. Топики в Kafka разделены на несколько партиций, что позволяет работать с данными в параллельном режиме.
- Партиции (Partitions): Каждый топик в Kafka может быть разделён на несколько партиций. Партицирование позволяет распределить данные по нескольким узлам и таким образом повысить производительность за счёт параллельной обработки.
- Брокеры (Brokers): Серверы, которые хранят данные и обслуживают клиентские запросы. Кластер Kafka состоит из одного или нескольких брокеров. Брокеры отвечают за хранение данных и их репликацию для обеспечения отказоустойчивости.
- ZooKeeper: Используется для управления и координации брокеров Kafka. Он отслеживает состояние кластера Kafka, определяет стратегию выбора лидера партиций, а также управляет состоянием конфигураций.
- Kafka Connect: Инструмент для интеграции Kafka с другими приложениями, например, базами данных, системами очередей и др. Kafka Connect позволяет легко и надёжно передавать данные между Kafka и другими системами.
- Kafka Streams: Библиотека для разработки приложений и микросервисов, которые обрабатывают потоки данных. Она позволяет легко писать приложения, которые обрабатывают данные в режиме реального времени.

<h4>Преимущества использования для обработки потоковых дынных</h4>

Apache Kafka стала стандартом для обработки потоковых данных в реальном времени. Вот ее ключевые преимущества:
- Высокая пропускная способность и низкая задержка: Kafka способна обрабатывать огромные объемы данных с минимальной задержкой (миллисекунды). Это достигается за счет эффективной структуры данных (log) и последовательного ввода/вывода.
- Масштабируемость: Kafka легко масштабируется горизонтально. Вы можете добавлять брокеры в кластер без простоев. Топики могут быть разделены на партиции, что позволяет параллельно обрабатывать данные.
- Отказоустойчивость и надежность: Данные реплицируются across несколькими брокерами, поэтому при отказе одного или нескольких брокеров данные не теряются, и система продолжает работать.
- Поддержка множества производителей и потребителей: Kafka позволяет множеству производителей записывать данные в топики, и множеству потребителей (в том числе в разных группах) читать эти данные. Это делает ее идеальной для построения сложных потоковых пайплайнов.
- Сохранение сообщений: Сообщения в Kafka сохраняются на диск и могут храниться длительное время (настраивается). Это позволяет повторно обрабатывать данные, если это необходимо.
- Интеграция с экосистемой: Kafka имеет богатую экосистему, включая Kafka Connect для интеграции с внешними системами и Kafka Streams для потоковой обработки.
- Гарантия порядка доставки: В пределах одной партиции Kafka гарантирует порядок сообщений. Это важно для многих приложений, где порядок имеет значение.

<h4>Продюсеры и консьюмеры</h4>

Управление потоками данных в Apache Kafka централизовано вокруг двух основных компонентов: продюсеров (producers) и консьюмеров (consumers). Эти компоненты играют ключевую роль в публикации и чтении данных, соответственно.

Продюсеры — это клиенты или приложения, которые отправляют (публикуют) сообщения в топики Kafka. Ключевые аспекты работы продюсеров:
- Конфигурация: Продюсеры могут быть настроены для обеспечения различных гарантий доставки и производительности. Основные параметры конфигурации включают:
  - `acks`: контролирует, сколько подтверждений от брокеров требуется перед тем, как считать сообщение отправленным.
  - `buffer.memory`: размер буфера, который продюсер может использовать для хранения еще не отправленных сообщений.
  - `compression.type`: тип сжатия (например, `none`, `gzip`, `snappy`, `lz4`), который продюсер использует для уменьшения размера данных.
- Отправка сообщений: Продюсеры могут отправлять сообщения в Kafka синхронно или асинхронно:
  - Синхронная отправка обеспечивает, что приложение будет ждать подтверждения от Kafka перед продолжением выполнения.
  - Асинхронная отправка позволяет продюсеру продолжить обработку, пока сообщения отправляются в фоновом режиме.
- Партиционирование: Продюсеры могут напрямую управлять распределением сообщений по партициям через указание ключа или позволить Kafka выбирать партицию на основе балансировки нагрузки.

Консьюмеры читают сообщения из топиков Kafka. Важные аспекты работы консьюмеров:
- Группы консьюмеров: Консьюмеры могут быть организованы в группы для обеспечения параллельной обработки данных. Kafka контролирует, какие партиции читаются каждым консьюмером в группе, обеспечивая выполнение условия того, что каждая партиция будет обслуживать лишь один консьюмер из группы.
- Управление смещением: Консьюмеры отслеживают смещения (offsets) в логе топика, что позволяет им знать, какие сообщения были уже прочитаны. Это смещение можно контролировать автоматически или вручную, что позволяет реализовать различные сценарии обработки сообщений.
- Перебалансировка: Когда новые консьюмеры присоединяются к группе или когда консьюмеры выходят из строя, Kafka автоматически перераспределяет партиции между доступными консьюмерами.

<h4>Семантики доставки сообщений</h4>

В Apache Kafka существуют три основных семантики доставки сообщений, которые определяют, как система обрабатывает потенциальные дубликаты и потери сообщений в процессе передачи. Выбор между этими семантиками зависит от требований приложения к достоверности и производительности:
- At-least-once (По крайней мере один раз): Эта семантика обеспечивает, что сообщения никогда не будут потеряны (то есть они будут доставлены хотя бы один раз), но это может привести к тому, что некоторые сообщения будут доставлены повторно. Это особенно актуально в случае сбоев сети или компонентов системы, когда сообщение может быть отправлено повторно. Как достигается:
  - Продюсеры: Подтверждение получения каждого сообщения брокером перед отправкой следующего. Если подтверждение не получено, сообщение отправляется повторно.
  - Консьюмеры: Коммит смещений после обработки сообщения. Если консьюмер падает перед коммитом, то после перезапуска он обработает некоторые сообщения повторно.
- At-most-once (Не более одного раза): Сообщения могут быть потеряны, но никогда не будут доставлены повторно. Это минимальная гарантия доставки, при которой производительность системы обычно выше, но с риском потери данных. Как достигается:
  - Продюсеры: Отправка сообщений без ожидания подтверждения от брокера. Если сообщение потеряно в процессе передачи, оно не будет отправлено повторно.
  - Консьюмеры: Коммит смещений перед обработкой сообщения. Это уменьшает риск повторной обработки, но увеличивает вероятность пропуска сообщений при сбое.
- Exactly-once (Точно один раз): Это самая строгая семантика, которая обеспечивает, что каждое сообщение будет обработано ровно один раз — ни одно не потеряется и не будет обработано повторно. Это идеально подходит для сценариев, где дубликаты или потери могут привести к серьёзным проблемам. Как достигается:
  - Продюсеры: Использование транзакционной отправки сообщений, где группа сообщений коммитится как единая транзакция.
  - Консьюмеры: Обеспечение идемпотентности на стороне приемника, так чтобы повторная обработка сообщения не влияла на результат.

<h4>Роль и использование ZooKeeper</h4>

Apache Kafka исторически сильно зависела от Apache Zookeeper, который выступал в роли системы координации и управления для кластера. Однако в последних версиях (Kafka 3.x и выше, и особенно в Kafka 4.0) идет активный переход на встроенный механизм управления, известный как KRaft (Kafka Raft metadata mode), который позволяет Kafka работать без Zookeeper.

Роль Zookeeper в "классической" Kafka (до версии 3.0):
- Хранение метаданных кластера: Список всех брокеров, их адреса и "живы" ли они. Список всех топиков, их конфигурации и список партиций. Сопоставление: какая партиция какого топика на каком брокере находится, и кто для нее лидер.
- Контроль лидерства: Zookeeper управляет выбором лидера для каждой партиции. При падении текущего лидера Zookeeper инициирует процесс выборов нового лидера среди ISR.
- Членство в кластере и обнаружение сбоев: Каждый брокер регистрируется в Zookeeper как "ephemereal узел". Если брокер "умирает", его сессия с Zookeeper разрывается, и узел удаляется. Это служит сигналом для остального кластера о том, что брокер недоступен.
- Конфигурация Access Control Lists (ACLs): Хранение прав доступа к топикам.
- Отслеживание потребителей (для старого Consumer API): Хранение оффсетов (позиций чтения) для потребительских групп.

Почему Kafka уходит от Zookeeper (переход на KRaft)?
- Снижение сложности: Не нужно разворачивать и поддерживать два отдельных распределенных системы.
- Улучшение масштабируемости: Zookeeper мог становиться "бутылочным горлышком" при очень большом количестве партиций (сотни тысяч).
- Повышение производительности: Прямое управление метаданными внутри Kafka делает операции (например, создание топиков, выборы лидера) быстрее.
- Упрощенная безопасность: Единая модель безопасности для всего.

<h4>Механизм репликации данных</h4>

Репликация — это фундаментальный механизм в Kafka, обеспечивающий отказоустойчивость и доступность данных. Ключевые понятия:
- Топик (Topic): Логический канал, в который публикуются сообщения.
- Партиция (Partition): Топик делится на партиции для горизонтального масштабирования и параллельной обработки. Каждая партиция — это упорядоченная, неизменяемая последовательность сообщений.
- Реплика (Replica): Каждая партиция реплицируется (копируется) на несколько брокеров (серверов Kafka) для надежности.
- Лидер (Leader): Для каждой партиции один из брокеров назначается лидером. Все операции чтения и записи для этой партиции идут только через лидера.
- Фолловер (Follower) или In-Sync Replica (ISR): Остальные реплики партиции являются фолловерами. Они постоянно синхронно копируют (pull) данные с лидера.

Как работает репликация:
1. Назначение лидера: Kafka динамически выбирает одного лидера для партиции. Все остальные реплики становятся фолловерами.
2. Процесс записи: Производитель (Producer) отправляет сообщения только лидеру партиции. Лидер записывает сообщение в свой локальный log. Фолловеры постоянно опрашивают лидера, запрашивая новые сообщения. Когда лидер получает запрос от фолловера, он отправляет ему новые сообщения.
3. Подтверждение записи (Acknowledgment): Производитель может настраивать уровень надежности через параметр `acks`:
  - `acks=0`: "Отправил и забыл". Подтверждение не требуется. Высокая скорость, но риск потери данных.
  - `acks=1`: Лидер подтверждает запись после того, как сохранил сообщение у себя. Данные могут быть потеряны, если лидер "умрет" до того, как фолловеры успеют скопировать данные.
  - `acks=all`: Лидер ждет подтверждения от всех реплик, входящих в ISR (In-Sync Replica), прежде чем отправить подтверждение производителю. Это гарантирует, что сообщение не будет потеряно, даже если лидер "умрет". Наиболее надежный, но менее производительный режим.
4. In-Sync Replicas (ISR): Это набор реплик, которые "последними" синхронизировались с лидером (имеют небольшую задержку). Реплика, которая отстает слишком сильно (например, из-за проблем с сетью или брокером), временно исключается из ISR.
5. Восстановление при сбое: Если лидер партиции выходит из строя, один из фолловеров (обязательно из ISR) автоматически становится новым лидером. Это обеспечивает непрерывность работы без потери данных (при `acks=all`).

<h4>Стратегии балансировки нагрузки</h4>

Балансировка нагрузки в Kafka происходит на уровне потребительских групп (Consumer Groups). Группа потребителей — это набор потребителей, которые совместно обрабатывают сообщения из одного или нескольких топиков. Каждая партиция топика в любой момент времени потребляется только одним потребителем из группы. Но один потребитель может читать данные из нескольких партиций.

Процесс ребалансировки (Rebalancing): Это процесс перераспределения владения партициями между потребителями в группе. - Он запускается в следующих случаях:
- Подключился новый потребитель.
- Один из потребителей отключился (аварийно или штатно).
- Добавились новые партиции в топик.
- Изменилась подписка группы.

Стратегии балансировки (Partition Assignment Strategies):
- Range Assignor (По диапазонам): Партиции каждого топика сортируются, а потребители сортируются по имени. Затем партиции делятся на диапазоны, и каждый потребитель получает свой диапазон. Стратегия по умолчанию. Может привести к дисбалансу, особенно когда много топиков с малым числом партиций. Один потребитель может получить ощутимо больше партиций, чем другой. Например: У нас 2 топика (T1, T2), в каждом по 3 партиции (P0, P1, P2), и 2 потребителя (C1, C2). C1 получит [T1-P0, T1-P1, T2-P0, T2-P1], а C2 получит [T1-P2, T2-P2].
- RoundRobin Assignor (Циклическая): Все партиции всех топиков, на которые подписана группа, и все потребители собираются в один "котел". Затем партиции по одной по кругу распределяются между потребителями. Обычно обеспечивает более сбалансированное распределение, чем Range, но может нарушить локальность данных, если потребитель подключен к конкретному брокеру. Например: У нас 2 топика (T1, T2), в каждом по 3 партиции (P0, P1, P2), и 2 потребителя (C1, C2). C1 получит [T1-P0, T1-P2, T2-P1], а C2 получит [T1-P1, T2-P0, T2-P2].
- StickyAssignor ("Липкая" стратегия): Эта стратегия сочетает в себе равномерность RoundRobin и минимальное перемещение партиций при ребалансировке. При ребалансировке она старается оставить как можно больше партиций за их старыми потребителями, перераспределяя только необходимое для выравнивания нагрузки. Более сбалансированное распределение, чем у Range, меньшие накладные расходы при ребалансировке, так как уменьшается количество партиций, которые нужно "переселить" (и, как следствие, количество повторной обработки сообщений или сброса кэшей). StickyAssignor часто является наилучшим выбором для большинства случаев, так как минимизирует негативное влияние ребалансировок.
- Cooperative Sticky Assignor (Кооперативная "липкая" стратегия): Это улучшенная версия StickyAssignor, которая поддерживает инкрементную ребалансировку. При ребалансировке потребители не должны отключаться от всей группы. Они могут продолжать обрабатывать свои текущие партиции, пока координатор группы перераспределяет только те партиции, которые необходимо переместить. Это делает процесс ребалансировки гораздо более плавным и с меньшим временем простоя. Это стратегия по умолчанию в новых версиях Kafka и настоятельно рекомендуется к использованию.

Стратегия выбирается на стороне потребителей (параметр `partition.assignment.strategy`).

<h4>Управление смещением</h4>

Смещение (offset) — это уникальный идентификатор для каждого сообщения в партиции. Управление смещением — это механизм, который позволяет потребителям отслеживать, какие сообщения они уже прочитали. Потребители (consumers) читают сообщения из партиций топика. Каждый потребитель в группе читает из своих назначенных партиций. После прочтения сообщения потребитель может зафиксировать (commit) смещение, чтобы отметить, что сообщение было обработано. Смещения хранятся в специальном топике `__consumer_offsets`.

Существует два основных подхода к управлению смещением:
- Автоматическая фиксация (Auto-commit): Потребитель автоматически фиксирует смещения с заданным интервалом (например, каждые 5 секунд). Это просто, но может привести к потере сообщений или повторной обработке, если потребитель fails в промежутке между фиксациями.
- Ручная фиксация (Manual commit): Потребитель сам решает, когда фиксировать смещение. Это может быть сделано синхронно (commitSync) или асинхронно (commitAsync). Ручная фиксация дает больше контроля, но требует больше кода.

Важные моменты:
- Если потребитель фиксирует смещение, а затем не может обработать сообщение (например, из-за ошибки в приложении), то сообщение может быть пропущено. Поэтому часто фиксацию делают после успешной обработки сообщения.
- При ребалансировке потребительской группы, каждый новый потребитель начинает читать с последнего зафиксированного смещения для своей партиции.
- Можно также управлять смещением вручную, используя `seek()`, чтобы перечитать сообщения или пропустить некоторые.

<h4>Восстановление данных после сбоя</h4>

Kafka разработана для обработки сбоев и обеспечения надежности данных. Вот как она справляется с различными типами сбоев:
- Сбой брокера (Broker failure): Kafka реплицирует данные на несколько брокеров. Каждая партиция имеет одного лидера и несколько реплик-последователей (followers). Если лидер выходит из строя, одна из реплик-последователей (которая входит in-sync replicas, ISR) становится новым лидером. Это происходит автоматически. Потребители и производители перенаправляются к новому лидеру.
- Сбой диска (Disk failure): Рекомендуется использовать RAID или другие методы избыточности дисков, чтобы избежать потери данных из-за сбоя диска. Также репликация между брокерами защищает от потери данных при сбое всего брокера.
- Сбой сети (Network failure): Если брокер становится недоступным из-за сетевых проблем, он будет исключен из ISR. Когда сеть восстанавливается, брокер переподключается к кластеру и синхронизирует данные, после чего может быть снова добавлен в ISR.
- Сбой потребителя (Consumer failure): Потребители в группе периодически отправляют сердцебиения (heartbeats) координатору группы. Если потребитель перестает отправлять сердцебиения, координатор инициирует ребалансировку, и партиции, которые потреблял этот потребитель, перераспределяются между остальными потребителями в группе. При этом чтение продолжается с последних зафиксированных смещений.
- Сбой производителя (Producer failure): Производители могут быть настроены на повторную отправку сообщений в случае ошибки. Также они могут использовать идемпотентность (idempotence) и транзакции, чтобы избежать дублирования и обеспечить exactly-once семантику.
- Восстановление данных после потери: Если данные были потеряны на одном брокере (например, из-за сбоя диска), они могут быть восстановлены из реплик на других брокерах. Если данные потеряны на всех репликах (что маловероятно при достаточном факторе репликации), то восстановление невозможно. Поэтому важно выбирать соответствующий фактор репликации (обычно 3) и мониторить состояние кластера.

<h3>2. Основные концепции и использование</h3>
<h4>Оптимизация хранения сообщений</h4>

Kafka хранит сообщения в логах (логах партиций) на диске. Оптимизация включает:
- Сжатие (Compression): Kafka позволяет сжимать сообщения для уменьшения объема хранимых данных и сетевого трафика. Поддерживаемые кодеки: gzip, snappy, lz4, zstd. Сжатие может быть настроено на продюсере (то есть сообщения сжимаются перед отправкой) или на брокере (сжатие при записи). Сжатие на продюсере обычно более эффективно, так как снижает нагрузку на сеть и брокеры.
- Срок хранения (Retention): Сообщения в Kafka хранятся ограниченное время (по умолчанию 7 дней) или до достижения определенного размера лога. По истечении срока или при превышении размера старые сегменты лога удаляются. Также можно настроить политику удаления на основе времени бездействия (`log.retention.ms` по умолчанию не установлен). Настройки:
  - `log.retention.hours` (также есть минуты, дни)
  - `log.retention.bytes` (максимальный размер лога на партицию)
- Управление логами (Log Management): Лог партиции разбивается на сегменты (segments). Новые сообщения записываются в активный сегмент. Когда активный сегмент достигает размера (настройка `log.segment.bytes`) или времени (настройка `log.roll.ms / log.roll.hours`), он закрывается и открывается новый. Очистка лога (log cleanup) происходит путем удаления старых сегментов. Также существует политика "compaction" (уплотнение) для топиков с ключами, которая оставляет только последнее значение для каждого ключа.

Размер лога (количество данных, хранимых в партиции) напрямую влияет на производительность и использование диска:
- Размер сегментов: Большие сегменты уменьшают частоту создания новых файлов, но могут увеличить время восстановления после сбоя и задержку при удалении (так как удаляются целые сегменты). Маленькие сегменты приводят к большему количеству файлов, что может негативно сказаться на производительности файловой системы.
- Ретеншн политики: Длительное хранение (большой размер лога) требует больше дискового пространства и может увеличить время восстановления партиции при переподключении реплики или перезапуске брокера. Короткое хранение уменьшает объем данных, но может привести к потере сообщений, если потребитель не успел их обработать.
- Влияние на производительность: Чем больше лог, тем дольше могут выполняться операции чтения с диска (особенно если чтение происходит с конца, а данные в начале лога уже не в кэше). Однако Kafka оптимизирована для последовательного чтения и записи. Размер лога также влияет на время ребалансировки потребителей: при смене потребителя ему может потребоваться прочитать большой объем данных с начала лога (если он отстал).
