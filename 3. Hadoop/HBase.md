<h2>HBase</h2>
<h3>1. Архитектура и модель данных</h3>
<h4>Основные понятия</h4>

HBase — распределенная и масштабируемая база данных, основанная на технологии Hadoop и HDFS. Она предназначена для хранения и обработки больших объемов структурированных данных в режиме реального времени. HBase использует модель данных, схожую с Google's Bigtable, и предлагает возможности по работе с большими данными, которые не поддерживаются традиционными реляционными базами данных.

Модель данных HBase:
- Таблицы: Данные в HBase хранятся в таблицах. Каждая таблица состоит из строк и столбцов.
- Строки: Каждая строка идентифицируется уникальным ключом (Row Key). Строки автоматически сортируются по ключу строки, что обеспечивает быстрый доступ к данным.
- Столбцы: Столбцы группируются в семейства столбцов (HColumnFamily), которые должны быть объявлены заранее при создании таблицы. В пределах одного семейства столбцов можно динамически добавлять столбцы.
- Ячейки: Каждая ячейка данных в таблице определяется уникальной комбинацией ключа строки, семейства столбцов, идентификатора столбца и временной метки. Ячейки могут содержать несколько версий одних и тех же данных, отличающихся по временной метке.

Архитектура HBase:
- HMaster: Управляет кластером, назначает регионы региональным серверам, контролирует сбои и обеспечивает балансировку нагрузки.
- RegionServer: Обрабатывают запросы к данным, каждый из них управляет определенным набором регионов.
- Region: Таблицы в HBase делятся на регионы для распределения данных по кластеру. Каждый регион содержит строки таблицы в определенном диапазоне ключей.
- HDFS: HBase хранит данные в Hadoop Distributed File System (HDFS), что обеспечивает надежность и масштабируемость.

HBase идеально подходит для:
- Хранения больших объемов разреженных данных: Например, веб-таблицы, где у каждого сайта много возможных атрибутов, но заполнены лишь некоторые.
- Систем, требующих случайного доступа на чтение/запись: Сервисы обмена сообщениями, почтовые ящики.
- Систем, собирающих данные с временными рядами: Метрики с датчиков IoT, лог-файлы, история транзакций.
- В качестве "горячего" хранилища поверх Hadoop: Быстрый доступ к результатам агрегации или предварительно обработанным данным из HDFS.

<h4>Назначение и структура Column Family</h4>

В HBase данные организованы в таблицы, которые состоят из строк и столбцов. Но в отличие от реляционных баз, столбцы группируются в семейства столбцов (Column Families). Семейство столбцов (Column Family, CF) — это основная единица физического хранения и настройки производительности в HBase. Это логическая группировка столбцов, которые имеют общие характеристики и часто применяются вместе.

Ключевые аспекты назначения:
- Физическая группировка: Все столбцы из одного семейства хранятся вместе в файловой системе (в одних и тех же HFiles). Это позволяет эффективно читать данные из одного семейства, не загружая данные из других.
- Точка настройки: Все параметры хранения задаются на уровне семейства столбцов, а не отдельного столбца или строки:
  - Сжатие (GZIP, LZO, Snappy)
  - Версионность (количество хранимых версий значения для одной ячейки)
  - Время жизни (TTL) для автоматического удаления устаревших данных
  - Размер блока для кэширования
  - Bloom filters для ускорения поиска строк
- Семантическая группировка: Позволяет логически организовать данные. Например, в таблице `users` можно создать семейства `profile_data` (имя, email) и `activity_data` (последний вход, количество действий).

Логическая модель данных в HBase выглядит так:
```bash
Table: 'users'
Row Key: 'user123'
    Column Family: 'profile_data'
        Column Qualifier: 'name'    -> Value: 'John Doe', Timestamp: t3
        Column Qualifier: 'email'   -> Value: 'john@mail.com', Timestamp: t2
    Column Family: 'activity_data'
        Column Qualifier: 'last_login' -> Value: '2023-10-27', Timestamp: t1
        Column Qualifier: 'login_count' -> Value: '42', Timestamp: t1
```

Где:
- Row Key: `user123` — уникальный идентификатор строки.
- Column Family: `profile_data` и `activity_data` — заранее объявленные группы.
- Column Qualifier: `name`, `email`, `last_login` — динамические метки столбцов внутри семейства. Они создаются "на лету" при записи.

Имена семейств столбцов должны быть короткими строковыми константами (например, cf1, d, info), так как они повторяются для каждой ячейки. Имена квалификаторов столбцов могут быть любыми.

<h4>Процесс чтения и записи</h4>

Процесс чтения данных:
1. Клиент отправляет запрос get или scan к HRegionServer.
2. HRegionServer направляет запрос в соответствующий Region.
3. Region сначала проверяет BlockCache (кэш чтения) на наличие часто читаемых данных.
4. Если данных нет в BlockCache, происходит поиск в MemStore (данные, которые еще не сброшены на диск) и затем в HFile (данные на диске).
5. Поскольку данные в MemStore и HFile отсортированы по ключу, поиск происходит быстро (бинарный поиск в HFile).
6. Если включен Bloom Filter, он используется для проверки отсутствия данных в HFile, что уменьшает количество дисковых операций.
7. Данные из HFile могут быть закэшированы в BlockCache для последующих чтений.
8. Клиент получает результат.

Процесс записи данных:
1. Клиент отправляет запрос put к соответствующему HRegionServer (найденному через hbase:meta таблицу).
2. HRegionServer получает запрос и направляет его в соответствующий Region.
3. Region сначала записывает данные в Write-Ahead Log (WAL) для обеспечения надежности. WAL хранится в HDFS.
4. Затем данные помещаются в MemStore (в памяти) региона. MemStore отсортирован по ключу.
5. Когда MemStore достигает определенного размера (настраивается), его содержимое сбрасывается (flush) в новый HFile на HDFS.
6. Клиент получает подтверждение об успешной записи.

<h4>HLog и HFile</h4>

HLog (также известный как WAL — Write-Ahead Log) — это механизм записи операций в лог-файл перед их применением в памяти (MemStore). Каждый регион-сервер в HBase имеет один общий HLog. Его назначение - обеспечение надежности и долговечности данных при операциях записи.

Принцип работы:
1. Когда клиент отправляет запрос на запись (например, PUT), он сначала попадает в HRegionServer.
2. Перед тем как данные будут записаны в MemStore (в оперативную память), операция записывается в WAL на HDFS.
3. Только после успешной записи в WAL данные помещаются в MemStore.
4. Клиент получает подтверждение об успешной записи.

Если HRegionServer неожиданно падает, данные из его MemStore (которые находятся в RAM) теряются. При перезапуске система обнаруживает, что некоторые данные из WAL не были применены к постоянным HFiles, и воспроизводит (replays) журнал, восстанавливая тем самым потерянные операции.

HFile — это внутренний формат файлов хранения данных в HBase, основанный на формате SSTable (Google BigTable). Данные в HFile отсортированы по ключу (RowKey) и хранятся в HDFS.

Принцип работы:
1. Когда MemStore достигает определенного размера, его содержимое сбрасывается (flushed) на диск в виде нового HFile.
2. Со временем для одного региона и одного семейства столбцов накапливается множество маленьких HFile.
3. Процесс компактизации (Compaction) объединяет маленькие HFile в один большой, отсортированный HFile. Это улучшает производительность чтения и освобождает место (удаляя старые версии и удаленные ячейки).

Связь HLog и HFile:
- HLog — это последовательный журнал операций для надежности. Он быстро растет и periodically архивируется после успешного сброса MemStore в HFile.
- HFile — это отсортированное, индексированное хранилище для эффективного чтения. Это итоговое место хранения ваших данных.

<h4>TTL и Bloom Filter</h4>

TTL (Time-to-Live) - это механизм автоматического удаления данных по истечении заданного времени. В HBase TTL задается на уровне семейства столбцов (Column Family). HBase хранит метку времени (timestamp) для каждой ячейки. При чтении данных, если текущее время превышает timestamp + TTL, то такие ячейки не возвращаются и впоследствии удаляются в процессе компакции (compaction). TTL задается в секундах. Можно установить при создании таблицы или изменении семейства столбцов.

```bash
# Создание таблицы с TTL = 30 дней (2592000 секунд) для семейства столбцов 'cf1'
create 'mytable', {NAME => 'cf1', TTL => 2592000}

# Изменение существующей таблицы для установки TTL
alter 'mytable', NAME => 'cf1', TTL => 2592000
```

Важные моменты:
- TTL применяется к каждой ячейке индивидуально. Время отсчитывается от timestamp ячейки (который обычно устанавливается в момент записи).
- TTL не гарантирует немедленное удаление. Устаревшие данные удаляются во время компакции.
- Если TTL не задан, данные хранятся вечно.

Bloom Filter - это вероятностная структура данных, используемая для проверки отсутствия элемента в наборе. В HBase Bloom Filter помогает уменьшить количество дисковых операций при чтении данных. Bloom Filter хранит битовый массив и использует несколько хэш-функций для каждого ключа. При запросе ключа, если Bloom Filter говорит, что ключа нет, то это точно так. Если говорит, что ключ есть, то это может быть ошибка (ложное срабатывание), но тогда мы проверим данные на диске. Задается на уровне семейства столбцов.

Типы Bloom Filter в HBase:
- `NONE`: Не использовать Bloom Filter.
- `ROW`: Использует Row Key для построения фильтра. Подходит для запросов по полному ключу строки.
- `ROWCOL`: Использует Row Key и Column Qualifier для построения фильтра. Подходит для запросов по конкретному столбцу в строке.

```bash
# Создание таблицы с Bloom Filter типа ROW для семейства 'cf1'
create 'mytable', {NAME => 'cf1', BLOOMFILTER => 'ROW'}

# Или типа ROWCOL для более точной фильтрации
alter 'mytable', NAME => 'cf1', BLOOMFILTER => 'ROWCOL'
```

<h4>Split и Compact</h4>

Split (Разделение регионов) - применяется когда регион становится слишком большим, чтобы распределить нагрузку и обеспечить масштабируемость.

Принцип работы:
1. Когда размер региона превышает заданный порог (`hbase.hregion.max.filesize`, по умолчанию 10 ГБ), HRegionServer инициирует разделение.
2. Регион разделяется на два примерно равных по размеру региона. Разделение происходит по ключу (например, по середине диапазона ключей).
3. Новые регионы создаются вначале в состоянии "offline", затем их метаданные обновляются в таблице `hbase:meta`.
4. HMaster назначает новые регионы на другие RegionServer (балансировка нагрузки).

Стратегии разделения:
- SteppingSplitPolicy (по умолчанию с HBase 0.94): Умная стратегия, учитывающая количество регионов на сервере, постепенно увеличивает порог разделения
- ConstantSizeRegionSplitPolicy: Разделяет при достижении фиксированного размера. Простая, но может создавать неравномерное распределение
- KeyPrefixRegionSplitPolicy: Разделяет по префиксам ключей, что может быть полезно когда префикс определяет логическую группу

Автоматическое разделение можно отключить, а также можно выполнить разделение вручную через HBase Shell: 
```bash
split 'table_name', 'split_key'
```

Compact (Компактизация) - применяется для объединения нескольких маленьких HFile в один большой, удаляя при этом удаленные и устаревшие (по TTL) ячейки. Множество маленьких файлов неэффективно для чтения (много seek операций) и занимает больше места из-за накладных расходов.

Типы компактизации:
- Minor Compact - объединяет несколько маленьких HFile в один большой, но не обязательно удаляет все удаленные данные и не объединяет все файлы. Выполняется автоматически при достижении определенного количества HFile.
- Major Compact - объединяет все HFile региона в один HFile, при этом полностью удаляются удаленные ячейки (с пометкой на удаление) и устаревшие версии (сверх заданного количества версий). Major compact требует значительных ресурсов и обычно планируется на время низкой нагрузки.

Автоматическая компактизация настраивается через параметры:
- `hbase.hstore.compactionThreshold` - минимальное количество HFile для запуска minor compact (по умолчанию 3)
- `hbase.hstore.compaction.max` - максимальное количество HFile, объединяемых за одну компактизацию (по умолчанию 10)
- `hbase.hregion.majorcompaction` - интервал между major compact (по умолчанию 7 дней)

В HBase Shell можно запустить компактизацию вручную:
- `compact 'table_name'` - minor compact
- `major_compact 'table_name'` - major compact

Major compact может быть ресурсоемким и в это время регион может быть недоступен для чтения/записи, поэтому в production-окружении его часто запускают вручную в подходящее время.

Процессы Split и Compact работают вместе для поддержания производительности и распределения данных. Split распределяет данные по кластеру, а Compact оптимизирует хранение данных внутри региона.

<h4>Роль ZooKeeper в HBase</h4>

ZooKeeper — это распределенный сервис, который является "мозговым центром" и единым источником истины для всего кластера HBase. Без ZooKeeper кластер HBase не сможет функционировать как согласованная распределенная система. Он обеспечивает необходимый уровень координации, обнаружения сбоев и хранения критически важной метаинформации.

Ключевые роли ZooKeeper в HBase:
- Координация и выбор Лидера (Leader Election) для HMaster: В кластере может быть запущено несколько HMaster'ов для отказоустойчивости. ZooKeeper гарантирует, что в любой момент времени активен только один ("Leader"). Если активный HMaster падает, ZooKeeper немедленно инициирует выборы нового лидера.
- Регистрация и мониторинг HRegionServer: Каждый HRegionServer при запуске создает в ZooKeeper эфемерный узел (ephemeral node). HMaster "подписывается" на эти узлы и отслеживает состояние всех RegionServer'ов через механизм "heartbeat". Если связь с RegionServer'ом теряется (узел удаляется), ZooKeeper немедленно уведомляет HMaster, который запускает процедуру восстановления регионов этого сервера.
- Хранилище критических метаданных (Metadata Gateway): ZooKeeper хранит расположение корневой таблицы `hbase:meta`. Эта таблица — карта всего кластера. В ней содержится информация о том, какой регион какой таблицы обслуживается каким RegionServer'ом. Процесс обращения клиента:
  - Клиент сначала обращается к ZooKeeper, чтобы узнать, где находится `hbase:meta`.
  - Затем клиент обращается к соответствующему RegionServer'у, чтобы прочитать `hbase:meta` и узнать расположение нужного ему региона данных.
  - Получив эту информацию, клиент кэширует ее и обращается напрямую к нужному RegionServer'у.
- Распределенная синхронизация: ZooKeeper помогает координировать распределенные операции, такие как разделение регионов (region splitting), когда требуется заблокировать родительский регион перед созданием дочерних.

<h3>2. Работа с HBase</h3>
<h4>CRUD операции</h4>

CRUD в HBase имеет свои особенности по сравнению с реляционными БД:
- Create - `create`, `put` (создание и обновление)
- Read - `get`, `scan`
- Update - `put` (перезапись версии)
- Delete - `delete`

Особенности модели данных:
- Данные идентифицируются по: Row Key + Column Family + Column Qualifier + Timestamp
- Операции атомарны в пределах одной строки
- Отсутствуют транзакции между разными строками
- Версионность позволяет хранить несколько значений для одной ячейки

<h4>Создание таблиц</h4>

Таблицы в HBase создаются с указанием имен семейств столбцов (column families). При создании таблицы необходимо задать ее имя и минимум одно семейство столбцов.

Создание таблицы:
```bash
# В HBase Shell
create 'users', 'profile', 'contacts', 'activity'

# С дополнительными параметрами
create 'users',
  {NAME => 'profile', VERSIONS => 3, TTL => 2592000},  # 30 дней TTL
  {NAME => 'contacts', VERSIONS => 1},
  {NAME => 'activity', VERSIONS => 10, BLOOMFILTER => 'ROW'}
```

Параметры семейств столбцов:
- `VERSIONS` - количество хранимых версий
- `TTL` - время жизни данных в секундах
- `BLOOMFILTER` - ускорение поиска (`ROW`, `ROWCOL`)
- `COMPRESSION` - алгоритм сжатия (`SNAPPY`, `GZIP`, `LZ4`)


<h4>Вставка данных</h4>

Вставка данных в HBase выполняется с помощью операции `put`:
```bash
# Базовый синтаксис: put 'таблица', 'row_key', 'семейство:квалификатор', 'значение'

# Вставка основных данных
put 'users', 'user001', 'profile:name', 'Иван Иванов'
put 'users', 'user001', 'profile:age', '30'
put 'users', 'user001', 'contacts:email', 'ivan@mail.com'
put 'users', 'user001', 'contacts:phone', '+79161234567'
put 'users', 'user001', 'activity:last_login', '2023-10-27 14:30:00'

# Вставка данных для другого пользователя
put 'users', 'user002', 'profile:name', 'Мария Петрова'
put 'users', 'user002', 'profile:age', '25'
put 'users', 'user002', 'contacts:email', 'maria@mail.com'

# Вставка нескольких столбцов за операцию:
put 'users', 'user003',
    'profile:name', 'Петр Сидоров',
    'profile:age', '35',
    'contacts:email', 'petr@mail.com'
```

Особенности операции `put`:
- Если строка не существует - она создается
- Если строка существует - значение обновляется


<h4>Чтение данных</h4>

HBase хранит несколько версий (настраивается на уровне семейства столбцов), и по умолчанию при чтении возвращается последняя версия. Также можно читать старые версии, указывая timestamp. Вставка данных выполняется с помощью операций `get` и `scan`.

`get` - чтение одной строки:
```bash
get 'users', 'user001'                                               # Получить всю строку
get 'users', 'user001', 'profile'                                    # Получить конкретное семейство столбцов
get 'users', 'user001', 'profile:name', 'contacts:email'             # Получить конкретные столбцы
get 'users', 'user001', {COLUMN => 'profile:name', VERSIONS => 3}    # Получить несколько версий значения
```

`scan` - чтение диапазона строк:
```bash
scan 'users'                                                     # Сканировать всю таблицу
scan 'users', {COLUMNS => 'profile'}                             # Сканировать с фильтрацией по семейству столбцов
scan 'users', {COLUMNS => ['profile:name', 'contacts:email']}    # Сканировать с фильтрацией по конкретным столбцам
scan 'users', {LIMIT => 10}                                      # Сканировать с лимитом
scan 'users', {STARTROW => 'user001', ENDROW => 'user005'}       # Сканировать с диапазоном ключей
scan 'users', {FILTER => "ValueFilter(=, 'binary:Иван')"}        # Сканировать с фильтром по значению
```

<h4>Обновление данных</h4>

В HBase обновление осуществляется путем вставки новой версии значения для того же ключа и столбца. Для этого применяется операция `put`:

```bash
# Обновление значения
put 'users', 'user001', 'profile:age', '31'

# Обновление нескольких значений
put 'users', 'user001',
    'profile:age', '31',
    'contacts:phone', '+79169876543',
    'activity:last_login', '2023-10-28 09:15:00'
```

<h4>Удаление данных</h4>

В HBase есть несколько методов удаления данных:
- `delete` - удаление конкретного значения
- `deleteall` - удаление всей строки
- `truncate` - очистка таблицы


```bash
delete 'users', 'user001', 'contacts:phone'    # Удалить конкретный столбец
delete 'users', 'user001', 'contacts'          # Удалить весь семейство столбцов в строке
deleteall 'users', 'user002'    # Удалить всю строку

# Очистить таблицу (disable -> truncate -> enable)
disable 'users'
truncate 'users'
enable 'users'
```

<h4>Использование фильтров</h4>

В HBase Shell можно использовать фильтры для уточнения запросов при сканировании таблицы. Фильтры позволяют отбирать данные по различным условиям.

Общий синтаксис использования фильтров в команде scan:
```bash
scan 'table_name', {FILTER => "FilterName(argument1, argument2, ...)"}
```

SingleColumnValueFilter - фильтр по значению в определенном столбце:
```bash
scan 'mytable', {FILTER => "SingleColumnValueFilter('cf1', 'name', =, 'binary:John')"}
```

PrefixFilter - фильтр по префиксу ключа строки:
```bash
scan 'mytable', {FILTER => "SingleColumnValueFilter('cf1', 'name', =, 'binary:John')"}
```

ColumnPrefixFilter - фильтр по префиксу в имени столбца:
```bash
scan 'mytable', {FILTER => "ColumnPrefixFilter('addr')"}
```

MultipleColumnPrefixFilter - фильтр по нескольким префиксам имен столбцов:
```bash
scan 'mytable', {FILTER => "MultipleColumnPrefixFilter('addr', 'phone')"}
```

PageFilter - постраничный вывод:
```bash
scan 'mytable', {FILTER => "PageFilter(10)"}
```

TimestampsFilter - фильтр по меткам времени:
```bash
scan 'mytable', {FILTER => "TimestampsFilter(1660000000000, 1660000001000)"}
```

ValueFilter: Фильтр по значению (в любом столбце):
```bash
scan 'mytable', {FILTER => "ValueFilter(=, 'substring:error')"}
```

Комбинирование фильтров: Можно комбинировать несколько фильтров с помощью `AND` и `OR`:
```bash
scan 'mytable', {FILTER => "SingleColumnValueFilter('cf1', 'age', >, 'binary:25')                                                             AND SingleColumnValueFilter('cf1', 'city', =, 'binary:New York')"}
```

<h4>Команды HBase Shell</h4>

CRUD:
- `put` - вставка или обновление данных
- `get` - чтение одной строки
- `scan` - чтение диапазона строк
- `delete` - удаление конкретного значения
- `deleteall` - удаление всей строки

Управление таблицами:
- `list` - список всех таблиц
- `describe 'table_name'` - описание структуры таблицы (семейства столбцов и их параметры)
- `exists 'table_name'` - проверка существования таблицы
- `disable 'table_name'` - отключение таблицы (необходимо для некоторых операций)
- `enable 'table_name'` - включение таблицы
- `is_disabled 'table_name'` - проверка, отключена ли таблица
- `is_enabled 'table_name'` - проверка, включена ли таблица
- `create 'table_name'` - создание таблицы
- `drop 'table_name'` - удаление таблицы (предварительно нужно отключить)
- `екгтсфеу 'table_name'` - очистка таблицы (предварительно нужно отключить)
- `alter 'table_name', ...` - изменение таблицы (добавление/удаление семейств столбцов, изменение параметров)

Пространство имен (Namespaces):
- `list_namespace` - список пространств имен
- `create_namespace 'ns'` - создание пространства имен
- `drop_namespace 'ns'` - удаление пространства имен
- `list_namespace_tables 'ns'` - список таблиц в пространстве имен

Администрирование кластера:
- `status` - статус кластера (количество серверов, средняя нагрузка)
- `version` - версия HBase
- `whoami` - текущий пользователь
- `balance_switch` - управление балансировкой (вкл/выкл)
- `balancer` - запуск балансировщика вручную

Прочие команды:
- `count 'table_name'` - подсчет строк в таблице (может быть долгим для больших таблиц)
- `truncate 'table_name'` - очистка таблицы (disable, drop, create)
- `flush 'table_name'` - принудительный сброс MemStore в HFile
- `compact 'table_name'` - запуск компактизации таблицы
- `split 'table_name'` - разделение всех регионов таблицы (или указанного региона)
- `major_compact 'table_name'` - запуск major compact

<h3>3. Интеграция с Hadoop</h3>
<h4>Основы интеграции и роль HDFS</h4>

HBase тесно интегрирован с Hadoop. Он использует HDFS в качестве файловой системы для хранения данных (HFile) и WAL (Write-Ahead Log). HBase может быть использован как источник данных для MapReduce задач. Существуют классы (например, TableInputFormat и TableOutputFormat) для чтения и записи данных HBase в MapReduce.

HBase также интегрируется с другими компонентами Hadoop, такими как Hive (через HBaseStorageHandler) и Spark (через Spark HBase Connector).

Роль HDFS в HBase:
- HDFS обеспечивает надежное хранение данных HBase. Все данные (HFiles) и логи (WAL) хранятся в HDFS.
- HDFS обеспечивает отказоустойчивость: данные реплицируются across multiple nodes.
- HDFS обеспечивает масштабируемость: можно добавлять узлы для увеличения объема хранилища и пропускной способности.

Важно отметить, что HBase не использует HDFS для произвольных запросов, а использует его как надежное хранилище, а быстрый доступ обеспечивается за счет собственных индексов и структуры данных в памяти (MemStore) и на диске (HFile).

<h4>Репликация</h4>

Репликация в HBase позволяет асинхронно реплицировать данные из одного кластера HBase (источник) в другой (приемник). Это используется для аварийного восстановления, географического распределения данных и анализа данных без воздействия на основной кластер. Репликация работает путем чтения WAL исходного кластера и применения изменений в целевом кластере.

Типы репликации:
- Master-Slave: один источник, один или несколько приемников.
- Master-Master: взаимная репликация между двумя кластерами.

Настройка репликации (hbase-site.xml):
```xml
<property>
  <name>hbase.replication</name>
  <value>true</value>
</property>
```

Включение репликации для таблицы:
```bash
disable 'user_actions'
alter 'user_actions', {NAME => 'actions', REPLICATION_SCOPE => '1'}
enable 'user_actions'
```

<h4>Интеграция с Hive</h4>

Hive предоставляет SQL-подобный интерфейс (HiveQL) для запросов к данным, хранящимся в HDFS и других хранилищах, включая HBase. Для интеграции Hive с HBase используется HBaseStorageHandler, который позволяет отображать таблицу HBase как внешнюю таблицу в Hive.

Пример создания таблицы Hive, связанной с таблицей HBase:
```sql
CREATE EXTERNAL TABLE hbase_table_employee(key int, value string)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:name")
TBLPROPERTIES ("hbase.table.name" = "employee");
```

В этом примере:
- `hbase_table_employee` — имя таблицы в Hive.
- `key` и `value` — столбцы в Hive, которые отображаются на строки и столбцы HBase.
- `hbase.columns.mapping` — указывает соответствие между колонками Hive и HBase. `:key` соответствует `row key`, а `cf1:name` — колонке `name` в семействе колонок `cf1`.
- `hbase.table.name` — имя таблицы в HBase.

<h4>Интеграция с Pig</h4>

Pig — это платформа для анализа больших данных, использующая высокоуровневый язык Pig Latin. Pig может читать и записывать данные в HBase с помощью HBaseStorage.

Пример загрузки данных из HBase в Pig:
```bash
data = LOAD 'hbase://employee'
       USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf1:name', '-loadKey true -gt 10000') AS
       (id:bytearray, name:chararray);
```
В этом примере:
- Загружаем таблицу HBase с именем `employee`.
- Указываем, что мы хотим загрузить колонку `cf1:name` и ключ (с опцией `-loadKey true`).
- Опция `-gt 10000` означает, что мы загружаем строки с ключом больше 10000 (если ключи числовые).
- Преобразуем данные в поля: `id` (ключ) и `name` (значение из колонки `cf1:name`).

<h4>Интеграция с Spark</h4>

Apache Spark — это мощный фреймворк для распределенной обработки данных. Интеграция Spark с HBase позволяет читать и записывать данные из/в HBase непосредственно в Spark-приложениях. Для этого нужно использовать Apache HBase Connector. Сначала нужно добавить зависимость в проект Spark, затем можно читать данные из HBase в DataFrame.

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# Создаем Spark сессию
spark = SparkSession.builder \
    .appName("HBase-Spark-Python") \
    .config("spark.sql.adaptive.enabled", "true") \
    .getOrCreate()

# Определяем каталог для маппинга HBase таблицы
catalog = ''.join("""{
    "table":{"namespace":"default", "name":"users"},
    "rowkey":"key",
    "columns":{
        "rowkey":{"cf":"rowkey", "col":"key", "type":"string"},
        "user_id":{"cf":"info", "col":"user_id", "type":"string"},
        "name":{"cf":"info", "col":"name", "type":"string"},
        "age":{"cf":"info", "col":"age", "type":"int"},
        "email":{"cf":"contact", "col":"email", "type":"string"}
    }
}""".split())
```

Чтение из HBase:
```python
df = spark.read.options(catalog=catalog).format("org.apache.hadoop.hbase.spark").load()
df.show()
```

Запись в HBase:
```python
# Создаем тестовые данные
data = [
    ("user1", "U001", "Иван Иванов", 25, "ivan@mail.ru"),
    ("user2", "U002", "Мария Петрова", 30, "maria@mail.ru"),
    ("user3", "U003", "Алексей Сидоров", 35, "alex@mail.ru")
]

schema = StructType([
    StructField("rowkey", StringType(), True),
    StructField("user_id", StringType(), True),
    StructField("name", StringType(), True),
    StructField("age", IntegerType(), True),
    StructField("email", StringType(), True)
])

df = spark.createDataFrame(data, schema)
df.write.options(catalog=catalog).format("org.apache.hadoop.hbase.spark").save()
```

<h4>Безопасность</h4>

Безопасность в HBase включает аутентификацию, авторизацию и шифрование.
HBase поддерживает аутентификацию с помощью Kerberos. Это означает, что пользователи и сервисы должны пройти аутентификацию, прежде чем получить доступ к кластеру HBase. Также HBase предоставляет механизм авторизации на уровне таблиц и семейств колонок. Можно использовать Access Control Lists (ACLs) для управления правами пользователей и групп. Права включают: READ, WRITE, CREATE, ADMIN и другие.

Пример управления правами в HBase с помощью shell:
```bash
# Дать пользователю 'user1' права на чтение таблицы 'test_table'
grant 'user1', 'R', 'test_table'

# Отозвать права
revoke 'user1', 'test_table'
```

Также можно настроить видимость тегов (Cell-level security) для более тонкого контроля доступа к данным.

HBase поддерживает шифрование данных на уровне хранилища (HFiles) и при передаче по сети (RPC). Можно настроить шифрование для семейств колонок, используя алгоритмы шифрования, предоставляемые Hadoop KMS (Key Management Server).

<h4>Настройка для больших данных</h4>

Настройка выполняется в файле hbase-site.xml:
- Настройка памяти: важно выделить достаточную память для Heap RegionServer (например, 8-16 ГБ и более) и настроить off-heap память для кэшей (BlockCache, используемый для чтения, и MemStore, используемый для записи).
- Настройка HDFS: HBase полагается на HDFS, поэтому важно настроить HDFS для высокой пропускной способности и надежности (репликация данных, обычно 3 копии).
- Настройка компактизации (compaction): процесс объединения HFile для улучшения производительности чтения. Настройка политик компактизации (например, количество файлов, размеры) важна для производительности.
- Настройка разбиения (splitting): можно настроить порог разбиения регионов, а также использовать предварительное разбиение (pre-splitting) для равномерного распределения данных при создании таблицы.
- Настройка кэширования: Bloom filters для ускорения чтения, настройка размеров кэшей (BlockCache, MemStore) в зависимости от рабочей нагрузки (read-heavy или write-heavy).

Память:
```xml
<!-- Настройки памяти RegionServer -->
<property>
  <name>hbase.regionserver.heapsize</name>
  <value>16g</value>  # Размер Heap памяти
</property>

<property>
  <name>hbase.regionserver.global.memstore.size</name>
  <value>0.4</value>  # 40% heap для MemStore
</property>

<property>
  <name>hfile.block.cache.size</name>
  <value>0.4</value>  # 40% heap для BlockCache
</property>

<!-- Off-heap память для BucketCache -->
<property>
  <name>hbase.bucketcache.ioengine</name>
  <value>offheap</value>
</property>

<property>
  <name>hbase.bucketcache.size</name>
  <value>4096</value>  # 4GB off-heap
</property>
```

Производительность записи:
```xml
<!-- Размер MemStore для flush -->
<property>
  <name>hbase.hregion.memstore.flush.size</name>
  <value>134217728</value>  # 128MB
</property>

<!-- Максимальный размер WAL -->
<property>
  <name>hbase.regionserver.maxlogs</name>
  <value>32</value>
</property>

<!-- Параллельные операции записи -->
<property>
  <name>hbase.regionserver.handler.count</name>
  <value>30</value>  # Количество обработчиков
</property>

<!-- Размер блока HFile -->
<property>
  <name>hbase.mapreduce.hfileoutputformat.blocksize</name>
  <value>262144</value>  # 256KB
</property>
```

Производительность чтения:
```xml
<!-- Bloom Filter -->
<property>
  <name>hbase.rs.cacheblocksonwrite</name>
  <value>true</value>
</property>

<!-- Prefetch для сканирования -->
<property>
  <name>hbase.client.scanner.caching</name>
  <value>100</value>
</property>

<!-- Кэширование метаданных -->
<property>
  <name>hbase.client.meta.cache</name>
  <value>true</value>
</property>
```

Компактизация:
```xml
<!-- Minor Compaction -->
<property>
  <name>hbase.hstore.compactionThreshold</name>
  <value>3</value>  # Минимум файлов для compact
</property>

<property>
  <name>hbase.hstore.compaction.max</name>
  <value>10</value>  # Максимум файлов за одну compact
</property>

<!-- Major Compaction интервал -->
<property>
  <name>hbase.hregion.majorcompaction</name>
  <value>604800000</value>  # 7 дней в миллисекундах
</property>

<!-- Блокировка записи при большом количестве файлов -->
<property>
  <name>hbase.hstore.blockingStoreFiles</name>
  <value>16</value>
</property>
```

Write-intensive workload:
```xml
<property>
  <name>hbase.regionserver.global.memstore.size</name>
  <value>0.5</value>  # Больше памяти для MemStore
</property>

<property>
  <name>hbase.hstore.blockingStoreFiles</name>
  <value>32</value>   # Реже блокируем запись
</property>

<property>
  <name>hbase.hregion.memstore.flush.size</name>
  <value>256000000</value>  # 256MB flush size
</property>
```

Read-intensive workload:
```xml
<property>
  <name>hfile.block.cache.size</name>
  <value>0.6</value>  # Больше памяти для BlockCache
</property>

<property>
  <name>hbase.bucketcache.size</name>
  <value>8192</value>  # 8GB off-heap cache
</property>

<property>
  <name>hbase.client.scanner.caching</name>
  <value>200</value>   # Больше строк за запрос
</property>
```