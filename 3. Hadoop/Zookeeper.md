<h2>Zookeeper</h2>
<h3>1. Основы архитектуры и компоненты ZooKeeper</h3>
<h4>Основные понятия и архитектура</h4>

Apache ZooKeeper — это централизованный сервис для поддержания конфигурационной информации, именования, обеспечения распределённой синхронизации и групповых сервисов.

Основные понятия:
- Ансамбль (Ensemble): Кластер серверов ZooKeeper. Для обеспечения отказоустойчивости необходимо нечётное количество серверов (обычно 3, 5 или 7). Ансамбль продолжает работать, если "жива" большая часть серверов (кворум).
- Сессия (Session): Когда клиент подключается к ZooKeeper, устанавливается сессия. Это состояние подключения, которое имеет тайм-аут. Клиент периодически отправляет пинги (heartbeats), чтобы поддерживать сессию активной. Если сессия разрывается, все временные узлы (ephemeral znodes), созданные этой сессией, удаляются.
- Znode: Узел в данных ZooKeeper. Это не файл и не папка в классическом понимании, а нечто среднее — znode может хранить данные (как файл) и иметь дочерние узлы (как директория). Размер данных небольшой (обычно до 1 МБ), так как ZK не предназначен для хранения больших данных.
- Watches (Наблюдатели): Механизм уведомлений. Клиент может установить "наблюдателя" на znode. При любом изменении этого znode (изменение данных, удаление, появление дочерних узлов) ZooKeeper отправляет клиенту одноразовое уведомление (watch event).
- Версии (Version): Каждое изменение znode увеличивает его версию. Это позволяет реализовывать оптимистичные блокировки — клиент может проверить, не изменилась ли версия с момента его последнего чтения.

Преимущества ZooKeeper:
- Высокая доступность: Благодаря репликации данных на все серверы кластера и механизму кворума, сервис остается доступным даже при выходе из строя части серверов.
- Консистентность (Согласованность): ZooKeeper гарантирует линейную согласованность (linearizability) для операций записи. Это означает, что как только запись подтверждена, все последующие чтения (с любого сервера) увидят это изменение или более новое. Для операций чтения можно использовать sync, чтобы гарантированно получить самые свежие данные.
- Надежность: Данные реплицируются на все серверы. Даже если несколько серверов выйдут из строя и будут заменены, данные не будут потеряны, пока жив кворум.
- Высокая производительность на чтение: Поскольку чтения могут обслуживаться любым сервером (follower), они очень быстрые и легко масштабируются.
- Простота: Предоставляет простую и надежную модель данных (дерево znode) и понятный API, на основе которого можно построить сложные примитивы распределенных систем (блокировки, барьеры, очереди).

Основные компоненты архитектуры:
- Leader: Выбирается среди серверов ансамбля. Обрабатывает все операции записи (write requests) и реплицирует изменения на follower'ов.
- Followers: Обрабатывают операции чтения (read requests) и пересылают операции записи лидеру. Также участвуют в выборах лидера и голосуют за предложения лидера (в рамках алгоритма консенсуса).
- Observer: Похожи на followers, но не участвуют в выборах лидера и голосовании. Они используются для масштабирования системы для операций чтения.

Клиенты могут подключаться к любому серверу (leader, follower или observer). Если клиент подключен к follower или observer, и отправляет операцию записи, то этот сервер пересылает запрос лидеру.
Данные в ZooKeeper хранятся в памяти, но также периодически снимаются снапшоты (snapshots) и записываются в журнал транзакций (transaction log) на диск для восстановления. Обработка отказов серверов осуществляется с помощью выбора лидера, механизма сессий и кворума

<h4>Типы и особенности znode</h4>

Данные в ZooKeeper организованы в виде иерархического дерева пространства имён, очень похожего на файловую систему. Каждый узел в этом дереве — это znode. Путь к znode является абсолютным и должен начинаться с косой черты.

Существует три основных типа znode, которые определяют их жизненный цикл и поведение:
- Персистентный (Persistent): Существует до тех пор, пока не будет удален явно (командой delete). Используется для хранения долговременных данных, например, конфигурации, метаданных кластера.
- Эфемерный (Ephemeral): Существует только до тех пор, пока активна сессия клиента, который его создал. Если сессия клиента разрывается (из-за сбоя или явного закрытия), znode автоматически удаляется. Идеально для реализации сервиса обнаружения (Service Discovery) и мониторинга "живучести" узлов. Например, каждый экземпляр сервиса при запуске создает эфемерный znode. Если экземпляр "падает", его znode исчезает, и другие участники системы сразу об этом узнают.
- Sequential (Последовательный): Этот флаг можно комбинировать с Persistent или Ephemeral. При создании такого znode ZooKeeper автоматически добавляет к его имени монотонно возрастающий 10-значный суффикс (например, /lock/lock-0000000001, /lock/lock-0000000002). Ключевое применение — реализация распределенных блокировок (Distributed Locks) и очередей.

Ключевые особенности всех znode:
- Атомарность: Все операции над znode атомарны. Система гарантирует, что либо вся операция выполнится, либо не выполнится ничего.
- Наблюдатели (Watches): На любой znode можно повесить watch, что делает ZooKeeper системой, управляемой событиями.
- Версионность: Каждый znode имеет номер версии, который увеличивается при каждом изменении данных. Это предотвращает "состояние гонки" (race condition).

<h4>Файл zoo.cfg</h4>

Это основной конфигурационный файл для сервера ZooKeeper. В нем задаются параметры, необходимые для запуска и работы сервера. Вот некоторые ключевые параметры:
- `tickTime`: базовый временной интервал в миллисекундах, используемый ZooKeeper для измерения времени, например, для определения времени ожидания сессии (session timeout). Обычно устанавливается в 2000 мс (2 секунды).
- `initLimit`: время (в тиках - tickTime), которое позволяет follower-серверам подключиться к leader-серверу. Если за это время follower не успевает подключиться, то он исключается из ансамбля. Обычно устанавливается в 5 тиков (т.е. 5 * `tickTime`).
- `syncLimit`: время (в тиках), которое позволяет follower-серверам синхронизироваться с leader-сервером. Если follower отстает от leader на большее время, то он исключается из ансамбля. Обычно устанавливается в 2 тика.
- `dataDir`: директория, где ZooKeeper будет хранить снимки (snapshots) состояния данных и, если не задано иное, журнал транзакций (transaction log).
- `dataLogDir`: (опционально) директория для журнала транзакций. Если не задано, то используется `dataDir`.
- `clientPort`: порт, на котором сервер ZooKeeper будет слушать запросы от клиентов. По умолчанию 2181.
- `maxClientCnxns`: максимальное количество одновременных подключений от одного клиента (по IP). По умолчанию 60.
- `server.X`: список серверов, входящих в ансамбль. Здесь X - это идентификатор сервера (должен быть уникальным для каждого сервера). Формат: server.X=hostname:peerPort:leaderPort, где peerPort - порт для обмена данными между серверами (обычно 2888), leaderPort - порт для выборов лидера (обычно 3888).
- `autopurge.snapRetainCount`: количество снимков данных и соответствующих журналов транзакций, которые будут сохраняться после очистки (остальные удаляются). По умолчанию 3.
- `autopurge.purgeInterval`: интервал (в часах) для запуска задачи очистки. По умолчанию 0 (отключено).

Пример файла zoo.cfg:

```bash
# Основные настройки
tickTime=2000
dataDir=/var/lib/zookeeper
clientPort=2181

# Настройки ансамбля
initLimit=10
syncLimit=5

# Список серверов ансамбля
server.1=192.168.1.101:2888:3888
server.2=192.168.1.102:2888:3888
server.3=192.168.1.103:2888:3888

# Дополнительные настройки
maxClientCnxns=100
autopurge.snapRetainCount=5
autopurge.purgeInterval=1
```

<h4>Выбор лидера и настройка кворума</h4>

Выбор лидера (Leader Election) — это критический процесс в ZooKeeper, который гарантирует, что в ансамбле всегда есть лидер, отвечающий за координацию операций записи. ZooKeeper использует модифицированную версию алгоритма Paxos, называемую Fast Leader Election. Основная идея в том, чтобы выбрать сервер с самым последним состоянием (наибольшим ZXID).

Этапы выборов:
1. Состояние выборов (Election): Каждый сервер начинает в состоянии LOOKING и отправляет свой голос (vote) другим серверам. Голос содержит (предлагаемый лидер, ZXID, epoch).
2. Сбор голосов: Серверы обмениваются голосами. При получении голоса сервер проверяет, является ли предложенный в голосе лидер более подходящим (сравнивает сначала по ZXID, затем по server id). Если да, то сервер обновляет свой голос и рассылает новый голос.
3. Объявление лидера: Когда сервер получает голоса от кворума серверов в пользу одного и того же лидера, он переходит в состояние FOLLOWING (если он не лидер) или LEADING (если он лидер).

Кворум — это минимальное количество серверов, которые должны подтвердить операцию, чтобы она была committed. Кворум также используется для выборов лидера. Кворум определяется как большинство серверов ансамбля. Для ансамбля из N серверов кворум составляет floor(N/2) + 1.

В конфигурационном файле zoo.cfg серверы ансамбля задаются следующим образом:

```bash
server.1=host1:2888:3888
server.2=host2:2888:3888
server.3=host3:2888:3888
```
Здесь:
- 2888 — порт для обмена данными между серверами (через который лидер рассылает предложения)
- 3888 — порт для выборов лидера

Каждый сервер должен иметь в своей `dataDir` файл `myid`, содержащий номер, соответствующий его ID в конфигурации (например, для server.1 в `myid` должно быть 1).

Без кворума ансамбль не может принимать операции записи и выбирать лидера. Это гарантирует, что в случае разделения сети (network partition) только часть с кворумом может продолжать работу, избегая split-brain.


<h4>Роль в Hadoop</h4>

Apache ZooKeeper играет важную роль в экосистеме Hadoop, обеспечивая надежное, распределенное координационное и конфигурационное сервисное решение для крупномасштабных распределенных систем. В контексте Hadoop и других распределенных приложений, ZooKeeper используется для решения нескольких ключевых задач:
- Управление конфигурацией: ZooKeeper позволяет централизованно управлять конфигурацией, делая конфигурационные данные доступными для всех узлов в кластере. Изменения в конфигурации могут быть мгновенно распространены по всем узлам, что позволяет системе быстро адаптироваться к новым настройкам.
- Синхронизация: ZooKeeper обеспечивает механизмы для синхронизации действий между узлами в кластере. Это может быть использовано для координации начала и завершения различных операций, гарантируя, что все узлы работают согласованно.
- Выборы лидера: В многих распределенных системах необходимо определить "лидера" среди группы узлов для управления определенными задачами или для принятия решений от имени группы. ZooKeeper предоставляет сервисы для проведения выборов лидера и управления процессом, гарантируя, что в любой момент времени существует только один активный лидер.
- Регистрация сервисов: ZooKeeper может использоваться для отслеживания статуса различных компонентов в системе, предоставляя регистрацию сервисов и обнаружение. Это позволяет приложениям узнавать о доступности и местоположении различных сервисов в кластере.
- Управление распределенными блокировками: Для того чтобы обеспечить корректную обработку конкурентных операций в распределенной системе, необходим механизм блокировок. ZooKeeper предоставляет API для создания и управления распределенными блокировками, что позволяет разным узлам безопасно работать с общими ресурсами.
- Обработка отказов: ZooKeeper помогает системам быстро реагировать на отказы узлов, автоматически переконфигурируя систему для обхода недоступных узлов и минимизации простоев.

<h3>2. Внутренние механизмы и согласованность</h3>
<h4>Консистентность данных</h4>

ZooKeeper обеспечивает последовательную консистентность (sequential consistency) с определёнными гарантиями порядка операций.

Ключевые гарантии:
- Линейность записей (Linearizable Writes):
- Все операции записи (write) являются линейными — они выполняются атомарно и в порядке, соответствующем их временной очередности. Гарантируется, что если одна операция записи завершилась до начала другой, то все серверы увидят их в этом порядке.
- Упорядоченность FIFO для клиента (FIFO Client Order): Все запросы от одного клиента выполняются в том порядке, в котором они были отправлены. Если клиент отправляет операции A, B, C, то они будут обработаны именно в последовательности A→B→C на всех серверах.
- Согласованность в пределах одного клиента (Single-System Image): Клиент будет видеть одну и ту же последовательность обновлений независимо от того, к какому серверу ансамбля он подключен.

<h4>Алгоритмы консенсуса</h4>

ZooKeeper использует модифицированную версию алгоритма Paxos, называемую ZAB (ZooKeeper Atomic Broadcast). ZAB гарантирует, что все изменения реплицируются в одном порядке на всех серверах ансамбля.

ZAB состоит из двух основных фаз:
- Фаза восстановления (Recovery Phase): Происходит при запуске ансамбля или при потере лидера. В этой фазе выбирается новый лидер и происходит синхронизация состояния серверов до последней committed транзакции.
- Фаза широковещания (Broadcast Phase): После выбора лидера и синхронизации, лидер начинает обрабатывать запросы записи и рассылать их follower'ам. Когда предложение (proposal) подтверждается кворумом, лидер коммитит транзакцию и уведомляет follower'ов.

Особенности ZAB:
- Все операции записи идут через лидера.
- Лидер ждет подтверждения от кворума follower'ов, прежде чем закоммитить транзакцию.
- ZAB гарантирует, что если лидер закоммитил транзакцию, то все последующие лидеры также будут иметь эту транзакцию и в том же порядке.

Выборы лидера в ZAB используют алгоритм, похожий на Paxos, но оптимизированный для высокой производительности. Каждый сервер имеет идентификатор (sid) и номер эпохи (zxid - ZooKeeper Transaction ID). Сервер голосует за сервер с наибольшим zxid, а при равных zxid - за сервер с наибольшим sid.

В целом, ZAB обеспечивает линейную запись (linearizable writes) и упорядочивание сообщений, что необходимо для консистентности в распределенной системе.

<h4>Atomic Broadcoast</h4>

Atomic Broadcast — это фундаментальный механизм, лежащий в основе репликации данных в ZooKeeper. Он реализован в виде протокола Zab (ZooKeeper Atomic Broadcast). Задача Zab: Надежно и в правильном порядке реплицировать все состояния (транзакции) от Лидера к последователям.

Фазы работы Zab:
1. Фаза выборов (Leader Election): Серверы начинают выбирать лидера. Сервер, который имеет самую последнюю историю транзакций (наибольший ZXID), с большой вероятностью станет лидером. Как только лидер избран и у него есть "армия" последователей (кворум), система переходит к следующей фазе.
2. Фаза синхронизации (Synchronization): Лидер синхронизирует свое состояние с состоянием всех последователей в кворуме. Он отправляет им свои последние транзакции (начиная с последнего общего ZXID), чтобы все серверы в кворуме пришли к идентичному состоянию.
3. Фаза широковещательной рассылки (Broadcast): После синхронизации кластер готов к работе. Когда лидер получает запрос на запись, он генерирует предложение (proposal) и рассылает его всем последователям, последователи подтверждают получение предложения. Как только лидер получает подтверждения от кворума серверов, он фиксирует (commit) эту транзакцию и рассылает команду COMMIT всем последователям. Каждый сервер (и лидер, и последователи) применяет транзакцию к своему состоянию.

Ключевые гарантии Zab:
- Надежная доставка: Если транзакция закоммичена на одном сервере, она будет закоммичена на всех серверах кворума.
- Тотальный порядок: Все транзакции доставляются всем серверам в одном и том же порядке.
- Согласованность префикса: Если лидер закоммитил транзакцию T, то все предыдущие транзакции (с меньшим ZXID) также закоммичены.

<h4>Обработка разделения сети</h4>

Разделение сети (network partition) происходит, когда связь между серверами в ансамбле нарушается, и они не могут общаться друг с другом. В такой ситуации ZooKeeper стремится сохранить консистентность и доступность в той части сети, где есть кворум (большинство серверов).

Варианты обработки:
- Если текущий лидер остается в части сети с кворумом (большинством серверов), то он продолжает обрабатывать запросы записи.
- Если лидер оказывается в части сети без кворума, то он перестает быть лидером, и в части с кворумом начинаются новые выборы лидера.
- Клиенты, подключенные к серверам в части без кворума, не смогут выполнять операции записи, а также могут потерять сессию (по истечении таймаута), так как серверы в этой части не могут обновлять состояние сессий (требуется кворум для записи).

ZooKeeper жертвует доступностью в меньшинственной части сети для сохранения консистентности (следует принципу CAP - Consistency, Availability, Partition Tolerance: в случае разделения выбирает консистентность и устойчивость к разделению, но жертвует доступностью в меньшинственной части).

<h4>Транзакции</h4>

В ZooKeeper термин "транзакция" имеет несколько иное значение по сравнению с традиционными СУБД. Транзакция в ZooKeeper — это атомарная операция, которая может состоять из нескольких операций над znodes, но при этом гарантируется, что все они будут применены или ни одна. Однако, важно отметить, что в ZooKeeper нет поддержки многопоточных транзакций в классическом понимании (как в реляционных базах). Вместо этого, каждая операция является атомарной и упорядоченной.

Ключевые аспекты транзакций в ZooKeeper:
- Атомарность: Каждая операция выполняется атомарно. Это означает, что операция либо полностью применяется, либо не применяется вовсе.
- Упорядоченность: Каждая транзакция получает уникальный идентификатор (ZXID), который определяет порядок, в котором транзакции должны быть применены. Все серверы применяют транзакции в порядке возрастания ZXID.
- Многооперационные транзакции: С версии 3.4.0 ZooKeeper поддерживает многооперационные транзакции (multi-op transactions). Это позволяет группировать несколько операций в одну транзакцию, которая будет применена атомарно. Например, можно обновить несколько znodes так, чтобы либо все обновления произошли, либо ни одного.

<h4>Синхронизация и восстановление</h4>

ZooKeeper обеспечивает надежность хранения данных и согласованность между серверами ансамбля с помощью транзакционного журнала (transaction log) и снимков состояния (snapshots).

Транзакционный журнал (TxnLog):
- Каждая операция записи (транзакция) перед применением записывается в журнал на диск. Это гарантирует, что даже в случае сбоя сервер может восстановить состояние, воспроизведя журнал.
- Журнал записывается в последовательные файлы с префиксом "log". Когда текущий файл журнала достигает определенного размера, создается новый.
- Запись в журнал происходит в режиме добавления (append-only), что обеспечивает высокую производительность.

Снимки состояния (Snapshots):
- Периодически ZooKeeper создает снимки состояния данных в памяти. Снимок — это сериализованное представление всех znodes на момент создания снимка. Снимки сохраняются в файлы с префиксом "snapshot".
- Снимки не являются согласованными на момент создания, потому что они создаются в фоновом режиме без блокировки системы. Однако, это не проблема, потому что снимок используется вместе с журналом транзакций для восстановления: после загрузки снимка применяются все транзакции, которые были зафиксированы после создания снимка.

Синхронизация данных между серверами:
1. Когда лидер получает новую транзакцию, он записывает ее в свой журнал, затем рассылает предложение (proposal) фолловерам.
2. Фолловеры, получив предложение, также записывают транзакцию в свой журнал (но еще не применяют) и отправляют лидеру подтверждение (ack).
3. После того как лидер получает подтверждения от кворума фолловеров, он рассылает коммит (commit), и тогда все серверы применяют транзакцию к своим данным в памяти.

Восстановление после сбоя: При перезапуске сервер загружает последний снимок, а затем применяет все транзакции из журнала, которые были зафиксированы после создания этого снимка. Благодаря тому, что транзакции в журнале упорядочены по ZXID, сервер может точно восстановить свое состояние.

<h3>3. Клиентское взаимодействие и практическое использование</h3>
<h4>Инструменты для взаимодействия</h4>

ZooKeeper предлагает широкий выбор инструментов для взаимодействия и мониторинга, например, визуальные инструменты ZooInspector и ZooKeeper Monitoring.

Официальная CLI утилита (`zkCli.sh`/`zkCli.cmd`) - входит в стандартную поставку ZooKeeper и является основным инструментом для администрирования:
```bash
# Подключение к локальному серверу
./zkCli.sh

# Подключение к удалённому серверу
./zkCli.sh -server zoo1.example.com:2181

# Основные команды внутри zkCli:
[zk: localhost:2181(CONNECTED) 0] help
[zk: localhost:2181(CONNECTED) 1] ls /                    # Просмотр корневой директории
[zk: localhost:2181(CONNECTED) 2] create /node "data"     # Создание узла
[zk: localhost:2181(CONNECTED) 3] get /node               # Получение данных и метаданных
[zk: localhost:2181(CONNECTED) 4] set /node "new data"    # Обновление данных
[zk: localhost:2181(CONNECTED) 5] delete /node            # Удаление узла
[zk: localhost:2181(CONNECTED) 6] rmr /path               # Рекурсивное удаление
[zk: localhost:2181(CONNECTED) 7] stat /node              # Только метаданные
```

Четырёхбуквенные команды (Four Letter Words) - простой протокол для мониторинга и управления через telnet/nc:

```bash
echo stat | nc localhost 2181          # Базовая статистика
echo srvr | nc localhost 2181          # Детальная статистика сервера
echo ruok | nc localhost 2181          # Проверка работоспособности ("imok")
echo dump | nc localhost 2181          # Дамп сессий и временных узлов
echo cons | nc localhost 2181          # Список активных подключений
echo wchs | nc localhost 2181          # Статистика watches
echo mntr | nc localhost 2181          # Метрики в формате для мониторинга
```

Ключевые метрики для мониторинга:
- Режим сервера (Leader/Follower): Убедитесь, что в кластере ровно один лидер.
- Задержки (Latency): avg_latency, max_latency. Рост задержек может указывать на проблемы.
- Количество подключений (num_alive_connections): Резкое падение может означать проблемы с клиентами.
- Количество ожидающих запросов (outstanding_requests): Большая очередь может указывать на то, что сервер не справляется с нагрузкой.
- Статус синхронизации с лидером (followers, synced_followers): Убедитесь, что все последователи синхронизированы с лидером.

<h4>Взаимодействие с клиентом</h4>

Клиент взаимодействует с ZooKeeper через клиентскую библиотеку. Вот основные шаги:
1. Установление соединения: Клиент подключается к одному из серверов ансамбля ZooKeeper, указав в конфигурации список серверов. Клиентская библиотека пытается подключиться к одному из серверов из списка. После установления соединения клиент и сервер поддерживают сессию.
2. Отправка запросов: Клиент может отправлять запросы на чтение или запись. Запросы на запись (создание, удаление, изменение узлов) всегда перенаправляются на лидера и проходят процесс согласования в ансамбле. Запросы на чтение могут быть обработаны любым сервером, к которому подключен клиент, что позволяет распределять нагрузку.
3. Поддержание сессии: Клиент периодически отправляет heartbeat-сообщения (пинги) для поддержания сессии. Если сервер не получает heartbeat в течение времени, превышающего таймаут сессии, сессия считается разорванной, и все эфемерные узлы, созданные в этой сессии, удаляются.
4. Механизм watch: Клиент может установить watch на узел. При изменении узла (например, изменение данных, удаление, добавление дочерних узлов) сервер отправляет уведомление клиенту. Watch срабатывает только один раз, поэтому клиент должен установить его снова, если нужно отслеживать дальнейшие изменения.
5. Обработка сбоев: Если соединение с текущим сервером разрывается, клиентская библиотека пытается переподключиться к другому серверу из списка. При этом сессия сохраняется, если клиент успевает переподключиться в течение таймаута сессии.

<h4>Session и Watch</h4>

Сессия представляет собой связь между клиентом и сервером ZooKeeper. Она устанавливается при подключении клиента и остается активной до тех пор, пока клиент не отключится или не истечет таймаут сессии. Каждая сессия имеет уникальный идентификатор и таймаут, который задается клиентом при создании соединения. Сервер использует таймаут, чтобы определить, активен ли еще клиент. Клиент должен периодически отправлять heartbeat (пустые запросы или пинги) для поддержания сессии. Если сервер не получает никаких сообщений от клиента в течение времени, превышающего таймаут сессии, он считает сессию разорванной. Все эфемерные узлы, созданные в рамках сессии, автоматически удаляются при разрыве сессии. Это позволяет использовать эфемерные узлы для представления состояния клиента (например, онлайн/оффлайн).

Watch — это механизм, позволяющий клиенту получать уведомления об изменениях в узле. Клиент может установить watch при выполнении операции чтения (таких как `get`, `exists`, `getChildren`). Когда происходит изменение, связанное с отслеживаемым узлом (изменение данных, удаление узла, добавление/удаление дочерних узлов), сервер отправляет клиенту событие (watch event). Watch срабатывает только один раз — после срабатывания клиент должен установить watch снова, если хочет продолжать получать уведомления.

Watch бывают разных типов в зависимости от операции, которая их установила:
- `NodeCreated`: срабатывает при создании узла (установлен с помощью `exists`).
- `NodeDeleted`: срабатывает при удалении узла (установлен с помощью `exists` или `get`).
- `NodeDataChanged`: срабатывает при изменении данных узла (установлен с помощью `exists` или `get`).
- `NodeChildrenChanged`: срабатывает при изменении списка дочерних узлов (установлен с помощью `getChildren`).

Watch обеспечивают событийно-ориентированную модель программирования, позволяя клиентам реагировать на изменения в данных ZooKeeper без постоянного опрашивания.

<h4>Обработка конфликтов</h4>

В распределенных системах конфликты возникают, когда несколько клиентов пытаются одновременно изменить одни и те же данные. ZooKeeper решает эту проблему с помощью двух ключевых механизмов:
- Гарантия порядка: ZooKeeper гарантирует, что все операции обновления (записи) выполняются в строгом порядке, определенном лидером. Каждое обновление получает уникальный, монотонно возрастающий идентификатор — ZXID (ZooKeeper Transaction ID). Это предотвращает ситуацию, когда два клиента видят изменения в разном порядке.
- Версионность (Versioning): Все операции обновления (setData, delete) могут принимать ожидаемую версию в качестве параметра. Каждый znode имеет три номера версии:
  - `version` — количество изменений данных znode.
  - `cversion` — количество изменений дочерних элементов znode.
  - `aversion` — количество изменений ACL znode.

Механизм "Оптимистичной блокировки":
1. Клиент A читает данные znode и получает его версию (например, `v=5`).
2. Клиент B читает те же данные и тоже получает `v=5`.
3. Клиент A пытается выполнить `setData(/path, data, 5)`. Операция успешна, так как текущая версия на сервере равна 5. Версия становится 6.
4. Клиент B пытается выполнить `setData(/path, data, 5)`. Операция проваливается с ошибкой BadVersion, потому что текущая версия на сервере теперь 6, а не 5.
5. Таким образом, клиент B узнает о конфликте и должен заново прочитать данные, обработать их и повторить попытку записи.