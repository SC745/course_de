<h2>Вопросы</h2>
<h3>1. Hadoop</h3>

1) Hadoop
Фреймворк для распределённой обработки больших данных.

2) Компоненты Hadoop
HDFS — хранение данных.
YARN — управление ресурсами и планирование задач.
MapReduce — модель выполнения вычислений.

<h3>2. HDFS</h3>

1) HDFS
Распределённая файловая система Hadoop для хранения больших данных.

2) Компоненты HDFS

NameNode — управляет метаданными файловой системы.

DataNode — хранит непосредственно блоки данных.

Secondary NameNode — выполняет периодическое слияние журналов и чекпоинтов (не резервная копия).

3) Фактор репликации
Количество копий каждого блока данных в HDFS (по умолчанию 3). Обеспечивает отказоустойчивость и доступность.

4) Проблема маленьких файлов
Большое количество маленьких файлов перегружает оперативную память NameNode, так как для каждого файла хранится метаинформация.

5) QJM (Quorum Journal Manager)
Механизм для разделяемого журнала редактирования, обеспечивающий отказоустойчивость активного NameNode.

6) Типы хранилищ в HDFS
DISK (по умолчанию)
SSD
ARCHIVE (малопроизводительные, но ёмкие диски)
RAM_DISK (кэширование в оперативной памяти)

9) Назначение политик хранения
Автоматическое перемещение данных между типами хранилищ (например, из SSD в ARCHIVE) на основе правил для оптимизации стоимости и производительности.

10) Конфигурационные файлы
core-site.xml — общие настройки.
hdfs-site.xml — настройки HDFS.
yarn-site.xml — настройки YARN.
mapred-site.xml — настройки MapReduce.

Команды:
```bash
hdfs dfs -touchz /user/data/empty_file.txt            # Создание файла
hdfs dfs -put local_file.txt /user/data/              # Загрузка файла
hdfs dfs -get /user/data/file.txt ./local_copy.txt    # Скачивание файла
hdfs dfs -rm /dir/file.txt                            # Удаление файла
hdfs dfs -du /user/data/                              # Использование диска
hdfs dfs -setrep -w 2 /user/data/log.txt              # Изменить фактор репликации
hdfs storagepolicies -setStoragePolicy -path <путь> -policy <политика>    # Изменить политику хранения
```

<h3>3. YARN, MapReduce</h3>

1) YARN
Платформа управления ресурсами и задачами в Hadoop.

2) Компоненты YARN
- ResourceManager — глобальное управление ресурсами кластера.
- NodeManager — управление ресурсами и контейнерами на отдельном узле.
- ApplicationMaster — управление жизненным циклом одного приложения.

3) Алгоритм YARN
1. Клиентское приложение отправляет запрос в кластер;
2. Менеджер ресурсов выделяет необходимые ресурсы для контейнера и запускает ApplicationMaster;
3. ApplicationMaster отправляет запрос менеджеру узла NodeManager, включая контекст запуска контейнера;
4. ApplicationMaster выделяет контейнеры для приложения в каждом узле и контролирует их работу;
5. Для запуска контейнера менеджер узла копирует в локальное хранилище все необходимые зависимости;
6. По завершении задачи мастер приложения отменяет выделенный контейнер в диспетчере ресурсов.
7. Клиент может отслеживать состояние распределенного приложения, обращаясь к менеджеру ресурсов или сразу к мастеру приложения.

3) Планировщики в YARN
FIFO Scheduler — выполняет задачи в порядке очереди.
Capacity Scheduler — выделяет доли (квоты) ресурсов для разных групп.
Fair Scheduler — динамически распределяет ресурсы между приложениями для равноправия.

4) Очереди в YARN
Виртуальные контейнеры для ресурсов в планировщиках (Capacity, Fair). Позволяют организовывать, контролировать и ограничивать использование ресурсов разными пользователями или группами.

5) Метрики в YARN
Данные о состоянии кластера: использование памяти/процессоров, количество запущенных/завершённых приложений, доступные/используемые ресурсы на узлах.

6) ApplicationMaster в YARN
Роль: Посредник между приложением и ResourceManager.
Функции: Запрашивает ресурсы у RM, отслеживает выполнение задач контейнерах, обрабатывает сбои.

7) MapReduce
Модель программирования для параллельной обработки больших данных на кластере.

8) Стадии MapReduce
Map — преобразование входных данных в пары ключ-значение.
Shuffle & Sort — группировка значений по одинаковым ключам.
Reduce — агрегация сгруппированных данных.

Использование YARN для мониторинга ресурсов
- yarn node -list: Показывает список всех NodeManagers (узлов) в кластере, что позволяет оценить общее количество ресурсов.
- yarn node -status <NodeID>: Предоставляет детальную информацию о состоянии и метриках конкретного NodeManager.
- yarn application -list: Отображает список всех запущенных приложений в YARN, что дает представление о текущем использовании ресурсов кластера.
- yarn queue -status <QueueName>: Выводит информацию о конкретной очереди YARN, включая настройки и статистику использования ресурсов.

<h3>4. ZooKeeper</h3>

1) Что такое ZooKeeper
Централизованный сервис для координации и поддержки консенсуса в распределённых системах.

2) Архитектура ZooKeeper
Кластер (ансамбль) из нечётного количества серверов. Один сервер — лидер (leader), остальные — последователи (followers). Все записи проходят через лидера, чтение доступно с любого сервера.

3) Роль ZooKeeper (подробнее)
Является распределённым хранилищем ключ-значение (в виде иерархического дерева znodes). Решает задачи:
- Координация: управление конфигурацией, распределённая синхронизация, выбор лидера.
- Согласованность: гарантирует, что все узлы кластера видят одни и те же данные.
- Регистрация: отслеживание доступности узлов (service discovery).
- Блокировки: реализация распределённых mutex.

4) Протокол Zab (подробнее)
ZooKeeper Atomic Broadcast — протокол атомарного широковещания, обеспечивающий согласованность данных.
- Фаза выбора лидера: гарантирует, что в кластере есть единственный лидер, прежде чем начать широковещание.
- Фаза широковещания: все операции записи (транзакции) рассылаются лидером и обрабатываются в строгом порядке.

Гарантии: доставляет все сообщения в одинаковом порядке (тотальный порядок) и гарантирует, что состояние всех серверов будет согласованным после восстановления лидера.

Apache ZooKeeper — связывающий компонент распределенных систем. В основе ZooKeeper лежит набор данных, представленный в виде дерева, которое похоже на файловую систему. Это дерево обладает узлами (ZNode), которые, в свою очередь, могут хранить данные и иметь подчиненные узлы. Существует два типа узлов:
- Persistent — значение, которое хранится на диске.
- Ephemeral — значение, которое хранится только до тех пор, пока существует соединение клиента с ZooKeeper.

Архитектура:
- Ансамбль (Ensemble): Кластер серверов ZooKeeper. Для обеспечения отказоустойчивости необходимо нечётное количество серверов (обычно 3, 5 или 7). Ансамбль продолжает работать, если "жива" большая часть серверов (кворум).
- Сессия (Session): Когда клиент подключается к ZooKeeper, устанавливается сессия. Это состояние подключения, которое имеет тайм-аут. Клиент периодически отправляет пинги (heartbeats), чтобы поддерживать сессию активной. Если сессия разрывается, все временные узлы (ephemeral znodes), созданные этой сессией, удаляются.
- Znode: Узел в данных ZooKeeper. Это не файл и не папка в классическом понимании, а нечто среднее — znode может хранить данные (как файл) и иметь дочерние узлы (как директория). Размер данных небольшой (обычно до 1 МБ), так как ZK не предназначен для хранения больших данных.
- Watches (Наблюдатели): Механизм уведомлений. Клиент может установить "наблюдателя" на znode. При любом изменении этого znode (изменение данных, удаление, появление дочерних узлов) ZooKeeper отправляет клиенту одноразовое уведомление (watch event).
- Версии (Version): Каждое изменение znode увеличивает его версию. Это позволяет реализовывать оптимистичные блокировки — клиент может проверить, не изменилась ли версия с момента его последнего чтения.

Apache ZooKeeper играет важную роль в экосистеме Hadoop, обеспечивая надежное, распределенное координационное и конфигурационное сервисное решение для крупномасштабных распределенных систем. В контексте Hadoop и других распределенных приложений, ZooKeeper используется для решения нескольких ключевых задач:
- Управление конфигурацией: ZooKeeper позволяет централизованно управлять конфигурацией, делая конфигурационные данные доступными для всех узлов в кластере. Изменения в конфигурации могут быть мгновенно распространены по всем узлам, что позволяет системе быстро адаптироваться к новым настройкам.
- Синхронизация: ZooKeeper обеспечивает механизмы для синхронизации действий между узлами в кластере. Это может быть использовано для координации начала и завершения различных операций, гарантируя, что все узлы работают согласованно.
- Выборы лидера: В многих распределенных системах необходимо определить "лидера" среди группы узлов для управления определенными задачами или для принятия решений от имени группы. ZooKeeper предоставляет сервисы для проведения выборов лидера и управления процессом, гарантируя, что в любой момент времени существует только один активный лидер.
- Регистрация сервисов: ZooKeeper может использоваться для отслеживания статуса различных компонентов в системе, предоставляя регистрацию сервисов и обнаружение. Это позволяет приложениям узнавать о доступности и местоположении различных сервисов в кластере.
- Управление распределенными блокировками: Для того чтобы обеспечить корректную обработку конкурентных операций в распределенной системе, необходим механизм блокировок. ZooKeeper предоставляет API для создания и управления распределенными блокировками, что позволяет разным узлам безопасно работать с общими ресурсами.
- Обработка отказов: ZooKeeper помогает системам быстро реагировать на отказы узлов, автоматически переконфигурируя систему для обхода недоступных узлов и минимизации простоев.

<h3>5. Hive</h3>

1) Что такое Hive
Система для запросов к данным в HDFS с помощью SQL-подобного языка (HiveQL).

2) Архитектура Hive
CLI/UI → Driver (компилятор, оптимизатор, исполнитель) → Metastore (база метаданных) → Execution Engine (MapReduce/Tez/Spark).

3) Типы таблиц в Hive и их отличия
Управляемые (Internal): Hive управляет и данными, и метаданными. При удалении таблицы данные удаляются из HDFS.
Внешние (External): Hive управляет только метаданными. Данные хранятся во внешнем расположении HDFS и не удаляются при дропе таблицы.

Синтаксис создания таблицы:
```sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name
(
  column_name data_type [COMMENT column_comment],
  ...
)
[COMMENT table_comment]
[PARTITIONED BY (partition_column data_type [COMMENT partition_comment], ...)]
[CLUSTERED BY (column_name, ...) [SORTED BY (column_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
[ROW FORMAT row_format]
[STORED AS file_format]
[LOCATION hdfs_path]
[TBLPROPERTIES (property_name=property_value, ...)];
```

4) Отличия от традиционных СУБД
Schema-on-Read (схема при чтении) vs Schema-on-Write.
Запись/обновление строк неэффективны или ограничены.
Высокая задержка, предназначен для пакетной обработки, а не OLTP.

5) Форматы файлов в Hive
TextFile, SequenceFile, ORC (оптимизированный, лучшая компрессия и производительность), Parquet.

6) Отличия HiveQL и SQL
HiveQL не поддерживает транзакции на низком уровне (до версии 3 - ограниченно), обновления и удаления строк. Имеет специфичные конструкции для HDFS (например, LOCATION).

7) Партицирование
Организация данных в каталоги HDFS по значениям столбцов (например, .../date=2023-10-01/). Ускоряет запросы с фильтрами по партициям (пропуск сканирования нерелевантных данных).

8) Кластеризация (Бакетирование)
Разделение данных внутри партиции на "корзины" (файлы) по хэшу от столбцов. Ускоряет джойны и семпплирование.

9) Виды джоинов
INNER, LEFT OUTER, RIGHT OUTER, FULL OUTER. Map-side join (для маленьких таблиц) и Reduce-side join (общий случай).

10) Методы оптимизации запросов
Использование форматов ORC/Parquet.
Партицирование и бакетирование.
Векторизация выполнения.
Статистика таблиц (ANALYZE).
Cost-Based Optimizer (CBO).

11) Как работает встроенный оптимизатор запросов
Cost-Based Optimizer (CBO) использует статистику (число строк, распределение данных) для выбора наиболее эффективного плана выполнения (порядок джоинов, тип джоина).

<h3>6. Spark</h3>

1) Что такое Spark
Фреймворк для распределённой обработки данных с вычислениями в памяти.

2) Компоненты Spark
- Spark Core — движок для распределенной обработки данных.
- Spark SQL — модуль обработка структурированных данных.
- Spark Streaming — потоковая обработка (микропакетами).
- MLlib — библиотека машинного обучения.
- GraphX — обработка графов.

3) Архитектура Spark
Driver Program (мастер) управляет SparkContext, который координирует работу Executors (рабочих процессов) на кластере через Cluster Manager (YARN, Mesos, Standalone).

- Driver Program: Программа, которая создает SparkContext, инициирующий Spark-приложение. Это центральный узел управления, который конвертирует пользовательскую программу в задачи и распределяет их между исполнителями (Executors). Драйвер также отвечает за планирование задач и восстановление от сбоев.
- SparkContext: Контекст выполнения приложения, управляющий доступом к кластеру через Cluster Manager.
- Cluster Manager: Spark может работать на различных менеджерах кластеров, включая Spark Standalone, YARN (Hadoop), Mesos и Kubernetes. Менеджер кластера отвечает за выделение ресурсов драйверу и исполнителям.
- Executors: Процессы, выполняющиеся на узлах рабочего кластера, которые обрабатывают задачи вычислений и хранят данные приложения в памяти или на диске. Executors взаимодействуют с программой "Driver Program" для выполнения кода.
- RDD (Resilient Distributed Dataset): Это основная абстракция данных в Spark, представляющая собой неизменяемую коллекцию элементов, распределенных по кластеру, которую можно обрабатывать в параллельном режиме. Именно RDD является основным вычислительным примитивом Spark, над которым можно делать параллельные вычисления и преобразования с помощью встроенных и произвольных функций, в том числе с помощью временных окон.

4) Отличие Spark Streaming от Structured Streaming
- Spark Streaming — устаревший API на основе DStreams (дискретных потоков RDD).
- Structured Streaming — современный API на основе безграничных DataFrame, обеспечивающий оптимизацию запросов.

5) RDD в Spark
Resilient Distributed Dataset — неизменяемая, отказоустойчивая, распределённая коллекция объектов, основная низкоуровневая абстракция данных.

6) DataFrame в Spark
Распределённая коллекция данных, организованная в именованные столбцы (как таблица в реляционной БД). Абстракция более высокого уровня, чем RDD.

7) Отличия RDD от DataFrame
- RDD: Неструктурированные данные, API на Scala/Java/Python, оптимизация вручную.
- DataFrame: Структурированные данные, API на SQL/DSL, автоматическая оптимизация (Catalyst).

8) Трансформации и действия в Spark
- Трансформации (map, filter) — ленивые операции, создающие новый RDD/DataFrame.
- Действия (count, collect) — операции, запускающие вычисление и возвращающие результат.

9) Структура приложения Spark
- Создание SparkSession.
- Загрузка данных (создание RDD/DataFrame).
- Применение трансформаций.
- Вызов действия для получения результата.
- Закрытие сессии.

10) UDF в Spark
User-Defined Function — пользовательская функция, написанная на Python, Scala или Java, для применения к данным, когда встроенных функций недостаточно.

11) Регистрация и использование UDF
- Определить функцию на языке.
- Зарегистрировать её с помощью spark.udf.register().
- Использовать в DSL или SQL-запросе.

12) Кэширование в Spark
Сохранение RDD/DataFrame в память или на диск узлов для многократного использования, что ускоряет итеративные алгоритмы и доступ к часто используемым данным.

13) Оптимизация приложений Spark
- Выбор правильного уровня параллелизма.
- Использование кэширования.
- Минимизация операций shuffle.
- Использование форматов columnar (Parquet, ORC).
- Настройка разделов (partitions).

14) Источники данных
Файловые системы (HDFS, S3), реляционные и NoSQL БД, потоки данных (Kafka), другие источники через коннекторы.

<h3>7. HBase</h3>

1) Что такое HBase
Распределённая, масштабируемая NoSQL СУБД поверх HDFS для случайного доступа к большим данным в реальном времени.

2) Архитектура HBase
- HMaster: Управляет метаданными и балансировкой регионов.
- RegionServer: Обслуживает регионы (диапазоны строк) для чтения/записи.
- ZooKeeper: Координирует кластер, отслеживает доступность HMaster и RegionServer.
- HDFS: Файловая система для хранения данных.

3) Модель данных HBase
Колоночная ориентированная. Данные — разреженная таблица с:
- Ключ строки (уникальный, сортированный)
- Семейства столбцов (группы столбцов)
- Ячейки: версия (timestamp) → значение

4) Роли компонентов
- HMaster: Администрирование (создание таблиц, назначение регионов), отказоустойчивость.
- RegionServer: Обработка запросов ввода-вывода к регионам, управление MemStore (память) и HFiles.
- HFile: Физический формат хранения данных (на основе HFile, обычно в HDFS), неизменяемый после записи.

<h3>8. Компоненты</h3>

1) Apache Ranger
Apache Ranger - фреймворк для управления безопасностью и политиками доступа в Hadoop экосистеме. Основные возможности:
- Централизованное управление политиками доступа: Предоставляет единую панель для настройки политик безопасности, контроля доступа и аудита.
- Поддержка множества служб: Включает в себя интеграцию с большинством компонентов Hadoop, таких как HDFS, YARN, Hive, HBase и других.
- Мониторинг и аудит: Фиксирует все действия пользователей и администраторов, предоставляя подробные отчеты для аудита и соответствия стандартам безопасности.
- Тонкая настройка политик доступа: Позволяет определять политики на уровне ресурсов, пользователей и групп.

2) Apache Knox
Apache Knox - шлюз безопасности для Hadoop экосистемы, предназначенный для обеспечения безопасного доступа к данным и интерфейсам Hadoop через REST API. Knox помогает упростить интеграцию и безопасный доступ к кластерам Hadoop извне. Основные возможности:
- Упрощение доступа: Обеспечивает единый доступ через REST API ко всем компонентам Hadoop кластера.
- Аутентификация и авторизация: Поддерживает множество механизмов аутентификации, включая LDAP и Active Directory, а также интеграцию с Apache Ranger для управления доступом.
- Маршрутизация запросов: Автоматически направляет запросы к соответствующим службам в кластере.
- Безопасность на транспортном уровне: Обеспечивает шифрование трафика и поддерживает работу через HTTPS для защиты данных в процессе передачи.

3) Apache Atlas
Apache Atlas предназначен для управления метаданными и обеспечения управляемости данных в Hadoop экосистеме. Он позволяет классифицировать и управлять метаданными, а также обеспечивать трассировку происхождения данных (Data Lineage).Основные возможности:
- Классификация данных: Помогает определить и применить классификации к данным, упрощая их поиск, управление и защиту.
- Трассировка происхождения данных: Позволяет отслеживать и визуализировать процесс перемещения и обработки данных внутри экосистемы.
- Интеграция с другими службами: Тесно интегрируется с другими компонентами Hadoop для автоматического сбора и классификации метаданных.

4) Apache Ambari
Apache Ambari предоставляет инструменты для управления, мониторинга и настройки кластеров Hadoop. Хотя Ambari не управляет метаданными напрямую, он играет ключевую роль в управлении экосистемой, которая генерирует и использует эти метаданные. Основные возможности:
- Управление кластером: Упрощает процесс развертывания, конфигурирования и управления кластерами Hadoop.
- Мониторинг: Предоставляет дашборды для отслеживания состояния кластера, сервисов и узлов.
- Настройка служб: Позволяет настраивать и оптимизировать параметры конфигурации компонентов Hadoop кластера.

5) Apache Hue - веб-интерфейс для упрощения работы с данными в Hadoop экосистеме. Hue позволяет пользователям взаимодействовать с различными службами Hadoop, такими как HDFS, Apache Hive, Impala, Apache Spark и другими, через удобный пользовательский интерфейс.

Основные возможности:
- Редакторы запросов: Предоставляет интерфейсы для выполнения запросов SQL в Hive или Impala, скриптов Pig, задач Spark и других.
- Браузеры данных: Позволяет пользователям просматривать и управлять данными в HDFS, Hive и других хранилищах данных.
- Пользовательский доступ: Поддерживает управление доступом и безопасность на уровне пользователей и групп.
- Интеграция с Apache Oozie: Упрощает создание и мониторинг рабочих процессов и заданий в Oozie.