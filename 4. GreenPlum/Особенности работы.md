<h2>Особенности работы</h2>
<h3>1. Таблицы</h3>
<h4>Типы таблиц</h4>

Greenplum Database поддерживает разнообразие типов таблиц, каждый из которых предназначен для оптимизации хранения и обработки данных в зависимости от конкретных требований приложения. Основные типы таблиц в Greenplum:
- Обычные таблицы (Heap Tables): По умолчанию, таблицы в Greenplum создаются как обычные таблицы. Они поддерживают операции вставки, обновления и удаления данных. Данные в таких таблицах хранятся в неупорядоченном виде.
- Таблицы с разделением (Partitioned Tables): Таблицы могут быть разделены по диапазону или списку значений для оптимизации запросов, особенно для больших объемов данных. Разделение улучшает производительность за счет уменьшения количества данных, обрабатываемых в каждом запросе.
- Таблицы с внешним хранилищем (External Tables): Позволяют Greenplum работать с данными, физически хранящимися за пределами базы данных, например, в файлах на файловой системе или в Hadoop HDFS. Это полезно для интеграции и обработки больших объемов внешних данных.
- Таблицы со случайным распределением (Randomly Distributed Tables): В этих таблицах строки распределяются случайным образом по сегментам. Это может быть полезно, когда нет подходящего ключа для распределения или когда равномерное распределение данных является более важным.
- Распределенные по ключу таблицы (Hash Distributed Tables): В таких таблицах данные распределяются по сегментам на основе хэш-функции от одного или нескольких столбцов. Это обеспечивает эффективное параллельное выполнение запросов за счет локализации связанных данных в одном сегменте.

```sql
CREATE [TEMPORARY | TEMP] TABLE [IF NOT EXISTS] table_name (
column_name data_type [column_constraint] [DEFAULT default_expr]
[, ... ]
)
[WITH (storage_parameter=value [, ... ])]
[TABLESPACE tablespace]
[DISTRIBUTED BY (column_name [, ... ]) | DISTRIBUTED RANDOMLY | DISTRIBUTED REPLICATED]
[PARTITION BY partition_type (column_name)
[SUBPARTITION BY partition_type (column_name)]
[SUBPARTITION TEMPLATE (template_spec)]
[...] (partition_spec) ]
```

Пояснения:
- `TEMPORARY` или `TEMP`: создает временную таблицу, которая удаляется в конце сессии.
- `WITH (storage_parameter=value)`: задает параметры хранения, например:
  - `appendoptimized = true|false` - для сжатия и оптимизации под append-нагрузку
  - `orientation = column|row` - ориентация таблицы
  - `compresstype = zlib|quicklz|zstd|...` - тип сжатия
  - `compresslevel = compress_level` уровень сжатия - (например, от 1 до 9 для zlib)
- `TABLESPACE`: указывает табличное пространство для таблицы.
- `DISTRIBUTED BY`: указывает столбцы для распределения данных по сегментам. Альтернативы:
  - `DISTRIBUTED RANDOMLY`: данные распределяются случайным образом.
  - `DISTRIBUTED REPLICATED`: таблица реплицируется (копия на каждом узле).
- `PARTITION BY`: определяет партиционирование таблицы. Может быть:
  - `RANGE` (по диапазону)
  - `LIST` (по списку значений)
- Также можно создавать подпартиции (`SUBPARTITION BY`).

<h4>Модификация и особенности таблиц</h4>

После создания таблицы в Greenplum можно изменить некоторые аспекты, но не все. Рассмотрим основные операции:
- Изменение распределения: Можно изменить политику распределения, при этом данные будут перераспределены, что может быть ресурсоемкой операцией. Команда:
```sql
ALTER TABLE table_name SET [DISTRIBUTED BY (column_name [, ... ]) | DISTRIBUTED RANDOMLY]
```
- Изменение типа хранения (с `heap` на `columnar` и наоборот): Нельзя напрямую изменить тип хранения существующей таблицы. Но можно создать новую таблицу с нужным типом хранения и скопировать данные.
- Изменение партиционирования: Можно добавлять и удалять партиции, однако изменить способ партиционирования (столбец партиционирования или тип) напрямую нельзя. Команда:
```sql
ALTER TABLE table_name [ADD | DROP] PARTITION partition_expr
```
- Изменение схемы таблицы (добавление/удаление столбцов, изменение типов данных и т.д.): Поддерживаются стандартные операции `ALTER TABLE`, такие как `ADD COLUMN`, `DROP COLUMN`, `ALTER COLUMN TYPE`.
- Преобразование в реплицированную таблицу: В Greenplum нет прямой команды чтобы изменить распределенную таблицу на реплицированную. Обычно нужно создать новую таблицу с типом репликации и скопировать данные.

Особенности распределенных таблиц:
- Сегменты: Данные таблицы физически хранятся не в одном месте, а распределены по нескольким сегментам (отдельным экземплярам PostgreSQL), каждый на своем сервере или диске.
- Ключ распределения: Это столбец (или группа столбцов), указанный в `DISTRIBUTED BY`. При вставке строка попадает на определенный сегмент, вычисленный по хэшу от значения ключа распределения. Основные цели при определении ключа распределения
- Равномерность: Данные должны распределяться равномерно. Если один ключ встречается слишком часто, один сегмент будет перегружен, а другие — простаивать. Это называется "перекос данных".
- Локализация соединений: Если две таблицы распределены по одному и тому же ключу, то при `JOIN` строки с одинаковым значением ключа гарантированно находятся на одном и том же сегменте. Запрос выполняется локально на каждом сегменте без пересылки данных между ними (Motion).
- Перемещение данных: Если JOIN выполняется по ключу, отличному от ключа распределения, Greenplum вынужден перемещать данные. Motion — это дорогая операция, которую нужно минимизировать правильным выбором ключей распределения. Типы Motion:
  - Redistribute Motion: Перераспределяет строки одной таблицы по новому ключу.
  - Broadcast Motion: Отправляет всю небольшую таблицу на каждый сегмент, где находится большая таблица.
- Ограничения уникальности: Ограничения UNIQUE и PRIMARY KEY должны включать в себя все столбцы ключа распределения. Чтобы проверить уникальность значения, система должна видеть все его вхождения, а они разбросаны по сегментам. Если ключ распределения является частью первичного ключа, проверка уникальности гарантируется.

<h4>Сравнение постоянных и временных таблиц</h4>

Временные таблицы в Greenplum имеют важные особенности в многопользовательской среде. Основные ограничения:
- Изоляция сессий: Временные таблицы видны только в той сессии, где они созданы. Другие сессии не видят эти таблицы, даже если работают под тем же пользователем.
- Автоматическое удаление: Временные таблицы автоматически удаляются в конце сессии (при нормальном завершении), при аварийном обрыве соединения или их можно явно удалить командой `DROP TABLE`
- Ограничения распределения: Временные таблицы распределяются так же, как и обычные — по указанному ключу распределения или случайно, однако их данные хранятся локально в каждой сессии, что может приводить к дублированию.
- Ограничения транзакций: Временные таблицы участвуют в транзакциях, но их создание/удаление имеет особенности:
- Нельзя использовать в параллельных операциях: Временные таблицы сложно использовать для промежуточных результатов в параллельных ETL-процессах, так как они изолированы по сессиям.

Между вревенными и обычными таблицами существует ряд различий:
- Время жизни:
  - Временные: Существуют только в течение сессии или транзакции. Автоматически удаляются при завершении.
  - Постоянные: Существуют постоянно, пока не будут явно удалены командой `DROP TABLE`.
- Видимость:
  - Временные: Видны только в той сессии, в которой были созданы. Не видны другим пользователям.
  - Постоянные: Видны всем пользователям с соответствующими правами доступа.
- Распределение:
  - Временные: По умолчанию создаются только на мастере (не распределяются по сегментам). Можно явно указать распределение.
  - Постоянные: Всегда распределяются по сегментам (если не указано иное).
- Журналирование (WAL):
  - Временные: Минимальное или отсутствует журналирование, что повышает производительность.
  - Постоянные: Полное журналирование для обеспечения надежности и восстановления.
- Использование:
  - Временные: Для промежуточных вычислений, хранения временных данных в рамках ETL/ELT процессов.
  - Постоянные: Для хранения основных данных, фактовых и справочных таблиц.

<h4>Сравнение строковых и колоночных таблиц</h4>

Между строковыми и колоночными таблицами существует ряд различий:
- Структура хранения:
  - Строковые: Данные хранятся построчно. Все столбцы одной строки хранятся вместе.
  - Колоночные: Данные хранятся по столбцам. Все значения одного столбца хранятся вместе.
- Оптимизация:
  - Строковые: Для операций OLTP: частые вставки, обновления, удаления, выборка полных строк.
  - Колоночные: Для операций OLAP: аналитические запросы, агрегации, сканирование по ограниченному числу столбцов.
- Сжатие:
  - Строковые: Низкая эффективность сжатия, так как данные в строке разнотипные.
  - Колоночные: Очень высокая эффективность сжатия (до 70-90%). Данные в столбце однотипные, что позволяет применять эффективные алгоритмы (RLE, Delta и др.).
- Производительность запросов:
  - Строковые: Быстрый доступ к полной строке. Медленное сканирование при агрегациях по столбцам (читаются все данные).
  - Колоночные: Медленный доступ к полной строке. Очень быстрое сканирование столбцов для агрегаций и фильтрации (читаются только нужные столбцы).
- Операции DML:
  - Строковые: Поддерживают `UPDATE`, `DELETE` эффективно.
  - Колоночные: `UPDATE` и `DELETE` неэффективны, требуют перезаписи больших объемов данных. Оптимизированы для `INSERT` и `SELECT`.

<h4>Внешние и внутренние соединения таблиц</h4>

В контексте SQL и Greenplum, соединения таблиц бывают нескольких видов, но основные:
- Внутреннее соединение (`INNER JOIN`): Возвращает только те строки, для которых есть совпадение в обеих таблицах. Строки, не имеющие соответствия в другой таблице, не включаются в результат.
- Внешнее соединение (`OUTER JOIN`):
  - `LEFT OUTER JOIN`: Возвращает все строки из левой таблицы и соответствующие строки из правой. Если соответствия нет, то в правой части будут `NULL`.
  - `RIGHT OUTER JOIN`: Возвращает все строки из правой таблицы и соответствующие из левой. Если соответствия нет, то в левой части будут `NULL`.
  - `FULL OUTER JOIN`: Возвращает все строки из обеих таблиц. Если в одной таблице нет соответствия, то недостающие значения заменяются `NULL`.

Внешние соединения полезны, когда нужно сохранить все строки одной или обеих таблиц, даже если нет совпадений. Внутренние соединения используются, когда нужны только полные совпадения. В Greenplum, как распределенной СУБД, важно учитывать, как данные распределены между сегментами. При выполнении соединений необходимо, чтобы соединяемые строки находились в одном сегменте. Это обеспечивается правильным выбором ключа распределения.

<h4>Влияние ключа распределения и партицирования на производительность</h4>

В Greenplum данные таблицы распределяются по сегментам на основе ключа распределения (distribution key). Правильный выбор ключа распределения критически важен для производительности:
- Равномерное распределение: Ключ должен равномерно распределять данные по сегментам, чтобы избежать перекоса (skew). Если данные skewed, то некоторые сегменты будут обрабатывать больше данных, чем другие, что приведет к неравномерной загрузке и снижению производительности.
- Локальность данных при соединениях: Если две таблицы часто соединяются по определенному столбцу, то имеет смысл распределить обе таблицы по этому столбцу. Тогда соединение будет выполняться локально на каждом сегменте без перемещения данных (broadcast или redistribution). Это значительно ускоряет выполнение запроса.
- Перераспределение (redistribution) и Broadcast: Если ключи распределения таблиц не совпадают с условием соединения, то Greenplum должен либо перераспределить данные (переслать строки между сегментами) по ключу соединения, либо сделать broadcast одной из таблиц (скопировать ее на все сегменты). Обе операции требуют сетевого обмена и могут быть дорогими.
- Агрегация: При выполнении агрегатных функций также важно, чтобы данные были распределены по ключу группировки. Это позволит выполнить агрегацию локально на каждом сегменте без необходимости сбора всех данных в одном месте.

Партиционирование таблиц в Greenplum — это разделение таблицы на несколько частей (партиций) по какому-либо критерию (часто по диапазону дат или списку значений). Преимущества:
- Управляемость: Упрощает управление большими таблицами. Например, можно быстро удалить или добавить целую партицию, что особенно полезно для данных, имеющих временной характер (например, удаление старых данных по месяцу).
- Производительность запросов: Если запросы часто фильтруются по ключу партиционирования, то оптимизатор может исключить из сканирования ненужные партиции (partition pruning). Это уменьшает объем данных, которые необходимо прочитать и обработать.
- Параллелизм: Операции могут выполняться параллельно по разным партициям, что может ускорить обработку.
- Эффективность обслуживания: Операции обслуживания, такие как перестроение индексов, сбор статистики, могут выполняться на уровне партиций, что позволяет работать с меньшими частями таблицы.

<h4>Наследование таблиц</h4>

В Greenplum, как и в PostgreSQL, поддерживается наследование таблиц. Это означает, что можно создать таблицу-родитель, а затем создать дочерние таблицы, которые наследуют ее структуру (столбцы). При этом дочерние таблицы могут иметь свои собственные дополнительные столбцы.
Особенности в Greenplum:
- Наследование может быть полезно для организации партиционирования, хотя в современных версиях Greenplum рекомендуется использовать встроенное декларативное партиционирование.
- Запросы к родительской таблице автоматически включают данные из всех дочерних таблиц (если не указано ключевое слово `ONLY`). Это удобно для выборки данных по всем партициям.
- В распределенной системе Greenplum каждая таблица (и родительская, и дочерние) должны быть распределены по одним и тем же ключам распределения, чтобы обеспечить корректность запросов.

```sql
-- Родительская таблица
CREATE TABLE items (
    id SERIAL,
    name TEXT,
    created_date DATE
);

-- Дочерняя таблица наследует все столбцы родителя
CREATE TABLE books () INHERITS (items);
CREATE TABLE electronics () INHERITS (items);

-- В books и electronics автоматически появятся столбцы: id, name, created_date
```

<h4>Особенности использования индексов в распределенных таблицах</h4>

В Greenplum индексы создаются на каждой сегментной таблице (т.е. на каждом сегменте для каждой таблицы) независимо. Индексы могут улучшить производительность для точечных запросов (то есть запросов, которые возвращают небольшое количество строк), например, по первичному ключу или по условию равенства. Однако, в Greenplum индексы не всегда являются панацеей для ускорения запросов. Для аналитических запросов, которые сканируют большие объемы данных (полное сканирование таблицы), использование индексов может быть менее эффективным, чем полное сканирование с параллелизмом, так как каждому сегменту приходится обращаться к своему индексу, и если запрос затрагивает большую часть таблицы, то стоимость обращения к индексу и последующего случайного доступа к данным может быть выше, чем последовательное сканирование. Также, индексы занимают место и замедляют операции загрузки данных, так как их нужно поддерживать.

Индексы в Greenplum не глобальные, а локальные для каждого сегмента. Это означает, что условие индекса должно быть применимо к данным на каждом сегменте. Например, индекс по первичному ключу будет эффективен, так как значения уникальны в пределах сегмента (благодаря распределению по первичному ключу). Не рекомендуется создавать индексы на столбцах, которые не являются ключами распределения, если по ним часто происходит соединение, так как это может не помочь избежать перемещения данных.

<h3>2. Распределенность</h3>
<h4>Способы распределения данных и критерии выбора</h4>

В Greenplum данные распределяются по сегментам на основе метода распределения, указанного при создании таблицы. Есть три основных способа:
- Распределение по хэшу (`DISTRIBUTED BY (column_name)`): Данные распределяются по сегментам с помощью хэш-функции, примененной к указанному столбцу или набору столбцов. Это обеспечивает равномерное распределение данных, если выбран хороший ключ (с высокой кардинальностью).
- Случайное распределение (`DISTRIBUTED RANDOMLY`): Данные распределяются случайным образом по всем сегментам. Этот метод обеспечивает равномерное распределение, но не позволяет выполнить колокацию (collocation) при соединениях.
- Реплицирование (`DISTRIBUTED REPLICATED`): Полная копия таблицы хранится на каждом сегменте. Это полезно для небольших таблиц (справочников), которые часто используются в соединениях с большими таблицами.

```sql
-- 1. Хэш-распределение (по умолчанию)
CREATE TABLE table1 (id INT, name TEXT) 
DISTRIBUTED BY (id);

-- 2. Случайное распределение
CREATE TABLE table2 (id INT, name TEXT) 
DISTRIBUTED RANDOMLY;

-- 3. Реплицированное распределение
CREATE TABLE table3 (id INT, name TEXT) 
DISTRIBUTED REPLICATED;
```

Критерии выбора:
- Если таблица часто соединяется с другими большими таблицами, то следует распределять по ключу соединения (хэш-распределение) для колокации.
- Если таблица небольшая (несколько мегабайт) и часто используется в соединениях, то реплицированное распределение может быть лучшим выбором, так как оно исключает необходимость перемещения данных при соединениях.
- Если нет явного ключа для соединений или таблица используется в основном для агрегаций, то случайное распределение может быть хорошим выбором.

<h4>Преимущества распределения данных и влияние на производительность</h4>

Преимущества распределенного хранения данных:
- Масштабируемость: Возможность увеличивать объем данных и производительность за счет добавления новых узлов (сегментов) в кластер.
- Производительность: Параллельная обработка запросов на множестве сегментов позволяет обрабатывать большие объемы данных быстрее.
- Отказоустойчивость: В Greenplum реализована репликация сегментов (зеркалирование), что позволяет продолжать работу при отказе одного из сегментов.
- Экономичность: Использование кластера из commodity-серверов (стандартное оборудование) может быть более выгодным, чем один мощный сервер.
- Гибкость: Разные типы данных и рабочие нагрузки могут быть распределены по кластеру для оптимального использования ресурсов.

Распределение данных напрямую влияет на производительность запросов, особенно тех, которые включают соединения и агрегации. Основные понятия:
- Колокация (Collocation): когда две таблицы распределены по одному и тому же ключу, соединение по этому ключу может быть выполнено локально на каждом сегменте без перемещения данных между сегментами. Это значительно ускоряет выполнение запроса.
- Перекос данных (Data Skew): если данные распределены неравномерно (например, при хэш-распределении по ключу с малым количеством уникальных значений), то некоторые сегменты могут быть перегружены, что приводит к снижению производительности.
- Перемещение данных (Data Motion): если соединение выполняется не по тому ключу, то Greenplum должен переместить данные между сегментами (операция Broadcast или Redistribute). Это дорогостоящая операция, которая может значительно замедлить запрос.

<h4>Типы индексов и их взаимодействие с распределением данных</h4>

Greenplum поддерживает те же индексы, что и PostgreSQL:
- B-tree: Поддерживает операции: =, <, <=, >, >=, `BETWEEN`, `IN`, `IS NULL`, `IS NOT NULL`. Может использоваться для `LIKE 'pattern%'` (если шаблон начинается с символа) Также поддерживает индексирование по выражениям (например, `UPPER(name)`) и частичные индексы (`WHERE condition`)
- Bitmap: Особенно эффективен для столбцов с низкой кардинальностью (например, пол, статус заказа). Bitmap индекс в Greenplum создается с использованием структуры Bitmap, которая отображает ключи в битовые карты для быстрого выполнения логических операций (`AND`, `OR`).
- GiST: Применяется для данных, которые не могут быть индексировами B-деревом, например, геометрические типы (point, polygon) или полнотекстовый поиск.
- GIN: Подходит для индексирования массивов, JSONB, а также для полнотекстового поиска. GIN инвертирует индекс, храня отдельные элементы составных значений.
- Hash: В настоящее время не рекомендуется, так как B-tree быстрее и надежнее. Кроме того, Hash индексы не поддерживают операции диапазона и не являются устойчивыми к сбоям (в старых версиях).
- SP-GiST: Используется для данных, которые имеют естественное сегментирование пространства, но не обязательно сбалансированное (например, IP-адреса, геоданные).

```sql
-- B-tree
CREATE INDEX idx_orders_date ON orders (order_date);
CREATE INDEX idx_orders_customer_id ON orders (customer_id) WHERE status = 'active';

-- Bitmap
CREATE INDEX idx_sales_status_bitmap ON sales USING bitmap (status);

-- GIST
CREATE INDEX idx_points_geom ON points USING gist (geom);

--GIN
CREATE INDEX idx_products_tags ON products USING gin (tags);
CREATE INDEX idx_docs_content ON documents USING gin (to_tsvector('english', content));

--SPGIST
CREATE INDEX idx_ips ON ip_addresses USING spgist (ip);
```

В распределенной среде индексы создаются локально на каждом сегменте. Это означает, что каждый сегмент строит индекс для своей части данных. Взаимодействие с распределением данных:
- Индексы эффективны для точечных запросов (поиск по ключу) и некоторых видов диапазонных запросов. Однако в Greenplum, который ориентирован на аналитические запросы (большие сканирования), индексы используются менее часто, чем в OLTP-системах.
- При использовании индексов в распределенной таблице, запрос должен быть выполнен на каждом сегменте, и каждый сегмент использует свой индекс. Поэтому индекс будет эффективен, если условие запроса позволяет сегменту быстро найти локальные данные.
- Если запрос включает условие по ключу распределения, то он будет выполнен только на одном сегменте (если распределение хэш-по-ключу и условие точно определяет сегмент). В этом случае индекс может быть очень эффективен.
- Для запросов, которые требуют полного сканирования таблицы (аналитические запросы), использование индексов может быть неэффективно, так как параллельное полное сканирование часто быстрее.

<h4>Репликация и распределенные транзакции</h4>

В Greenplum репликация работает на двух уровнях:
- Репликация сегментов (Segment Mirroring): Каждый первичный сегмент данных имеет одного или более зеркальных сегментов (mirror) на другом физическом хосте. Данные на первичный и зеркальный сегменты записываются синхронно в рамках одной распределенной транзакции. Если первичный сегмент выходит из строя, его зеркало автоматически становится первичным. После восстановления хоста система автоматически пересинхронизирует данные (процесс gprecoverseg). Цель - обеспечение отказоустойчивости и высокой доступности. Это не репликация для чтения, а "hot standby".
- Репликация Мастера (Master Mirroring): Существует standby-мастер, который постоянно получает изменения с основного мастера через механизм потоковой репликации PostgreSQL (WAL shipping). В случае падения основного мастера, standby-мастер promoted до активного состояния. Цель - Обеспечение отказоустойчивости координатора (мастер-ноды).

В классической однопроцессной СУБД (как PostgreSQL) транзакция управляется одним экземпляром. В Greenplum, который состоит из Координатора (Master) и множества Сегментов (Segments), одна логическая транзакция со стороны клиента превращается в распределенную транзакцию, вовлекающую множество процессов.

Greenplum использует алгоритм двухфазного коммита для обеспечения атомарности (все или ничего) распределенных транзакций:
1. Фаза 1: Подготовка (Prepare Phase): Координатор рассылает команды `PREPARE TRANSACTION` всем Сегментам, которые участвуют в транзакции. Каждый cегмент получает команду и выполняет всю необходимую работу (запись в WAL, блокировки и т.д.), но не фиксирует изменения окончательно. Вместо этого он переводит транзакцию в состояние "ожидание решения" и возвращает координатору ответ: "готов" (`PREPARED`) или "не готов" (в случае ошибки).
2. Фаза 2: Фиксация или Откат (Commit / Abort Phase):
  - Если ВСЕ сегменты ответили "готов": Координатор принимает решение "зафиксировать". Он записывает это решение в свой собственный журнал транзакций (журнал распределенных транзакций) и затем рассылает команду `COMMIT PREPARED` всем сегментам. Сегменты получают команду и окончательно применяют изменения.
  - Если ХОТЯ БЫ ОДИН сегмент ответил "не готов" (или произошел сбой/таймаут): Координатор принимает решение "откатить". Он рассылает команду `ROLLBACK PREPARED` всем сегментам. Сегменты отменяют все изменения, сделанные в рамках этой транзакции.

Преимущества двухфазного коммита:
- Атомарность: Гарантирует, что транзакция будет зафиксирована на всех Сегментах или ни на одном. Это критически важно для целостности данных в распределенной системе.
- Согласованность: Данные всегда будут находиться в согласованном состоянии across всех узлах кластера.

<h4>Оптимизация и мониторинг распределенных запросов</h4>

Ключевые методы оптимизации распределенных запросов в GreenPlum:
- Оптимизация распределения данных: Выбор правильного ключа распределения (Distribution Key) для больших таблиц, чтобы JOIN и агрегации выполнялись локально. Использование реплицированных таблиц (`DISTRIBUTED REPLICATED`) для маленьких справочников. Избегание перекосов данных (data skew) — выбор столбца с высокой кардинальностью.
- Партиционирование: Разделение больших таблиц на партиции по диапазону или списку (например, по дате) для исключения партиций (partition pruning).
- Сбор статистики: Регулярный запуск `ANALYZE` для обновления статистики, чтобы оптимизатор мог строить эффективные планы.
- Оптимизация запросов: Использование `EXPLAIN ANALYZE` для анализа планов запросов и выявления узких мест (например, движений данных - Motion). Избегание распределенных `JOIN` по несовпадающим ключам, которые приводят к перемещению данных (Broadcast или Redistribute Motion). Минимизация использования `DISTINCT`, если это возможно, так как это может привести к лишним операциям агрегации и перемещению данных.
- Проектирование схемы и запросов: Использование подзапросов и CTE там, где это уместно, но с осторожностью, так как они могут влиять на план. По возможности фильтрация данных на ранних этапах (например, в подзапросах) для уменьшения объема обрабатываемых данных.
- Индексы: Создание индексов для точечных запросов (хотя в Greenplum индексы используются менее интенсивно, чем в OLTP-системах, из-за полного сканирования сегментов). Однако для некоторых операций (например, равенства) индексы могут помочь.

Для мониторинга следует использовать Greenplum Command Center (GPCC) и системные представления

<h4>Влияние распределения данных на план выполнения запроса</h4>

Распределение данных является фундаментальным фактором, определяющим план выполнения запроса в Greenplum. Планировщик стремится минимизировать движение данных между сегментами, и то, как данные распределены, напрямую влияет на необходимость таких перемещений. Рассмотрим ключевые аспекты влияния:
- Соединения таблиц (`JOIN`):
  - Идеальный случай: Совместное размещение. Если две таблицы распределены по одинаковому ключу и условие `JOIN` использует этот ключ, то соответствующие строки находятся на одном и том же сегменте. Это позволяет выполнить `JOIN` локально на каждом сегменте параллельно, без пересылки данных. В плане запроса вы не увидите операций Motion.
  - Худший случай: Перераспределение (`Redistribute Motion`). Если таблицы распределены по разным ключам или `JOIN` выполняется по неключевому столбцу, то данные одной или обеих таблиц должны быть перемещены между сегментами. В плане запроса появляется узел `Redistribute Motion`. Это одна из самых дорогих операций.
  - Широковещательная рассылка (`Broadcast Motion`). Если одна из таблиц небольшая, планировщик может выбрать стратегию, при которой вся эта таблица рассылается на все сегменты, где хранится вторая (большая) таблица. В плане появляется узел `Broadcast Motion`.
- Агрегация (`GROUP BY`): Если агрегация выполняется по ключу распределения, то все данные для каждой группы уже находятся на одном сегменте. Это позволяет выполнить агрегацию локально (узлы `HashAggregate` или `GroupAggregate` без последующего `Gather Motion`). Если агрегация выполняется по другому столбцу, то сначала может потребоваться этап перераспределения данных (`Redistribute Motion`) для группировки всех значений на соответствующих сегментах, а затем уже этап финальной агрегации.
- Оконные функции (Window Functions): Оконные функции, использующие ключ распределения в своем предложении `PARTITION BY`, могут быть вычислены локально на каждом сегменте. Если же предложение `PARTITION BY` не совпадает с ключом распределения, потребуется перераспределение данных.
- Фильтрация (`WHERE`): Хотя фильтрация всегда выполняется на сегментах, неравномерное распределение данных (data skew) может привести к тому, что один сегмент будет обрабатывать значительно больше строк, чем другие, становясь "узким местом" (hot spot).

<h4>Метрики эффективности распределения данных</h4>

Чтобы оценить, насколько хорошо распределены ваши данные, можно использовать следующий набор метрик:
- Равномерность распределения строк (Data Skew): Насколько равномерно строки таблицы распределены по сегментам. Идеальный показатель — когда все сегменты хранят почти одинаковое количество строк. Измеряется с помощью запроса к системным каталогам. Классический запрос использует представление `gp_toolkit.gp_skew_coefficients`. Более точный способ — посчитать количество строк на сегмент. Это можно сделать через `gp_toolkit.gp_skew_idle_fractions`. Перекос менее 10% считается хорошим. Перекос более 20-30% требует внимания.
- Равномерность распределения дискового пространства: Даже если строк распределено равномерно, их физический размер может различаться из-за разной длины строк (`TEXT`, `VARCHAR`). Эта метрика показывает, насколько равномерно используется дисковое пространство. Измеряется с помощью запроса с использованием функции `pg_relation_size(oid)` для получения размера в байтах.
- Эффективность выполнения запросов (Query Efficiency): Анализ планов запросов. Измеряется наличием операций Motion в планах запросов, особенно `Redistribute Motion` на больших таблицах, временем выполнения этапов (slice) в `EXPLAIN ANALYZE`. Если один сегмент (slice) выполняется значительно дольше других — это явный признак перекоса данных или неравномерной загрузки. Соотношением "AOCS" (Amount of Data Shuffled) / (Total Data Size). Чем меньше данных приходится перемещать, тем лучше распределение.

<h4>Стратегии минимизации фрагментации данных в партиционированных таблицах</h4>

Партицирование в Greenplum (наследующее механизм от PostgreSQL) разбивает таблицу на множество дочерних таблиц (partitions). Со временем операции `UPDATE` и `DELETE` приводят к фрагментации внутри этих партиций, так как они в PostgreSQL/Greenplum являются операциями "записать новую версию строки и пометить старую как удаленную" (MVCC).

Причины фрагментации:
- `UPDATE`: Создает новую версию строки. Старая версия остается "мертвой" (dead tuple) до очистки.
- `DELETE`: Помечает строку как "мертвую".
- Частые пакетные операции `UPDATE/DELETE` без должного обслуживания.

Стратегии борьбы с фрагментацией:
- Использование таблиц, оптимизированных для вставки (Append-Optimized Tables): Специальный тип хранения в Greenplum, при котором данные оптимизированы для массовой вставки (bulk insert). В таких таблицах не поддерживается `UPDATE` и `DELETE` на уровне отдельных строк (хотя их можно выполнять, но это не эффективно). Исключает фрагментацию от частых `UPDATE/DELETE`. Это предпочтительная стратегия для больших фактовых таблиц в хранилищах данных, где основная нагрузка — это `INSERT` и `SELECT`.
- Регулярное выполнение `VACUUM` и `ANALYZE`:
  - `VACUUM`: Освобождает пространство, занимаемое "мертвыми" строками, помечая его доступным для переиспользования внутри той же партиции. VACUUM не возвращает пространство операционной системе, но предотвращает "раздувание" (bloat) таблицы.
    - `VACUUM [tablename]`: Быстрая операция, которая обрабатывает только необходимое для новых транзакций пространство.
    - `VACUUM FULL [tablename]`: Полная блокировка таблицы, которая перезаписывает ее в новое место на диске, полностью устраняя фрагментацию и возвращая пространство ОС. Очень дорогая операция, ее следует выполнять в период низкой нагрузки.
  - `ANALYZE`: Собирает статистику по таблице. Следует всегда выполнять `ANALYZE` после `VACUUM`, чтобы планировщик запросов имел актуальную информацию.
- Стратегия "`DROP` и воссоздание" партиций: Для партицированных таблиц, в которых данные в старых партициях не изменяются (например, партиции по месяцам), самый эффективный способ борьбы с фрагментацией — не использовать `VACUUM`, а полностью пересоздавать партицию. Создается новая, пустая партиция с той же структурой, в нее вставляются данные из старой партиции, отфильтровав "мертвые" строки (используя CTAS или `INSERT INTO ... SELECT * FROM ...`). Удаляется старая партицию (`DROP PARTITION`) и переименовывается новая в имя старой. Этот метод полностью устраняет фрагментацию и часто выполняется быстрее, чем `VACUUM FULL` для больших партиций.
- Инкрементальное обслуживание с помощью `VACUUM`: Можно настроить политику регулярного выполнения `VACUUM` для партиций, которые подвергаются частым изменениям. Настраивается фоновый процесс (например, через cron), который выполняет `VACUUM` для партиций, изменявшихся за последний день/неделю.
- Мониторинг фрагментации: Следует регулярно отслеживать уровень фрагментации, чтобы принимать взвешенные решения о необходимости обслуживания. Используется представление `gp_toolkit.gp_bloat_diag` или запросы к `pg_stat_user_tables` (столбцы `n_dead_tup` и `n_live_tup`). Высокое соотношение `n_dead_tup / n_live_tup` (например, > 0.2 или 20%) — сигнал к выполнению `VACUUM`.

<h4>Алгоритмы и стратегии оптимального распределения данных</h4>

Greenplum использует распределенные таблицы, данные которых размещаются across сегментов. Правильное распределение данных критически важно для минимизации перемещения данных между сегментами (data skew) и максимального использования параллелизма.

Существует несколько стратегий распределения:
- Распределение по хешу (`HASH`): Данные распределяются по сегментам с помощью хеш-функции от значения колонки(ок) распределения. Цель: равномерное распределение данных, чтобы каждый сегмент имел примерно одинаковое количество строк. Рекомендуется выбирать колонки, которые часто используются в `JOIN` и `GROUP BY`, чтобы избежать перемещения данных.
```sql
CREATE TABLE sales (id int, date date, amount decimal)
DISTRIBUTED BY (id);
```
- Циклическое распределение (`ROUND ROBIN`): Данные распределяются по сегментам поочередно, без учета значений. Гарантирует равномерное распределение, но не оптимизирует выполнение `JOIN`. Полезно для таблиц, которые не участвуют в `JOIN` и не имеют явного ключа для распределения.
```sql
CREATE TABLE logs (id int, log_time timestamp, message text)
DISTRIBUTED RANDOMLY;
```
- Реплицированные таблицы (`REPLICATED`): Полная копия таблицы размещается на каждом сегменте. Полезно для небольших справочных таблиц, которые часто используются в `JOIN` с большими таблицами.
```sql
CREATE TABLE countries (id int, name text)
DISTRIBUTED REPLICATED;
```

Рекомендации по выбору колонок для распределения:
- Выбирать колонки, которые часто используются в условиях `JOIN` и `GROUP BY`.
- Избегать распределения по колонкам с низкой кардинальностью (например, пол с значениями 'M'/'F'), так как это приведет к неравномерному распределению (data skew).
- Если нет подходящих колонок, использовать `ROUND ROBIN`, но помнить, что это может привести к необходимости перемещения данных при `JOIN`.

<h4>Работа с большими данными</h4>

Greenplum предназначен для обработки больших объемов данных. Вот ключевые аспекты:
- Партиционирование: Разбиение таблицы на меньшие части (партиции) по диапазону или списку значений улучшает производительность за счет исключения чтения ненужных данных (partition pruning) и упрощает управление данными (например, удаление старой партиции вместо `DELETE`). Пример партиционирования по диапазону:
```sql
CREATE TABLE sales (id int, date date, amount decimal)
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
(START (date '2023-01-01') END (date '2023-12-31') EVERY (INTERVAL '1 month'),
DEFAULT PARTITION extra);
```
- Индексы: Greenplum поддерживает индексы (B-tree, GiST, GIN, др.), но в контексте больших данных их использование должно быть обосновано. В отличие от OLTP, в Greenplum (OLAP) часто полное сканирование таблицы эффективнее использования индекса, особенно если затрагивается большая часть таблицы. Индексы полезны для точечных запросов (поиск по ключу) и для некоторых типов `JOIN`.
- Сжатие данных: Greenplum поддерживает сжатие данных на уровне колонок и строк (используя технологию Appender). Сжатие уменьшает объем хранимых данных и ускоряет I/O. Пример создания таблицы со сжатием:
```sql
CREATE TABLE sales_compressed (id int, date date, amount decimal)
WITH (APPENDONLY=true, COMPRESSTYPE=zlib, COMPRESSLEVEL=5)
DISTRIBUTED BY (id);
```
- Управление ресурсами: Использование Resource Queues для управления памятью, CPU и параллелизмом, настройка приоритетов для разных пользователей и нагрузок.
- Анализ и обновление статистики: Регулярный запуск `ANALYZE` для обновления статистики по таблицам. Оптимизатор использует статистику для построения эффективных планов запросов.
- Материализованные представления: Предварительно вычисленные результаты для сложных запросов могут значительно ускорить выполнение часто используемых агрегаций. Пример создания материализованного представления:
```sql
CREATE MATERIALIZED VIEW sales_summary AS
SELECT date_trunc('month', date) as month, sum(amount) as total
FROM sales
GROUP BY month;
```
- Работа с внешними таблицами: Greenplum может запрашивать данные из внешних источников (HDFS, S3, др.) с помощью внешних таблиц. Это Полезно для ETL и работы с данными, которые не нужно хранить в Greenplum. Пример внешней таблицы для чтения из CSV:
```sql
CREATE EXTERNAL TABLE ext_sales (id int, date date, amount decimal)
LOCATION ('gpfdist://datahost:8081/sales.csv')
FORMAT 'CSV';
```
- Параллельная загрузка и выгрузка данных: Использование утилит `gpfdist` и `gpss` для параллельной загрузки данных и `COPY` для выгрузки данных.
- Мониторинг и устранение перекосов данных: Регулярная проверка распределения данных для выявления перекосов и использование функции `gp_toolkit.gp_skew_coefficients` для анализа перекосов. Пример запроса для проверки перекоса:
```sql
SELECT schemaname, tablename, skew_ratio
FROM gp_toolkit.gp_skew_coefficients
WHERE skew_ratio > 1.5;
```
- Обновление стратегии распределения: Если распределение оказалось неудачным, можно изменить его с помощью `ALTER TABLE`. Пример изменения распределения:
```sql
ALTER TABLE sales SET DISTRIBUTED BY (new_key);
```

<h3>3. Блокировки</h3>
<h4>Основы блокировок</h4>

Блокировка (Lock) — это механизм, который временно ограничивает доступ к данным (строке, таблице, всей БД), чтобы предотвратить конфликты между параллельными транзакциями. Основные цели:
- Согласованность (Consistency): Гарантирует, что данные всегда находятся в валидном состоянии, даже при параллельных изменениях.
- Изоляция (Isolation): Реализует один из принципов ACID, обеспечивая, что параллельные транзакции не мешают друг другу.

Основные типы блокировок:
- Эксклюзивные (Exclusive Locks, X): Запрещают любой доступ к объекту другим транзакциям. Используются при операциях модификации (`INSERT`, `UPDATE`, `DELETE`). Одновременно на объекте может быть только одна эксклюзивная блокировка.
- Разделяемые (Shared Locks, S): Разрешают другим транзакциям читать объект, но запрещают его изменение. Одновременно на объекте может быть несколько разделяемых блокировок.

Уровни блокировок:
- На уровне строки (Row-Level): Блокируется только одна строка. Высокий параллелизм.
- На уровне таблицы (Table-Level): Блокируется вся таблица. Низкий параллелизм, но меньше накладных расходов.

Конфликты блокировок:
- S и S — НЕТ КОНФЛИКТА
- S и X — ЕСТЬ КОНФЛИКТ
- X и X — ЕСТЬ КОНФЛИКТ

Транзакция, которая не может получить блокировку, блокируется (wait) и ожидает, пока текущий владелец блокировки не освободит её (через `COMMIT` или `ROLLBACK`).

<h4>Блокировки на уровне строк</h4>

Greenplum, как и PostgreSQL, использует Многовариантное Управление Параллелизмом (MVCC). Это означает, что вместо блокировок на чтение, для каждого оператора создается "снимок" (snapshot) данных, и он видит только те данные, которые были закоммичены до начала его выполнения. Однако, блокировки на уровне строк существуют и активно используются для операций модификации. Как это работает:
1. Когда транзакция изменяет строку (`UPDATE`, `DELETE`), она сначала устанавливает на нее эксклюзивную блокировку (Row Exclusive Lock).
2. Если другая транзакция попытается изменить ту же самую строку, она также попытается установить эксклюзивную блокировку. Обнаружив, что блокировка уже занята, вторая транзакция перейдет в состояние ожидания.
3. Как только первая транзакция завершится (`COMMIT`/`ROLLBACK`), блокировка освободится, и вторая транзакция сможет продолжить работу.

Особенности Greenplum:
- Распределенность: Поскольку данные распределены по сегментам, блокировки на уровне строк управляются на каждом сегменте независимо. Координатор не имеет единого централизованного менеджера блокировок для всех строк.
- Блокировки кортежей (Tuple Locks): Внутренне Greenplum использует блокировки на уровне кортежей (физических записей), которые хранятся в заголовке самой строки. Это делает их очень эффективными.

<h4>Контроль параллельного доступа к данным</h4>

GreenPlum использует MVCC, что позволяет одновременно выполнять несколько операций чтения и записи без блокировок на чтение. Однако, при одновременной записи в одну и ту же строку возникает конфликт, и одна из транзакций будет ждать или прервется (в зависимости от настроек). Важные аспекты:
- Уровни изоляции транзакций: GreenPlum поддерживает уровни изоляции, определенные в стандарте SQL. По умолчанию используется Read Committed. Также поддерживается Repeatable Read и Serializable (хотя в распределенной системе это сложнее).
- В GreenPlum, из-за распределенности, некоторые операции (например, создание индексов) могут требовать эксклюзивных блокировок на уровне таблицы, которые блокируют все операции с таблицей.

Для управления параллельным доступом можно использовать:
- Настройку уровня изоляции транзакций.
- Использование блокировок (например, `LOCK TABLE`) в явном виде.
- Оптимизацию запросов и транзакций, чтобы минимизировать время блокировок.

Пример установки уровня изоляции:
```sql
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
-- ... операции ...
COMMIT;
```
В GreenPlum также есть мониторинг блокировок. Можно запросить системные представления, такие как `pg_locks` и `pg_stat_activity`, чтобы увидеть текущие блокировки и транзакции.

Пример запроса для просмотра блокировок:
```sql
SELECT locktype, relation::regclass, mode, transactionid, virtualtransaction, pid, granted
FROM pg_locks
WHERE relation = 'table_name'::regclass;
```

В случае длительных блокировок может потребоваться принудительное завершение транзакции с помощью функции `pg_terminate_backend(pid)`.

<h4>Взаимоблокировки</h4>

Взаимоблокировка (Deadlock) — это ситуация, когда две или более транзакций взаимно блокируют друг друга, ожидая освобождения ресурсов, захваченных противоположной стороной. Каждая транзакция ждет завершения другой, создавая цикл ожидания. Пример классической взаимоблокировки:
1. Транзакция A: `UPDATE table1 SET ... WHERE id = 1;` → Блокирует строку 1 в table1
2. Транзакция B: `UPDATE table2 SET ... WHERE id = 1;` → Блокирует строку 1 в table2
3. Транзакция A: `UPDATE table2 SET ... WHERE id = 1;` → Ждет, пока Транзакция B освободит table2
4. Транзакция B: `UPDATE table1 SET ... WHERE id = 1;` → Ждет, пока Транзакция A освободит table1

Обе транзакции ждут друг друга и никогда не завершатся.

Механизмы предотвращения в Greenplum:
- Детектор взаимоблокировок (Deadlock Detector): Greenplum периодически (обычно каждые 1-5 секунд, настраивается через `deadlock_timeout`) проверяет граф ожидания блокировок на наличие циклов. Система строит граф, где узлы — транзакции, а ребра — зависимости "кто кого ждет". При обнаружении цикла одна из транзакций становится "жертвой". Система автоматически выбирает транзакцию для прерывания, обычно ту, которую дешевле откатить (например, которая сделала меньше изменений).
- Таймаут блокировок (`lock_timeout`): Глобальный параметр, который определяет максимальное время ожидания блокировки. Если транзакция ждет блокировку дольше `lock_timeout`, она не становится жертвой взаимоблокировки, а просто прерывается с ошибкой. Это не предотвращает взаимоблокировки, но ограничивает время "висения" транзакций.
- Распределенная природа Greenplum: Поскольку данные распределены по сегментам, многие блокировки управляются локально на каждом сегменте. Это может уменьшить вероятность взаимоблокировок для запросов, которые работают с разными сегментами данных. Однако взаимоблокировки все равно возможны, особенно при работе с данными, которые локализованы на одном сегменте, или при использовании блокировок на уровне таблиц.

Стратегии предотвращения взаимоблокировок:
- Упорядочивание доступа к объектам: всегда блокировать таблицы и строки в одном и том же порядке во всех транзакциях. Это предотвращает образование циклов.
- Использование кратковременных транзакций: чем короче транзакция, тем меньше времени для возникновения взаимоблокировки.
- Использование менее строгих уровней изоляции, где это возможно (например, Read Committed вместо Repeatable Read).
- Использование `SELECT ... FOR UPDATE NOWAIT`: Если строка уже заблокирована, запрос сразу завершится с ошибкой, а не будет ждать.
- Использование индексов для уменьшения времени блокировок при операциях обновления и удаления.

Диагностика и разрешение взаимоблокировок:
- Просмотр логов: В логах будет сообщение, содержащее детали взаимоблокировки, включая запросы и процессы, участвующие в ней.
- Использование системных представлений: Для диагностики можно использовать системные представления, такие как `pg_locks` и `pg_stat_activity`.
- Принудительное завершение: Можно принудительно завершить одну из транзакций, используя функцию `pg_terminate_backend(pid)`, но обычно система сама разрешает взаимоблокировку.

<h4>Уровни изоляции транзакций и команды для блокировки</h4>

Greenplum, как и PostgreSQL, поддерживает два уровня изоляции: `READ COMMITTED` и `REPEATABLE READ` (который в PostgreSQL называется `SERIALIZABLE`, но в Greenplum используется термин `REPEATABLE READ` для того же уровня). Однако, в Greenplum, из-за распределенного характера, уровень изоляции `REPEATABLE READ` не полностью соответствует стандарту SQL. Фактически, Greenplum использует модель изоляции на основе снимков данных (Snapshot Isolation) для распределенных транзакций.

Уровни изоляции:
- `READ COMMITTED` (по умолчанию): В этом уровне каждая оператор в транзакции видит только те данные, которые были зафиксированы до начала выполнения этого оператора. Это означает, что если в течение транзакции один и тот же запрос выполняется дважды, он может увидеть разные данные, если другие транзакции в промежутке зафиксировали изменения.
- `REPEATABLE READ`: В этом уровне транзакция видит только те данные, которые были зафиксированы до начала транзакции. Это обеспечивает повторяемость чтения. Однако, в Greenplum этот уровень реализован с использованием снимков данных на момент начала транзакции. Важно отметить, что в Greenplum уровень `REPEATABLE READ` не предотвращает фантомное чтение в том же смысле, как в стандарте SQL, из-за распределенной архитектуры.

Команды для управления блокировками:
- `BEGIN` или `START TRANSACTION` - начало транзакции.
- `SET TRANSACTION ISOLATION LEVEL { READ COMMITTED | REPEATABLE READ }` - установка уровня изоляции. Должна быть выполнена до любых операций в транзакции.
- `LOCK TABLE` - явная блокировка таблицы. Может использоваться для получения блокировок разных режимов (например, `ACCESS SHARE`, `ROW SHARE`, `ROW EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`, `SHARE`, `SHARE ROW EXCLUSIVE`, `EXCLUSIVE, ACCESS EXCLUSIVE`).

```sql
-- Установка уровня изоляции REPEATABLE READ
BEGIN;
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;
-- ... операции ...
COMMIT;

-- Явная блокировка таблицы
LOCK TABLE my_table IN ACCESS EXCLUSIVE MODE;
```

<h4>Оптимизация работы с блокировками</h4>

Цель — не допустить ситуаций, когда блокировки становятся "узким местом". Вот ключевые стратегии:
- Короткие транзакции: Чем быстрее транзакция завершается (`COMMIT`/`ROLLBACK`), тем меньше времени она удерживает блокировки.
- Порядок доступа к объектам: Всегда блокировать таблицы в одном и том же порядке во всех приложениях и скриптах. Это единственный надежный способ предотвратить взаимоблокировки (deadlocks).
- Использование подходящего уровня изоляции: Greenplum по умолчанию использует `READ COMMITTED`. В большинстве случаев этого достаточно. Не используйте `SERIALIZABLE` без крайней необходимости, так как это создает наибольшие накладные расходы и повышает вероятность конфликтов.
- Избегание блокировок таблиц (`LOCK TABLE`): Не использовать `LOCK TABLE` в явном виде, особенно в режимах `ACCESS EXCLUSIVE`, если это не критично для операций типа `ALTER TABLE` или полной перестройки данных.
- Оптимизация DDL-операций: Операции типа `ALTER TABLE`, `CREATE INDEX`, `TRUNCATE` требуют тяжелых блокировок, их следует выполнять в периоды минимальной нагрузки.
- Использование `TRUNCATE` вместо `DELETE FROM table`: `TRUNCATE` — это быстрая операция, которая сразу освобождает место и требует тяжелой блокировки, но на очень короткое время. `DELETE` сканирует каждую строку и может блокироваться другими операциями.
- Партиционирование: Огромное преимущество Greenplum. Если вы обновляете данные только в одной партиции, блокировка устанавливается только на эту партицию, а не на всю таблицу. Это кардинально повышает параллелизм.

Когда блокировки неизбежны, нужно смягчить их воздействие:
- Настройка таймаутов:
  - `lock_timeout`: Определяет максимальное время, которое операция будет ждать получения блокировки. Прерывает запрос, который не может получить блокировку, а не "висит" вечно. Например, `SET lock_timeout = '30s'`.
  - `idle_in_transaction_session_timeout`: Автоматически завершает сессии, которые открыли транзакцию, но не активны (не выполняют запросы). Такие сессии часто являются причиной "висящих" блокировок.
- Пакетная обработка (Batching): Вместо одного огромного `UPDATE` или `DELETE` на миллионы строк, выполняются пакеты по 10-50 тысяч строк. Каждый пакет — это короткая транзакция, которая ненадолго захватывает блокировки и освобождает их.
- `CREATE TABLE AS SELECT / INSERT INTO ... SELECT` вместо долгих `UPDATE`: Часто более эффективно создать новую таблицу с нужными данными, чем массово обновлять существующую. Это позволяет минимизировать время удержания эксклюзивных блокировок на исходной таблице.

Ключевые системные представления для мониторинга:
- `pg_locks`: Основное представление для просмотра всех текущих блокировок.
- `pg_stat_activity`: Представление для просмотра текущих активных сессий и их запросов.
- `gp_toolkit.gp_locks_on_relation`: Удобное представление из `gp_toolkit`, которое показывает блокировки конкретно на отношения (таблицы, индексы и т.д.).

<h4>MVCC и его использование</h4>

MVCC (Multi-Version Concurrency Control) - это механизм управления параллельным доступом, который позволяет нескольким транзакциям работать с одними и теми же данными без блокировок на чтение. Вместо блокировок, каждая транзакция видит снимок данных на определенный момент времени. Это достигается за счет хранения нескольких версий строк.

Как Greenplum использует MVCC:
- Каждая строка в таблице имеет системные поля `xmin` и `xmax`, которые указывают на идентификаторы транзакций (XID), которые создали и удалили (или обновили) эту строку.
- При операции `UPDATE` фактически создается новая версия строки, а в старой строке устанавливается xmax.
- При операции `DELETE` устанавливается xmax для текущей версии строки.
- При операции `INSERT` создается новая строка с `xmin`, равным `XID` текущей транзакции.

В Greenplum, как распределенной СУБД, MVCC работает на каждом сегменте независимо. Координатор управляет распределенными транзакциями, назначая глобальный `XID` для каждой транзакции, который затем используется на всех сегментах.

Преимущества MVCC в Greenplum:
- Чтение не блокирует запись, и запись не блокирует чтение (за исключением случаев, когда требуется очень тяжелая блокировка, например, ACCESS EXCLUSIVE).
- Высокий уровень параллелизма.

Однако, у MVCC есть и недостатки, например необходимость очистки старых версий строк, которые больше не видны ни одной транзакции. Этим занимается процесс автоочистки (autovacuum). В Greenplum, как и в PostgreSQL, важно следить за работой autovacuum, чтобы не накапливались мертвые строки, приводящие к росту таблиц и снижению производительности.

Пример запроса для просмотра информации о версиях строк:
```sql
SELECT xmin, xmax, * FROM my_table;
```
Где `xmin` - идентификатор транзакции, вставившей строку, `xmax` - идентификатор транзакции, удалившей или обновившей строку (если 0, то строка текущая).
В Greenplum также есть дополнительные особенности из-за распределенности, например, необходимость координировать снимки данных между сегментами, чтобы обеспечить согласованность на уровне распределенной транзакции.

Для управления пространством и очисткой старых версий в Greenplum используется команда `VACUUM`. Она может быть выполнена вручную или автоматически (autovacuum). Рекомендуется настроить autovacuum адекватно нагрузке. Пример ручного запуска очистки:
```sql
VACUUM [FULL] [FREEZE] [VERBOSE] [ANALYZE] table_name;
```
- `VACUUM` без `FULL` просто освобождает место, помечая его доступным для повторного использования, но не возвращает операционной системе.
- `VACUUM FULL` перезаписывает таблицу, удаляя мертвые строки и возвращая пространство. Эта операция требует эксклюзивной блокировки таблицы.